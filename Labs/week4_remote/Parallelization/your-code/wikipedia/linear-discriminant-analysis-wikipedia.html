<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Linear discriminant analysis - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRequestId":"XnDIsQpAMOIAApcpoIQAAAAL","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Linear_discriminant_analysis","wgTitle":"Linear discriminant analysis","wgCurRevisionId":945697526,"wgRevisionId":945697526,"wgArticleId":1470657,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 maint: archived copy as title","Wikipedia articles needing clarification from April 2019","Wikipedia articles needing clarification from April 2012",
"All articles with dead external links","Articles with dead external links from December 2017","Articles with permanently dead external links","Classification algorithms","Market research","Market segmentation","Statistical classification"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Linear_discriminant_analysis","wgRelevantArticleId":1470657,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q1228929","wgCentralAuthMobileDomain":
!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","jquery.makeCollapsible.styles":"ready","mediawiki.toc.styles":"ready","skins.vector.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","ext.scribunto.logs","site","mediawiki.page.startup","skins.vector.js","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin",
"mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cjquery.makeCollapsible.styles%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.35.0-wmf.22"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Linear_discriminant_analysis rootpage-Linear_discriminant_analysis skin-vector action-view">
<div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading" class="firstHeading" lang="en">Linear discriminant analysis</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
		<div id="contentSub"></div>
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#p-search">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div role="note" class="hatnote navigation-not-searchable">Not to be confused with <a href="/wiki/Latent_Dirichlet_allocation" title="Latent Dirichlet allocation">latent Dirichlet allocation</a>.</div>
<p><b>Linear discriminant analysis</b> (<b>LDA</b>), <b>normal discriminant analysis</b> (<b>NDA</b>), or <b>discriminant function analysis</b> is a generalization of <b>Fisher's linear discriminant</b>, a method used in <a href="/wiki/Statistics" title="Statistics">statistics</a>, <a href="/wiki/Pattern_recognition" title="Pattern recognition">pattern recognition</a>, and <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> to find a <a href="/wiki/Linear_combination" title="Linear combination">linear combination</a> of <a href="/wiki/Features_(pattern_recognition)" class="mw-redirect" title="Features (pattern recognition)">features</a> that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a <a href="/wiki/Linear_classifier" title="Linear classifier">linear classifier</a>, or, more commonly, for <a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">dimensionality reduction</a> before later <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a>.
</p><p>LDA is closely related to <a href="/wiki/Analysis_of_variance" title="Analysis of variance">analysis of variance</a> (ANOVA) and <a href="/wiki/Regression_analysis" title="Regression analysis">regression analysis</a>, which also attempt to express one <a href="/wiki/Dependent_variable" class="mw-redirect" title="Dependent variable">dependent variable</a> as a linear combination of other features or measurements.<sup id="cite_ref-Fisher:1936_1-0" class="reference"><a href="#cite_note-Fisher:1936-1">&#91;1&#93;</a></sup><sup id="cite_ref-McLachlan:2004_2-0" class="reference"><a href="#cite_note-McLachlan:2004-2">&#91;2&#93;</a></sup> However, ANOVA uses <a href="/wiki/Categorical_variable" title="Categorical variable">categorical</a> <a href="/wiki/Independent_variables" class="mw-redirect" title="Independent variables">independent variables</a> and a <a href="/wiki/Continuous_variable" class="mw-redirect" title="Continuous variable">continuous</a> <a href="/wiki/Dependent_variable" class="mw-redirect" title="Dependent variable">dependent variable</a>, whereas discriminant analysis has continuous <a href="/wiki/Independent_variables" class="mw-redirect" title="Independent variables">independent variables</a> and a categorical dependent variable (<i>i.e.</i> the class label).<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup> <a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a> and <a href="/wiki/Probit_regression" class="mw-redirect" title="Probit regression">probit regression</a> are more similar to LDA than ANOVA is, as they also explain a categorical variable by the values of continuous independent variables. These other methods are preferable in applications where it is not reasonable to assume that the independent variables are normally distributed, which is a fundamental assumption of the LDA method.
</p><p>LDA is also closely related to <a href="/wiki/Principal_component_analysis" title="Principal component analysis">principal component analysis</a> (PCA) and <a href="/wiki/Factor_analysis" title="Factor analysis">factor analysis</a> in that they both look for linear combinations of variables which best explain the data.<sup id="cite_ref-Martinez:2001_4-0" class="reference"><a href="#cite_note-Martinez:2001-4">&#91;4&#93;</a></sup> LDA explicitly attempts to model the difference between the classes of data. PCA, in contrast, does not take into account any difference in class, and factor analysis builds the feature combinations based on differences rather than similarities. Discriminant analysis is also different from factor analysis in that it is not an interdependence technique: a distinction between independent variables and dependent variables (also called criterion variables) must be made.
</p><p>LDA works when the measurements made on independent variables for each observation are continuous quantities. When dealing with categorical independent variables, the equivalent technique is discriminant correspondence analysis.<sup id="cite_ref-Abdi_2007_5-0" class="reference"><a href="#cite_note-Abdi_2007-5">&#91;5&#93;</a></sup><sup id="cite_ref-Perriere_2003_6-0" class="reference"><a href="#cite_note-Perriere_2003-6">&#91;6&#93;</a></sup>
</p><p>Discriminant analysis is used when groups are known a priori (unlike in <a href="/wiki/Cluster_analysis" title="Cluster analysis">cluster analysis</a>). Each case must have a score on one or more quantitative predictor measures, and a score on a group measure.<sup id="cite_ref-buy_7-0" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup> In simple terms, discriminant function analysis is classification - the act of distributing things into groups, classes or categories of the same type.
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#LDA_for_two_classes"><span class="tocnumber">2</span> <span class="toctext">LDA for two classes</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Assumptions"><span class="tocnumber">3</span> <span class="toctext">Assumptions</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Discriminant_functions"><span class="tocnumber">4</span> <span class="toctext">Discriminant functions</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#Discrimination_rules"><span class="tocnumber">5</span> <span class="toctext">Discrimination rules</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#Eigenvalues"><span class="tocnumber">6</span> <span class="toctext">Eigenvalues</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#Effect_size"><span class="tocnumber">7</span> <span class="toctext">Effect size</span></a></li>
<li class="toclevel-1 tocsection-8"><a href="#Canonical_discriminant_analysis_for_k_classes"><span class="tocnumber">8</span> <span class="toctext">Canonical discriminant analysis for <i>k</i> classes</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#Fisher&#39;s_linear_discriminant"><span class="tocnumber">9</span> <span class="toctext">Fisher's linear discriminant</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="#Multiclass_LDA"><span class="tocnumber">10</span> <span class="toctext">Multiclass LDA</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="#Incremental_LDA"><span class="tocnumber">11</span> <span class="toctext">Incremental LDA</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#Practical_use"><span class="tocnumber">12</span> <span class="toctext">Practical use</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="#Applications"><span class="tocnumber">13</span> <span class="toctext">Applications</span></a>
<ul>
<li class="toclevel-2 tocsection-14"><a href="#Bankruptcy_prediction"><span class="tocnumber">13.1</span> <span class="toctext">Bankruptcy prediction</span></a></li>
<li class="toclevel-2 tocsection-15"><a href="#Face_recognition"><span class="tocnumber">13.2</span> <span class="toctext">Face recognition</span></a></li>
<li class="toclevel-2 tocsection-16"><a href="#Marketing"><span class="tocnumber">13.3</span> <span class="toctext">Marketing</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#Biomedical_studies"><span class="tocnumber">13.4</span> <span class="toctext">Biomedical studies</span></a></li>
<li class="toclevel-2 tocsection-18"><a href="#Earth_science"><span class="tocnumber">13.5</span> <span class="toctext">Earth science</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-19"><a href="#Comparison_to_logistic_regression"><span class="tocnumber">14</span> <span class="toctext">Comparison to logistic regression</span></a></li>
<li class="toclevel-1 tocsection-20"><a href="#Linear_discriminant_in_high_dimension"><span class="tocnumber">15</span> <span class="toctext">Linear discriminant in high dimension</span></a></li>
<li class="toclevel-1 tocsection-21"><a href="#See_also"><span class="tocnumber">16</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-22"><a href="#References"><span class="tocnumber">17</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-23"><a href="#Further_reading"><span class="tocnumber">18</span> <span class="toctext">Further reading</span></a></li>
<li class="toclevel-1 tocsection-24"><a href="#External_links"><span class="tocnumber">19</span> <span class="toctext">External links</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=1" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The original <a href="/wiki/Dichotomy" title="Dichotomy">dichotomous</a> discriminant analysis was developed by Sir <a href="/wiki/Ronald_Fisher" title="Ronald Fisher">Ronald Fisher</a> in 1936.<sup id="cite_ref-cohen_8-0" class="reference"><a href="#cite_note-cohen-8">&#91;8&#93;</a></sup> It is different from an <a href="/wiki/ANOVA" class="mw-redirect" title="ANOVA">ANOVA</a> or <a href="/wiki/MANOVA" class="mw-redirect" title="MANOVA">MANOVA</a>, which is used to predict one (ANOVA) or multiple (MANOVA) continuous dependent variables by one or more independent categorical variables. Discriminant function analysis is useful in determining whether a set of variables is effective in predicting category membership.<sup id="cite_ref-green_9-0" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="LDA_for_two_classes">LDA for two classes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=2" title="Edit section: LDA for two classes">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Consider a set of observations <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\vec {x}}"/></span> (also called features, attributes, variables or measurements) for each sample of an object or event with known class <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"/></span>. This set of samples is called the <a href="/wiki/Training_set" class="mw-redirect" title="Training set">training set</a>. The classification problem is then to find a good predictor for the class <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"/></span> of any sample of the same distribution (not necessarily from the training set) given only an observation <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\vec {x}}"/></span>.<sup id="cite_ref-Venables:2002_10-0" class="reference"><a href="#cite_note-Venables:2002-10">&#91;10&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>338</span></sup>
</p><p>LDA approaches the problem by assuming that the conditional <a href="/wiki/Probability_density_function" title="Probability density function">probability density functions</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\vec {x}}|y=0)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>y</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\vec {x}}|y=0)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d1e91e3ff4724ab55e76552351b4cc0c00bae85e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:10.461ex; height:2.843ex;" alt="p({\vec {x}}|y=0)"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\vec {x}}|y=1)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>y</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\vec {x}}|y=1)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cb01c1539284f1d6a96aaa62447c5128e944a5fd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:10.461ex; height:2.843ex;" alt="p({\vec {x}}|y=1)"/></span> are both <a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">normally distributed</a> with mean and <a href="/wiki/Covariance" title="Covariance">covariance</a> parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \left({\vec {\mu }}_{0},\Sigma _{0}\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow>
          <mo>(</mo>
          <mrow>
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>&#x03BC;<!-- μ --></mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>0</mn>
              </mrow>
            </msub>
            <mo>,</mo>
            <msub>
              <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>0</mn>
              </mrow>
            </msub>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \left({\vec {\mu }}_{0},\Sigma _{0}\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a06199f4d32722d66d01c3c12bc66e3df6c77e58" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.031ex; height:2.843ex;" alt="\left({\vec {\mu }}_{0},\Sigma _{0}\right)"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \left({\vec {\mu }}_{1},\Sigma _{1}\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow>
          <mo>(</mo>
          <mrow>
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>&#x03BC;<!-- μ --></mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>1</mn>
              </mrow>
            </msub>
            <mo>,</mo>
            <msub>
              <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>1</mn>
              </mrow>
            </msub>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \left({\vec {\mu }}_{1},\Sigma _{1}\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d04542286712bfc7f0f79de2bcfd5541dab0e25b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.031ex; height:2.843ex;" alt="\left({\vec {\mu }}_{1},\Sigma _{1}\right)"/></span>, respectively. Under this assumption, the Bayes optimal solution is to predict points as being from the second class if the log of the likelihood ratios is bigger than some threshold T, so that:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle ({\vec {x}}-{\vec {\mu }}_{0})^{T}\Sigma _{0}^{-1}({\vec {x}}-{\vec {\mu }}_{0})+\ln |\Sigma _{0}|-({\vec {x}}-{\vec {\mu }}_{1})^{T}\Sigma _{1}^{-1}({\vec {x}}-{\vec {\mu }}_{1})-\ln |\Sigma _{1}|\ &gt;\ T}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mtext>&#xA0;</mtext>
        <mo>&gt;</mo>
        <mtext>&#xA0;</mtext>
        <mi>T</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle ({\vec {x}}-{\vec {\mu }}_{0})^{T}\Sigma _{0}^{-1}({\vec {x}}-{\vec {\mu }}_{0})+\ln |\Sigma _{0}|-({\vec {x}}-{\vec {\mu }}_{1})^{T}\Sigma _{1}^{-1}({\vec {x}}-{\vec {\mu }}_{1})-\ln |\Sigma _{1}|\ &gt;\ T}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1b9954e129b47bb7696b199b73c14bcc849d4cb6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:71.664ex; height:3.343ex;" alt="({\vec {x}}-{\vec {\mu }}_{0})^{T}\Sigma _{0}^{-1}({\vec {x}}-{\vec {\mu }}_{0})+\ln |\Sigma _{0}|-({\vec {x}}-{\vec {\mu }}_{1})^{T}\Sigma _{1}^{-1}({\vec {x}}-{\vec {\mu }}_{1})-\ln |\Sigma _{1}|\ &gt;\ T"/></span></dd></dl>
<p>Without any further assumptions, the resulting classifier is referred to as QDA (<a href="/wiki/Quadratic_classifier" title="Quadratic classifier">quadratic discriminant analysis</a>).
</p><p>LDA instead makes the additional simplifying <a href="/wiki/Homoscedastic" class="mw-redirect" title="Homoscedastic">homoscedasticity</a> assumption (<i>i.e.</i> that the class covariances are identical, so <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{0}=\Sigma _{1}=\Sigma }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{0}=\Sigma _{1}=\Sigma }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/89a60bdc5488c601ac4ded1044ae3f5b6bcabedd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:13.34ex; height:2.509ex;" alt="\Sigma _{0}=\Sigma _{1}=\Sigma "/></span>) and that the covariances have full rank.
In this case, several terms cancel:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}^{T}\Sigma _{0}^{-1}{\vec {x}}={\vec {x}}^{T}\Sigma _{1}^{-1}{\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>x</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>=</mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>x</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}^{T}\Sigma _{0}^{-1}{\vec {x}}={\vec {x}}^{T}\Sigma _{1}^{-1}{\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6f3d15b69c93b9becd961fd99c00ccb3f648b64e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:19.217ex; height:3.509ex;" alt="{\vec {x}}^{T}\Sigma _{0}^{-1}{\vec {x}}={\vec {x}}^{T}\Sigma _{1}^{-1}{\vec {x}}"/></span></dd>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}^{T}{\Sigma _{i}}^{-1}{\vec {\mu }}_{i}={{\vec {\mu }}_{i}}^{T}{\Sigma _{i}}^{-1}{\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>x</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msup>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>&#x03BC;<!-- μ --></mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msup>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}^{T}{\Sigma _{i}}^{-1}{\vec {\mu }}_{i}={{\vec {\mu }}_{i}}^{T}{\Sigma _{i}}^{-1}{\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b47548efcbd5e21aef5b9cb93e9c27e23d91036f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:22.56ex; height:3.343ex;" alt="{\displaystyle {\vec {x}}^{T}{\Sigma _{i}}^{-1}{\vec {\mu }}_{i}={{\vec {\mu }}_{i}}^{T}{\Sigma _{i}}^{-1}{\vec {x}}}"/></span>  because <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7311e26a182cf249a67308c6ceb4d12d2c6896b8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.478ex; height:2.509ex;" alt="\Sigma _{i}"/></span> is <a href="/wiki/Hermitian_matrix" title="Hermitian matrix">Hermitian</a></dd></dl>
<p>and the above decision criterion
becomes a threshold on the <a href="/wiki/Dot_product" title="Dot product">dot product</a>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\cdot {\vec {x}}&gt;c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&gt;</mo>
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\cdot {\vec {x}}&gt;c}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8fe25a6aa1b34af1442727dbb7827294f90102ee" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:8.778ex; height:2.343ex;" alt="{\vec {w}}\cdot {\vec {x}}&gt;c"/></span></dd></dl>
<p>for some threshold constant <i>c</i>, where
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}=\Sigma ^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>=</mo>
        <msup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <mo stretchy="false">(</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}=\Sigma ^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4b58cdf092dbf241d217dbca9b1e16a6335c7b0f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:18.335ex; height:3.176ex;" alt="{\vec {w}}=\Sigma ^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})"/></span></dd>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c={\frac {1}{2}}(T-{{\vec {\mu }}_{0}}^{T}\Sigma ^{-1}{{\vec {\mu }}_{0}}+{{\vec {\mu }}_{1}}^{T}\Sigma ^{-1}{{\vec {\mu }}_{1}})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mn>2</mn>
          </mfrac>
        </mrow>
        <mo stretchy="false">(</mo>
        <mi>T</mi>
        <mo>&#x2212;<!-- − --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>&#x03BC;<!-- μ --></mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>0</mn>
              </mrow>
            </msub>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msup>
        <msup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <mrow class="MJX-TeXAtom-ORD">
          <msub>
            <mrow class="MJX-TeXAtom-ORD">
              <mrow class="MJX-TeXAtom-ORD">
                <mover>
                  <mi>&#x03BC;<!-- μ --></mi>
                  <mo stretchy="false">&#x2192;<!-- → --></mo>
                </mover>
              </mrow>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mn>0</mn>
            </mrow>
          </msub>
        </mrow>
        <mo>+</mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>&#x03BC;<!-- μ --></mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>1</mn>
              </mrow>
            </msub>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msup>
        <msup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <mrow class="MJX-TeXAtom-ORD">
          <msub>
            <mrow class="MJX-TeXAtom-ORD">
              <mrow class="MJX-TeXAtom-ORD">
                <mover>
                  <mi>&#x03BC;<!-- μ --></mi>
                  <mo stretchy="false">&#x2192;<!-- → --></mo>
                </mover>
              </mrow>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mn>1</mn>
            </mrow>
          </msub>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c={\frac {1}{2}}(T-{{\vec {\mu }}_{0}}^{T}\Sigma ^{-1}{{\vec {\mu }}_{0}}+{{\vec {\mu }}_{1}}^{T}\Sigma ^{-1}{{\vec {\mu }}_{1}})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e8ea93776f4cb1a3cabfe26204850c643e5baccb" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.838ex; width:35.854ex; height:5.176ex;" alt="{\displaystyle c={\frac {1}{2}}(T-{{\vec {\mu }}_{0}}^{T}\Sigma ^{-1}{{\vec {\mu }}_{0}}+{{\vec {\mu }}_{1}}^{T}\Sigma ^{-1}{{\vec {\mu }}_{1}})}"/></span></dd></dl>
<p>This means that the criterion of an input <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\displaystyle {\vec {x}}}"/></span> being in a class <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"/></span> is purely a function of this linear combination of the known observations.
</p><p>It is often useful to see this conclusion in geometrical terms: the criterion of an input <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\displaystyle {\vec {x}}}"/></span> being in a class <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"/></span> is purely a function of projection of multidimensional-space point <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\displaystyle {\vec {x}}}"/></span> onto vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\displaystyle {\vec {w}}}"/></span> (thus, we only consider its direction). In other words, the observation belongs to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"/></span> if corresponding <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db2dc6ced9cc3bc7e8b9f2707cbec033f6d3759c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:2.343ex;" alt="{\displaystyle {\vec {x}}}"/></span> is located on a certain side of a hyperplane perpendicular to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\displaystyle {\vec {w}}}"/></span>. The location of the plane is defined by the threshold c.
</p>
<h2><span class="mw-headline" id="Assumptions">Assumptions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=3" title="Edit section: Assumptions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The assumptions of discriminant analysis are the same as those for MANOVA. The analysis is quite sensitive to outliers and the size of the smallest group must be larger than the number of predictor variables.<sup id="cite_ref-buy_7-1" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup>
</p>
<ul><li><a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">Multivariate normality</a>: Independent variables are normal for each level of the grouping variable.<sup id="cite_ref-green_9-1" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup><sup id="cite_ref-buy_7-2" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup></li>
<li>Homogeneity of variance/covariance (<a href="/wiki/Homoscedasticity" title="Homoscedasticity">homoscedasticity</a>): Variances among group variables are the same across levels of predictors. Can be tested with <a href="/wiki/Box%27s_M_test" title="Box&#39;s M test">Box's M</a> statistic.<sup id="cite_ref-green_9-2" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> It has been suggested, however, that linear discriminant analysis be used when covariances are equal, and that <a href="/wiki/Quadratic_classifier#Quadratic_discriminant_analysis" title="Quadratic classifier">quadratic discriminant analysis</a> may be used when covariances are not equal.<sup id="cite_ref-buy_7-3" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup></li>
<li><a href="/wiki/Multicollinearity" title="Multicollinearity">Multicollinearity</a>: Predictive power can decrease with an increased correlation between predictor variables.<sup id="cite_ref-buy_7-4" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup></li>
<li><a href="/wiki/Statistical_independence" class="mw-redirect" title="Statistical independence">Independence</a>: Participants are assumed to be randomly sampled, and a participant's score on one variable is assumed to be independent of scores on that variable for all other participants.<sup id="cite_ref-green_9-3" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup><sup id="cite_ref-buy_7-5" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup></li></ul>
<p>It has been suggested that discriminant analysis is relatively robust to slight violations of these assumptions,<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup> and it has also been shown that discriminant analysis may still be reliable when using dichotomous variables (where multivariate normality is often violated).<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">&#91;12&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Discriminant_functions">Discriminant functions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=4" title="Edit section: Discriminant functions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Discriminant analysis works by creating one or more linear combinations of predictors, creating a new <a href="/wiki/Latent_variable" title="Latent variable">latent variable</a> for each function. These functions are called discriminant functions. The number of functions possible is either <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle N_{g}-1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>N</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>g</mi>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle N_{g}-1}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7e37ccc72c1745fa547dbe5249d72e55d71688dd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:6.89ex; height:2.843ex;" alt="{\displaystyle N_{g}-1}"/></span> where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle N_{g}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>N</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>g</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle N_{g}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3e13540585f557c8bd150cd8236a82f3cf8c153f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:2.888ex; height:2.843ex;" alt="N_{g}"/></span> = number of groups, or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.089ex; width:1.259ex; height:2.009ex;" alt="p"/></span> (the number of predictors), whichever is smaller. The first function created maximizes the differences between groups on that function. The second function maximizes differences on that function, but also must not be correlated with the previous function. This continues with subsequent functions with the requirement that the new function not be correlated with any of the previous functions.
</p><p>Given group <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle j}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>j</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle j}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.027ex; width:0.985ex; height:2.509ex;" alt="j"/></span>, with  <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbb {R} _{j}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbb {R} _{j}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/de8051cf7d3985732207d2c56bca30e1b38b4768" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:2.588ex; height:2.843ex;" alt="{\mathbb  {R}}_{j}"/></span>  sets of sample space, there is a discriminant rule such that if <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x\in \mathbb {R} _{j}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x\in \mathbb {R} _{j}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/890e192110d0ea0cdc581c699ff30d69fea1a6d9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:6.758ex; height:2.843ex;" alt="x\in {\mathbb  {R}}_{j}"/></span>, then <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x\in j}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
        <mo>&#x2208;<!-- ∈ --></mo>
        <mi>j</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x\in j}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6acaa3c13e02debb505991f99188945c28fb3c73" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:5.128ex; height:2.509ex;" alt="x\in j"/></span>. Discriminant analysis then, finds “good” regions of  <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbb {R} _{j}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbb {R} _{j}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/de8051cf7d3985732207d2c56bca30e1b38b4768" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:2.588ex; height:2.843ex;" alt="{\mathbb  {R}}_{j}"/></span> to minimize classification error, therefore leading to a high percent correct classified in the classification table.<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">&#91;13&#93;</a></sup>
</p><p>Each function is given a discriminant score<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag may need clarification or removal of jargon. (April 2019)">clarification needed</span></a></i>&#93;</sup> to determine how well it predicts group placement. 
</p>
<ul><li>Structure Correlation Coefficients: The correlation between each predictor and the discriminant score of each function. This is a zero-order correlation (i.e., not corrected for the other predictors). <sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;14&#93;</a></sup></li>
<li>Standardized Coefficients: Each predictor's weight in the linear combination that is the discriminant function.  Like in a regression equation, these coefficients are partial (i.e., corrected for the other predictors). Indicates the unique contribution of each predictor in predicting group assignment.</li>
<li>Functions at Group Centroids: Mean discriminant scores for each grouping variable are given for each function. The farther apart the means are, the less error there will be in classification.</li></ul>
<h2><span class="mw-headline" id="Discrimination_rules">Discrimination rules</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=5" title="Edit section: Discrimination rules">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Maximum_likelihood" class="mw-redirect" title="Maximum likelihood">Maximum likelihood</a>: Assigns x to the group that maximizes population (group) density.<sup id="cite_ref-har_15-0" class="reference"><a href="#cite_note-har-15">&#91;15&#93;</a></sup></li>
<li>Bayes Discriminant Rule: Assigns x to the group that maximizes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \pi _{i}f_{i}(x)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03C0;<!-- π --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \pi _{i}f_{i}(x)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6f35c70a2c329679558c8589c3f45f0db95d1194" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.203ex; height:2.843ex;" alt="\pi _{i}f_{i}(x)"/></span>, where <i>π<sub>i</sub></i> represents the <a href="/wiki/Prior_probability" title="Prior probability">prior probability</a> of that classification, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f_{i}(x)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f_{i}(x)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/76860d42459c0fb06c73293d257cf90698390262" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.078ex; height:2.843ex;" alt="f_{i}(x)"/></span> represents the population density.<sup id="cite_ref-har_15-1" class="reference"><a href="#cite_note-har-15">&#91;15&#93;</a></sup></li>
<li><a href="/wiki/Linear_Discriminant_Analysis" class="mw-redirect" title="Linear Discriminant Analysis">Fisher's linear discriminant rule</a>: Maximizes the ratio between <i>SS</i><sub>between</sub> and <i>SS</i><sub>within</sub>, and finds a linear combination of the predictors to predict group.<sup id="cite_ref-har_15-2" class="reference"><a href="#cite_note-har-15">&#91;15&#93;</a></sup></li></ul>
<h2><span class="mw-headline" id="Eigenvalues">Eigenvalues</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=6" title="Edit section: Eigenvalues">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>An <a href="/wiki/Eigenvalues_and_eigenvectors" title="Eigenvalues and eigenvectors">eigenvalue</a> in discriminant analysis is the characteristic root of each function.<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag may need clarification or removal of jargon. (April 2012)">clarification needed</span></a></i>&#93;</sup> It is an indication of how well that function differentiates the groups, where the larger the eigenvalue, the better the function differentiates.<sup id="cite_ref-buy_7-6" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup> This however, should be interpreted with caution, as eigenvalues have no upper limit.<sup id="cite_ref-green_9-4" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup><sup id="cite_ref-buy_7-7" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup>
	The eigenvalue can be viewed as a ratio of <i>SS</i><sub>between</sub> and <i>SS</i><sub>within</sub> as in ANOVA when the dependent variable is the discriminant function, and the groups are the levels of the <a href="/wiki/Instrumental_variable" class="mw-redirect" title="Instrumental variable">IV</a><sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag may need clarification or removal of jargon. (April 2012)">clarification needed</span></a></i>&#93;</sup>.<sup id="cite_ref-green_9-5" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> This means that the largest eigenvalue is associated with the first function, the second largest with the second, etc..
</p>
<h2><span class="mw-headline" id="Effect_size">Effect size</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=7" title="Edit section: Effect size">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Some suggest the use of eigenvalues as <a href="/wiki/Effect_size" title="Effect size">effect size</a> measures, however, this is generally not supported.<sup id="cite_ref-green_9-6" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> Instead, the <a href="/wiki/Canonical_correlation" title="Canonical correlation">canonical correlation</a> is the preferred measure of effect size. It is similar to the eigenvalue, but is the square root of the ratio of <i>SS</i><sub>between</sub> and <i>SS</i><sub>total</sub>. It is the correlation between groups and the function.<sup id="cite_ref-green_9-7" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> 
	Another popular measure of effect size is the percent of variance<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag may need clarification or removal of jargon. (April 2012)">clarification needed</span></a></i>&#93;</sup> for each function.  This is calculated by: (<i>λ<sub>x</sub>/Σλ<sub>i</sub></i>) X 100 where <i>λ<sub>x</sub></i> is the eigenvalue for the function and Σ<i>λ<sub>i</sub></i> is the sum of all eigenvalues. This tells us how strong the prediction is for that particular function compared to the others.<sup id="cite_ref-green_9-8" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> 
	Percent correctly classified can also be analyzed as an effect size. The kappa value can describe this while correcting for chance agreement.<sup id="cite_ref-green_9-9" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup><span class="cleanup-needed-content" style="padding-left:0.1em; padding-right:0.1em; color:#595959; border:1px solid #DDD;">Kappa normalizes across all categorizes rather than biased by a significantly good or poorly performing classes.</span><sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="Kappa normalizes across all categorizes rather than biased by a significantly good or poorly performing classes (April 2012)">clarification needed</span></a></i>&#93;</sup><sup id="cite_ref-16" class="reference"><a href="#cite_note-16">&#91;16&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Canonical_discriminant_analysis_for_k_classes">Canonical discriminant analysis for <i>k</i> classes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=8" title="Edit section: Canonical discriminant analysis for k classes">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Canonical discriminant analysis (CDA) finds axes (<i>k</i>&#160;−&#160;1 <a href="/wiki/Canonical_coordinates" title="Canonical coordinates">canonical coordinates</a>, <i>k</i> being the number of classes) that best separate the categories. These linear functions are uncorrelated and define, in effect, an optimal <i>k</i>&#160;−&#160;1 space through the <i>n</i>-dimensional cloud of data that best separates (the projections in that space of) the <i>k</i> groups. See “<a href="#Multiclass_LDA">Multiclass LDA</a>” for details below.
</p>
<h2><span id="Fisher.27s_linear_discriminant"></span><span class="mw-headline" id="Fisher's_linear_discriminant">Fisher's linear discriminant</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=9" title="Edit section: Fisher&#039;s linear discriminant">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The terms <i>Fisher's linear discriminant</i> and <i>LDA</i> are often used interchangeably, although <a href="/wiki/Ronald_A._Fisher" class="mw-redirect" title="Ronald A. Fisher">Fisher's</a> original article<sup id="cite_ref-Fisher:1936_1-1" class="reference"><a href="#cite_note-Fisher:1936-1">&#91;1&#93;</a></sup> actually describes a slightly different discriminant, which does not make some of the assumptions of LDA such as <a href="/wiki/Normal_distribution" title="Normal distribution">normally distributed</a> classes or equal class <a href="/wiki/Covariance" title="Covariance">covariances</a>.
</p><p>Suppose two classes of observations have <a href="/wiki/Mean" title="Mean">means</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {\mu }}_{0},{\vec {\mu }}_{1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {\mu }}_{0},{\vec {\mu }}_{1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7d75b644ba086ca4f0c46c8f8a542ea8659350a4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.946ex; height:2.843ex;" alt="{\vec {\mu }}_{0},{\vec {\mu }}_{1}"/></span> and covariances <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{0},\Sigma _{1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{0},\Sigma _{1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4e7729961ead52abb59f9798f2d88bdb3cc9bced" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:6.499ex; height:2.509ex;" alt="\Sigma _{0},\Sigma _{1}"/></span>. Then the linear combination of features <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\cdot {\vec {x}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\cdot {\vec {x}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b0926e99d00d2252b6772c09f5bc3d4e307511ff" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:4.673ex; height:2.343ex;" alt="{\vec {w}}\cdot {\vec {x}}"/></span> will have <a href="/wiki/Mean" title="Mean">means</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\cdot {\vec {\mu }}_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\cdot {\vec {\mu }}_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b6c82ee601cf9d6ef231b9d1608c541624d07ed0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.545ex; height:2.843ex;" alt="{\vec {w}}\cdot {\vec {\mu }}_{i}"/></span> and <a href="/wiki/Variance" title="Variance">variances</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}^{T}\Sigma _{i}{\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>w</mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msup>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}^{T}\Sigma _{i}{\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6d37bffac7178f9da52d097140e007c9295d8d1c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.195ex; height:3.176ex;" alt="{\vec {w}}^{T}\Sigma _{i}{\vec {w}}"/></span> for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i=0,1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i=0,1}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6b152b69b98c4244dd0c690c8ef74740df7fd343" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.26ex; height:2.509ex;" alt="i=0,1"/></span>. Fisher defined the separation between these two <a href="/wiki/Probability_distribution" title="Probability distribution">distributions</a> to be the ratio of the variance between the classes to the variance within the classes:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle S={\frac {\sigma _{\text{between}}^{2}}{\sigma _{\text{within}}^{2}}}={\frac {({\vec {w}}\cdot {\vec {\mu }}_{1}-{\vec {w}}\cdot {\vec {\mu }}_{0})^{2}}{{\vec {w}}^{T}\Sigma _{1}{\vec {w}}+{\vec {w}}^{T}\Sigma _{0}{\vec {w}}}}={\frac {({\vec {w}}\cdot ({\vec {\mu }}_{1}-{\vec {\mu }}_{0}))^{2}}{{\vec {w}}^{T}(\Sigma _{0}+\Sigma _{1}){\vec {w}}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>S</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <msubsup>
              <mi>&#x03C3;<!-- σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>between</mtext>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>2</mn>
              </mrow>
            </msubsup>
            <msubsup>
              <mi>&#x03C3;<!-- σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>within</mtext>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>2</mn>
              </mrow>
            </msubsup>
          </mfrac>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mo>&#x22C5;<!-- ⋅ --></mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>&#x03BC;<!-- μ --></mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>&#x2212;<!-- − --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mo>&#x22C5;<!-- ⋅ --></mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>&#x03BC;<!-- μ --></mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>0</mn>
                </mrow>
              </msub>
              <msup>
                <mo stretchy="false">)</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msup>
            </mrow>
            <mrow>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>w</mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>T</mi>
                </mrow>
              </msup>
              <msub>
                <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mo>+</mo>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>w</mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>T</mi>
                </mrow>
              </msup>
              <msub>
                <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>0</mn>
                </mrow>
              </msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
            </mrow>
          </mfrac>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mo>&#x22C5;<!-- ⋅ --></mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>&#x03BC;<!-- μ --></mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>&#x2212;<!-- − --></mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>&#x03BC;<!-- μ --></mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>0</mn>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
              <msup>
                <mo stretchy="false">)</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msup>
            </mrow>
            <mrow>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>w</mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>T</mi>
                </mrow>
              </msup>
              <mo stretchy="false">(</mo>
              <msub>
                <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>0</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle S={\frac {\sigma _{\text{between}}^{2}}{\sigma _{\text{within}}^{2}}}={\frac {({\vec {w}}\cdot {\vec {\mu }}_{1}-{\vec {w}}\cdot {\vec {\mu }}_{0})^{2}}{{\vec {w}}^{T}\Sigma _{1}{\vec {w}}+{\vec {w}}^{T}\Sigma _{0}{\vec {w}}}}={\frac {({\vec {w}}\cdot ({\vec {\mu }}_{1}-{\vec {\mu }}_{0}))^{2}}{{\vec {w}}^{T}(\Sigma _{0}+\Sigma _{1}){\vec {w}}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9af8aa035642689bb2004047416b069a15406447" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.171ex; width:54.215ex; height:7.343ex;" alt="S={\frac {\sigma _{\text{between}}^{2}}{\sigma _{\text{within}}^{2}}}={\frac {({\vec {w}}\cdot {\vec {\mu }}_{1}-{\vec {w}}\cdot {\vec {\mu }}_{0})^{2}}{{\vec {w}}^{T}\Sigma _{1}{\vec {w}}+{\vec {w}}^{T}\Sigma _{0}{\vec {w}}}}={\frac {({\vec {w}}\cdot ({\vec {\mu }}_{1}-{\vec {\mu }}_{0}))^{2}}{{\vec {w}}^{T}(\Sigma _{0}+\Sigma _{1}){\vec {w}}}}"/></span></dd></dl>
<p>This measure is, in some sense, a measure of the <a href="/wiki/Signal-to-noise_ratio" title="Signal-to-noise ratio">signal-to-noise ratio</a> for the class labelling. It can be shown that the maximum separation occurs when
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\propto (\Sigma _{0}+\Sigma _{1})^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x221D;<!-- ∝ --></mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>+</mo>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <mo stretchy="false">(</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\propto (\Sigma _{0}+\Sigma _{1})^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ed939999cb7d18ccdd9ebe10120a0abe6f960edf" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:26.771ex; height:3.176ex;" alt="{\vec {w}}\propto (\Sigma _{0}+\Sigma _{1})^{-1}({\vec {\mu }}_{1}-{\vec {\mu }}_{0})"/></span></dd></dl>
<p>When the assumptions of LDA are satisfied, the above equation is equivalent to LDA.
</p><p>Be sure to note that the vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\vec {w}}"/></span> is the <a href="/wiki/Surface_normal" class="mw-redirect" title="Surface normal">normal</a> to the discriminant <a href="/wiki/Hyperplane" title="Hyperplane">hyperplane</a>. As an example, in a two dimensional problem, the line that best divides the two groups is perpendicular to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\vec {w}}"/></span>.
</p><p>Generally, the data points to be discriminated are projected onto <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\vec {w}}"/></span>; then the threshold that best separates the data is chosen from analysis of the one-dimensional distribution. There is no general rule for the threshold. However, if projections of points from both classes exhibit approximately the same distributions, a good choice would be the hyperplane between projections of the two means, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\cdot {\vec {\mu }}_{0}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\cdot {\vec {\mu }}_{0}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7ee2f8982c2052f90d40a2f67adac1057fda6eb5" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.799ex; height:2.843ex;" alt="{\vec {w}}\cdot {\vec {\mu }}_{0}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\cdot {\vec {\mu }}_{1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\cdot {\vec {\mu }}_{1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dd3e65a898afcb1def61eb279b6d36ca2bb39040" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.799ex; height:2.843ex;" alt="{\vec {w}}\cdot {\vec {\mu }}_{1}"/></span>. In this case the parameter c in threshold condition <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}\cdot {\vec {x}}&gt;c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&gt;</mo>
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}\cdot {\vec {x}}&gt;c}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8fe25a6aa1b34af1442727dbb7827294f90102ee" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:8.778ex; height:2.343ex;" alt="{\vec {w}}\cdot {\vec {x}}&gt;c"/></span> can be found explicitly:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c={\vec {w}}\cdot {\frac {1}{2}}({\vec {\mu }}_{0}+{\vec {\mu }}_{1})={\frac {1}{2}}{\vec {\mu }}_{1}^{T}\Sigma _{1}^{-1}{\vec {\mu }}_{1}-{\frac {1}{2}}{\vec {\mu }}_{0}^{T}\Sigma _{0}^{-1}{\vec {\mu }}_{0}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mn>2</mn>
          </mfrac>
        </mrow>
        <mo stretchy="false">(</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>+</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mn>2</mn>
          </mfrac>
        </mrow>
        <msubsup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msubsup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mn>2</mn>
          </mfrac>
        </mrow>
        <msubsup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msubsup>
        <msubsup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msubsup>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>&#x03BC;<!-- μ --></mi>
                <mo stretchy="false">&#x2192;<!-- → --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c={\vec {w}}\cdot {\frac {1}{2}}({\vec {\mu }}_{0}+{\vec {\mu }}_{1})={\frac {1}{2}}{\vec {\mu }}_{1}^{T}\Sigma _{1}^{-1}{\vec {\mu }}_{1}-{\frac {1}{2}}{\vec {\mu }}_{0}^{T}\Sigma _{0}^{-1}{\vec {\mu }}_{0}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b1d58841bc0a577a93fdd1a8456f7ab08168f160" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.838ex; width:47.46ex; height:5.176ex;" alt="{\displaystyle c={\vec {w}}\cdot {\frac {1}{2}}({\vec {\mu }}_{0}+{\vec {\mu }}_{1})={\frac {1}{2}}{\vec {\mu }}_{1}^{T}\Sigma _{1}^{-1}{\vec {\mu }}_{1}-{\frac {1}{2}}{\vec {\mu }}_{0}^{T}\Sigma _{0}^{-1}{\vec {\mu }}_{0}}"/></span>.</dd></dl>
<p><a href="/wiki/Otsu%27s_method" title="Otsu&#39;s method">Otsu's method</a> is related to Fisher's linear discriminant, and was created to binarize the histogram of pixels in a grayscale image by optimally picking the black/white threshold that minimizes intra-class variance and maximizes inter-class variance within/between grayscales assigned to black and white pixel classes.
</p>
<h2><span class="mw-headline" id="Multiclass_LDA">Multiclass LDA</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=10" title="Edit section: Multiclass LDA">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In the case where there are more than two classes, the analysis used in the derivation of the Fisher discriminant can be extended to find a <a href="/wiki/Linear_subspace" title="Linear subspace">subspace</a> which appears to contain all of the class variability.<sup id="cite_ref-garson_17-0" class="reference"><a href="#cite_note-garson-17">&#91;17&#93;</a></sup> This generalization is due to <a href="/wiki/C._R._Rao" title="C. R. Rao">C. R. Rao</a>.<sup id="cite_ref-Rao:1948_18-0" class="reference"><a href="#cite_note-Rao:1948-18">&#91;18&#93;</a></sup> Suppose that each of C classes has a mean <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mu _{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03BC;<!-- μ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mu _{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dea0a0293841cce9eef98b55e53a92b82ae59ee4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:2.201ex; height:2.176ex;" alt="\mu _{i}"/></span> and the same covariance <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9e1f558f53cda207614abdf90162266c70bc5c1e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.678ex; height:2.176ex;" alt="\Sigma "/></span>. Then the scatter between class variability may be defined by the sample covariance of the class means
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{b}={\frac {1}{C}}\sum _{i=1}^{C}(\mu _{i}-\mu )(\mu _{i}-\mu )^{T}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>C</mi>
          </mfrac>
        </mrow>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>C</mi>
          </mrow>
        </munderover>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>&#x03BC;<!-- μ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <mi>&#x03BC;<!-- μ --></mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>&#x03BC;<!-- μ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2212;<!-- − --></mo>
        <mi>&#x03BC;<!-- μ --></mi>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>T</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{b}={\frac {1}{C}}\sum _{i=1}^{C}(\mu _{i}-\mu )(\mu _{i}-\mu )^{T}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fa0c2ba77fb564fa7a73e18e49aec965f3fe91cd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:29.953ex; height:7.343ex;" alt="\Sigma _{b}={\frac {1}{C}}\sum _{i=1}^{C}(\mu _{i}-\mu )(\mu _{i}-\mu )^{T}"/></span></dd></dl>
<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mu }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03BC;<!-- μ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mu }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9fd47b2a39f7a7856952afec1f1db72c67af6161" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:1.402ex; height:2.176ex;" alt="\mu "/></span> is the mean of the class means. The class separation in a direction <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\vec {w}}"/></span> in this case will be given by
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle S={\frac {{\vec {w}}^{T}\Sigma _{b}{\vec {w}}}{{\vec {w}}^{T}\Sigma {\vec {w}}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>S</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>w</mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>T</mi>
                </mrow>
              </msup>
              <msub>
                <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>b</mi>
                </mrow>
              </msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
            </mrow>
            <mrow>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>w</mi>
                      <mo stretchy="false">&#x2192;<!-- → --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>T</mi>
                </mrow>
              </msup>
              <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x2192;<!-- → --></mo>
                  </mover>
                </mrow>
              </mrow>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle S={\frac {{\vec {w}}^{T}\Sigma _{b}{\vec {w}}}{{\vec {w}}^{T}\Sigma {\vec {w}}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/445ab98623e15c9b69c7ed0db334aba5e47b28cc" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:12.767ex; height:6.509ex;" alt="S={\frac {{\vec {w}}^{T}\Sigma _{b}{\vec {w}}}{{\vec {w}}^{T}\Sigma {\vec {w}}}}"/></span></dd></dl>
<p>This means that when <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\vec {w}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>w</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\vec {w}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b6c48cdaecf8d81481ea21b1d0c046bf34b68ec" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.664ex; height:2.343ex;" alt="{\vec {w}}"/></span> is an <a href="/wiki/Eigenvector" class="mw-redirect" title="Eigenvector">eigenvector</a> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma ^{-1}\Sigma _{b}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma ^{-1}\Sigma _{b}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bed8bc5902c52eeda946a8cd494c56b2a793da5e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:6.627ex; height:3.009ex;" alt="\Sigma ^{-1}\Sigma _{b}"/></span> the separation will be equal to the corresponding <a href="/wiki/Eigenvalue" class="mw-redirect" title="Eigenvalue">eigenvalue</a>.
</p><p>If <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma ^{-1}\Sigma _{b}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma ^{-1}\Sigma _{b}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bed8bc5902c52eeda946a8cd494c56b2a793da5e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:6.627ex; height:3.009ex;" alt="\Sigma ^{-1}\Sigma _{b}"/></span> is diagonalizable, the variability between features will be contained in the subspace spanned by the eigenvectors corresponding to the <i>C</i>&#160;−&#160;1 largest eigenvalues (since <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{b}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{b}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e155673de62e59fff0442b3c28f42ff0113cb222" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.616ex; height:2.509ex;" alt="\Sigma _{b}"/></span> is of rank <i>C</i>&#160;−&#160;1 at most). These eigenvectors are primarily used in feature reduction, as in PCA. The eigenvectors corresponding to the smaller eigenvalues will tend to be very sensitive to the exact choice of training data, and it is often necessary to use regularisation as described in the next section.
</p><p>If classification is required, instead of <a href="/wiki/Dimension_reduction" class="mw-redirect" title="Dimension reduction">dimension reduction</a>, there are a number of alternative techniques available. For instance, the classes may be partitioned, and a standard Fisher discriminant or LDA used to classify each partition. A common example of this is "one against the rest" where the points from one class are put in one group, and everything else in the other, and then LDA applied. This will result in C classifiers, whose results are combined. Another common
method is pairwise classification, where a new classifier is created for each pair of classes (giving <i>C</i>(<i>C</i>&#160;−&#160;1)/2 classifiers in total), with the individual classifiers combined to produce a final classification.
</p>
<h2><span class="mw-headline" id="Incremental_LDA">Incremental LDA</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=11" title="Edit section: Incremental LDA">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The typical implementation of the LDA technique requires that all the samples are available in advance. However,  there are situations where the entire data set is not available and the input data are observed as a stream. In this case, it is desirable for the LDA feature extraction to have the ability to update the computed LDA features by observing the new samples without running the algorithm on the whole data set. For example, in many real-time applications such as mobile robotics or on-line face recognition, it is important to update the extracted LDA features as soon as new observations are available. An LDA feature extraction technique that can update the LDA features by simply observing new samples is an <i>incremental LDA algorithm</i>, and this idea has been extensively studied over the last two decades.<sup id="cite_ref-:0_19-0" class="reference"><a href="#cite_note-:0-19">&#91;19&#93;</a></sup> Chatterjee and Roychowdhury proposed an incremental self-organized LDA algorithm for updating the LDA features.<sup id="cite_ref-:1_20-0" class="reference"><a href="#cite_note-:1-20">&#91;20&#93;</a></sup> In other work, Demir and Ozmehmet proposed online local learning algorithms for updating LDA features incrementally using error-correcting and the Hebbian learning rules.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21">&#91;21&#93;</a></sup> Later, Aliyari <i>et a</i>l. derived fast incremental algorithms to update the LDA features by observing the new samples.<sup id="cite_ref-:0_19-1" class="reference"><a href="#cite_note-:0-19">&#91;19&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Practical_use">Practical use</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=12" title="Edit section: Practical use">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In practice, the class means and covariances are not known. They can, however, be estimated from the training set. Either the <a href="/wiki/Maximum_likelihood_estimation" title="Maximum likelihood estimation">maximum likelihood estimate</a> or the <a href="/wiki/Maximum_a_posteriori" class="mw-redirect" title="Maximum a posteriori">maximum a posteriori</a> estimate may be used in place of the exact value in the above equations. Although the estimates of the covariance may be considered optimal in some sense, this does not mean that the resulting discriminant obtained by substituting these values is optimal in any sense, even if the assumption of normally distributed classes is correct.
</p><p>Another complication in applying LDA and Fisher's discriminant to real data occurs when the number of measurements of each sample (i.e., the dimensionality of each data vector) exceeds the number of samples in each class.<sup id="cite_ref-Martinez:2001_4-1" class="reference"><a href="#cite_note-Martinez:2001-4">&#91;4&#93;</a></sup> In this case, the covariance estimates do not have full rank, and so cannot be inverted. There are a number of ways to deal with this. One is to use a <a href="/wiki/Pseudo_inverse" class="mw-redirect" title="Pseudo inverse">pseudo inverse</a> instead of the usual matrix inverse in the above formulae. However, better numeric stability may be achieved by first projecting the problem onto the subspace spanned by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma _{b}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma _{b}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e155673de62e59fff0442b3c28f42ff0113cb222" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.616ex; height:2.509ex;" alt="\Sigma _{b}"/></span>.<sup id="cite_ref-22" class="reference"><a href="#cite_note-22">&#91;22&#93;</a></sup>
Another strategy to deal with small sample size is to use a <a href="/wiki/Shrinkage_estimator" class="mw-redirect" title="Shrinkage estimator">shrinkage estimator</a> of the covariance matrix, which
can be expressed mathematically as
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Sigma =(1-\lambda )\Sigma +\lambda I\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
        <mo>=</mo>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mo>&#x2212;<!-- − --></mo>
        <mi>&#x03BB;<!-- λ --></mi>
        <mo stretchy="false">)</mo>
        <mi mathvariant="normal">&#x03A3;<!-- Σ --></mi>
        <mo>+</mo>
        <mi>&#x03BB;<!-- λ --></mi>
        <mi>I</mi>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Sigma =(1-\lambda )\Sigma +\lambda I\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/64bc6ee831988f828bf12487ce2d62a4fc45e2ad" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:19.376ex; height:2.843ex;" alt="\Sigma =(1-\lambda )\Sigma +\lambda I\,"/></span></dd></dl>
<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle I}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>I</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle I}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/535ea7fc4134a31cbe2251d9d3511374bc41be9f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.172ex; height:2.176ex;" alt="I"/></span> is the identity matrix, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \lambda }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03BB;<!-- λ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \lambda }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;" alt="\lambda "/></span> is the <i>shrinkage intensity</i> or <i>regularisation parameter</i>.
This leads to the framework of regularized discriminant analysis<sup id="cite_ref-Friedman:2001_23-0" class="reference"><a href="#cite_note-Friedman:2001-23">&#91;23&#93;</a></sup> or shrinkage discriminant analysis.<sup id="cite_ref-24" class="reference"><a href="#cite_note-24">&#91;24&#93;</a></sup>
</p><p>Also, in many practical cases linear discriminants are not suitable. LDA and Fisher's discriminant can be extended for use in non-linear classification via the <a href="/wiki/Kernel_trick" class="mw-redirect" title="Kernel trick">kernel trick</a>. Here, the original observations are effectively mapped into a higher dimensional non-linear space. Linear classification in this non-linear space is then equivalent to non-linear classification in the original space. The most commonly used example of this is the <a href="/wiki/Kernel_Fisher_discriminant_analysis" title="Kernel Fisher discriminant analysis">kernel Fisher discriminant</a>.
</p><p>LDA can be generalized to <a href="/wiki/Multiple_discriminant_analysis" title="Multiple discriminant analysis">multiple discriminant analysis</a>, where <i>c</i> becomes a <a href="/wiki/Categorical_variable" title="Categorical variable">categorical variable</a> with <i>N</i> possible states, instead of only two. Analogously, if the class-conditional densities <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\vec {x}}\mid c=i)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>c</mi>
        <mo>=</mo>
        <mi>i</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\vec {x}}\mid c=i)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ebdf44d9590830d518013f4dc56163d79940f530" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:11.243ex; height:2.843ex;" alt="{\displaystyle p({\vec {x}}\mid c=i)}"/></span> are normal with shared covariances, the <a href="/wiki/Sufficient_statistic" title="Sufficient statistic">sufficient statistic</a> for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle P(c\mid {\vec {x}})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>c</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x2192;<!-- → --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(c\mid {\vec {x}})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/09592196975f053db376553a76bd452b5b246455" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.828ex; height:2.843ex;" alt="{\displaystyle P(c\mid {\vec {x}})}"/></span> are the values of <i>N</i> projections, which are the <a href="/wiki/Linear_subspace" title="Linear subspace">subspace</a> spanned by the <i>N</i> means, <a href="/wiki/Affine_transformation" title="Affine transformation">affine projected</a> by the inverse covariance matrix. These projections can be found by solving a <a href="/wiki/Eigenvalue,_eigenvector_and_eigenspace#generalized_eigenvalue_problem" class="mw-redirect" title="Eigenvalue, eigenvector and eigenspace">generalized eigenvalue problem</a>, where the numerator is the covariance matrix formed by treating the means as the samples, and the denominator is the shared covariance matrix. See “<a href="#Multiclass_LDA">Multiclass LDA</a>” above for details.
</p>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=13" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In addition to the examples given below, LDA is applied in <a href="/wiki/Positioning_(marketing)" title="Positioning (marketing)">positioning</a> and <a href="/wiki/Product_management" title="Product management">product management</a>.
</p>
<h3><span class="mw-headline" id="Bankruptcy_prediction">Bankruptcy prediction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=14" title="Edit section: Bankruptcy prediction">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In <a href="/wiki/Bankruptcy_prediction" title="Bankruptcy prediction">bankruptcy prediction</a> based on accounting ratios and other financial variables, linear discriminant analysis was the first statistical method applied to systematically explain which firms entered bankruptcy vs. survived. Despite limitations including known nonconformance of accounting ratios to the normal distribution assumptions of LDA, <a href="/wiki/Edward_Altman" title="Edward Altman">Edward Altman</a>'s <a href="/wiki/Z-Score_Financial_Analysis_Tool" class="mw-redirect" title="Z-Score Financial Analysis Tool">1968 model</a> is still a leading model in practical applications.
</p>
<h3><span class="mw-headline" id="Face_recognition">Face recognition</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=15" title="Edit section: Face recognition">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In computerised <a href="/wiki/Facial_recognition_system" title="Facial recognition system">face recognition</a>, each face is represented by a large number of pixel values. Linear discriminant analysis is primarily used here to reduce the number of features to a more manageable number before classification. Each of the new dimensions is a linear combination of pixel values, which form a template. The linear combinations obtained using Fisher's linear discriminant are called <i>Fisher faces</i>, while those obtained using the related <a href="/wiki/Principal_component_analysis" title="Principal component analysis">principal component analysis</a> are called <i><a href="/wiki/Eigenfaces" class="mw-redirect" title="Eigenfaces">eigenfaces</a></i>.
</p>
<h3><span class="mw-headline" id="Marketing">Marketing</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=16" title="Edit section: Marketing">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In <a href="/wiki/Marketing" title="Marketing">marketing</a>, discriminant analysis was once often used to determine the factors which distinguish different types of customers and/or products on the basis of surveys or other forms of collected data. <a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a> or other methods are now more commonly used. The use of discriminant analysis in marketing can be described by the following steps:
</p>
<ol><li>Formulate the problem and gather data—Identify the <a href="/wiki/Social_salience" title="Social salience">salient</a> attributes consumers use to evaluate products in this category—Use <a href="/wiki/Quantitative_marketing_research" title="Quantitative marketing research">quantitative marketing research</a> techniques (such as <a href="/wiki/Statistical_survey" class="mw-redirect" title="Statistical survey">surveys</a>) to collect data from a sample of potential customers concerning their ratings of all the product attributes. The data collection stage is usually done by marketing research professionals. Survey questions ask the respondent to rate a product from one to five (or 1 to 7, or 1 to 10) on a range of attributes chosen by the researcher. Anywhere from five to twenty attributes are chosen. They could include things like: ease of use, weight, accuracy, durability, colourfulness, price, or size. The attributes chosen will vary depending on the product being studied. The same question is asked about all the products in the study. The data for multiple products is codified and input into a statistical program such as <a href="/wiki/R_language" class="mw-redirect" title="R language">R</a>, <a href="/wiki/SPSS" title="SPSS">SPSS</a> or <a href="/wiki/SAS_programming_language" class="mw-redirect" title="SAS programming language">SAS</a>. (This step is the same as in Factor analysis).</li>
<li>Estimate the Discriminant Function Coefficients and determine the statistical significance and validity—Choose the appropriate discriminant analysis method. The direct method involves estimating the discriminant function so that all the predictors are assessed simultaneously. The stepwise method enters the predictors sequentially. The two-group method should be used when the dependent variable has two categories or states. The multiple discriminant method is used when the dependent variable has three or more categorical states. Use <a href="/wiki/Wilks%27_lambda_distribution" class="mw-redirect" title="Wilks&#39; lambda distribution">Wilks's Lambda</a> to test for significance in SPSS or F stat in SAS. The most common method used to test validity is to split the sample into an estimation or analysis sample, and a validation or holdout sample. The estimation sample is used in constructing the discriminant function. The validation sample is used to construct a classification matrix which contains the number of correctly classified and incorrectly classified cases. The percentage of correctly classified cases is called the <i>hit ratio</i>.</li>
<li>Plot the results on a two dimensional map, define the dimensions, and interpret the results. The statistical program (or a related module) will map the results. The map will plot each product (usually in two-dimensional space). The distance of products to each other indicate either how different they are. The dimensions must be labelled by the researcher. This requires subjective judgement and is often very challenging. See <a href="/wiki/Perceptual_mapping" title="Perceptual mapping">perceptual mapping</a>.</li></ol>
<h3><span class="mw-headline" id="Biomedical_studies">Biomedical studies</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=17" title="Edit section: Biomedical studies">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The main application of discriminant analysis in medicine is the assessment of severity state of a patient and prognosis of disease outcome. For example, during retrospective analysis, patients are divided into groups according to severity of disease – mild, moderate and severe form. Then results of clinical and laboratory analyses are studied in order to reveal variables which are statistically different in studied groups. Using these variables, discriminant functions are built which help to objectively classify disease in a future patient into mild, moderate or severe form.
</p><p>In biology, similar principles are used in order to classify and define groups of different biological objects, for example, to define phage types of Salmonella enteritidis based on Fourier transform infrared spectra,<sup id="cite_ref-25" class="reference"><a href="#cite_note-25">&#91;25&#93;</a></sup> to detect animal source of Escherichia coli studying its virulence factors<sup id="cite_ref-26" class="reference"><a href="#cite_note-26">&#91;26&#93;</a></sup> etc.
</p>
<h3><span class="mw-headline" id="Earth_science">Earth science</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=18" title="Edit section: Earth science">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>This method can be used to separate the alteration zones. For example, when different data from various zones are available, discriminant analysis can find the pattern within the data and classify it effectively.<sup id="cite_ref-27" class="reference"><a href="#cite_note-27">&#91;27&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Comparison_to_logistic_regression">Comparison to logistic regression</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=19" title="Edit section: Comparison to logistic regression">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Discriminant function analysis is very similar to <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>, and both can be used to answer the same research questions.<sup id="cite_ref-green_9-10" class="reference"><a href="#cite_note-green-9">&#91;9&#93;</a></sup> Logistic regression does not have as many assumptions and restrictions as discriminant analysis. However, when discriminant analysis’ assumptions are met, it is more powerful than logistic regression.<sup id="cite_ref-28" class="reference"><a href="#cite_note-28">&#91;28&#93;</a></sup> Unlike logistic regression, discriminant analysis can be used with small sample sizes. It has been shown that when sample sizes are equal, and homogeneity of variance/covariance holds, discriminant analysis is more accurate.<sup id="cite_ref-buy_7-8" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup> With all this being considered, logistic regression has become the common choice, since the assumptions of discriminant analysis are rarely met.<sup id="cite_ref-cohen_8-1" class="reference"><a href="#cite_note-cohen-8">&#91;8&#93;</a></sup><sup id="cite_ref-buy_7-9" class="reference"><a href="#cite_note-buy-7">&#91;7&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Linear_discriminant_in_high_dimension">Linear discriminant in high dimension</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=20" title="Edit section: Linear discriminant in high dimension">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Geometric anomalities in high dimension lead to the well-known <a href="/wiki/Curse_of_dimensionality" title="Curse of dimensionality">curse of dimensionality</a>. Nevertheless, proper utilization of <a href="/wiki/Concentration_of_measure" title="Concentration of measure">concentration of measure</a> phenomena can make computation easier.<sup id="cite_ref-29" class="reference"><a href="#cite_note-29">&#91;29&#93;</a></sup> An important case of these  <a href="/wiki/Curse_of_dimensionality#Blessing_of_dimensionality" title="Curse of dimensionality"><i>blessing of dimensionality</i></a> phenomena was highlighted by Donoho and Tanner: if a sample is essentially high-dimensional then each point can be separated from the rest of the sample by linear inequality, with high probability, even for exponentially large samples.<sup id="cite_ref-30" class="reference"><a href="#cite_note-30">&#91;30&#93;</a></sup> These linear inequalities can be selected in the standard (Fisher's) form of the linear discriminant for a rich family of probability distribution.<sup id="cite_ref-31" class="reference"><a href="#cite_note-31">&#91;31&#93;</a></sup> In particular, such theorems are proven for <a href="/wiki/Logarithmically_concave_measure" title="Logarithmically concave measure">log-concave</a> distributions including <a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">multidimensional normal distribution</a> (the proof is based on the concentration inequalities for long-concave measures<sup id="cite_ref-32" class="reference"><a href="#cite_note-32">&#91;32&#93;</a></sup>) and for product measures on a multidimensional cube (this is proven using <a href="/wiki/Talagrand%27s_concentration_inequality" title="Talagrand&#39;s concentration inequality">Talagrand's concentration inequality</a> for product probability spaces). Data separability by classical linear discriminants simplifies the problem of error correction for <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> systems in high dimension..<sup id="cite_ref-GMT2019_33-0" class="reference"><a href="#cite_note-GMT2019-33">&#91;33&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=21" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Data_mining" title="Data mining">Data mining</a></li>
<li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision tree learning</a></li>
<li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>
<li><a href="/wiki/Kernel_Fisher_discriminant_analysis" title="Kernel Fisher discriminant analysis">Kernel Fisher discriminant analysis</a></li>
<li><a href="/wiki/Logit" title="Logit">Logit</a> (for <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>)</li>
<li><a href="/wiki/Multiple_discriminant_analysis" title="Multiple discriminant analysis">Multiple discriminant analysis</a></li>
<li><a href="/wiki/Multidimensional_scaling" title="Multidimensional scaling">Multidimensional scaling</a></li>
<li><a href="/wiki/Pattern_recognition" title="Pattern recognition">Pattern recognition</a></li>
<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>
<li><a href="/wiki/Preference_regression" title="Preference regression">Preference regression</a></li>
<li><a href="/wiki/Quadratic_classifier" title="Quadratic classifier">Quadratic classifier</a></li>
<li><a href="/wiki/Statistical_classification" title="Statistical classification">Statistical classification</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=22" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-Fisher:1936-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-Fisher:1936_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Fisher:1936_1-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal"><a href="/wiki/Ronald_Fisher" title="Ronald Fisher">Fisher, R. A.</a> (1936). <a rel="nofollow" class="external text" href="https://digital.library.adelaide.edu.au/dspace/bitstream/2440/15227/1/138.pdf">"The Use of Multiple Measurements in Taxonomic Problems"</a> <span class="cs1-format">(PDF)</span>. <i><a href="/wiki/Annals_of_Eugenics" class="mw-redirect" title="Annals of Eugenics">Annals of Eugenics</a></i>. <b>7</b> (2): 179–188. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1111%2Fj.1469-1809.1936.tb02137.x">10.1111/j.1469-1809.1936.tb02137.x</a>. <a href="/wiki/Handle_System" title="Handle System">hdl</a>:<a rel="nofollow" class="external text" href="//hdl.handle.net/2440%2F15227">2440/15227</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annals+of+Eugenics&amp;rft.atitle=The+Use+of+Multiple+Measurements+in+Taxonomic+Problems&amp;rft.volume=7&amp;rft.issue=2&amp;rft.pages=179-188&amp;rft.date=1936&amp;rft_id=info%3Ahdl%2F2440%2F15227&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1469-1809.1936.tb02137.x&amp;rft.aulast=Fisher&amp;rft.aufirst=R.+A.&amp;rft_id=https%3A%2F%2Fdigital.library.adelaide.edu.au%2Fdspace%2Fbitstream%2F2440%2F15227%2F1%2F138.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r935243608">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-McLachlan:2004-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-McLachlan:2004_2-0">^</a></b></span> <span class="reference-text"><cite class="citation book">McLachlan, G. J. (2004). <i>Discriminant Analysis and Statistical Pattern Recognition</i>. Wiley Interscience. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-471-69115-0" title="Special:BookSources/978-0-471-69115-0"><bdi>978-0-471-69115-0</bdi></a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a>&#160;<a rel="nofollow" class="external text" href="//www.ams.org/mathscinet-getitem?mr=1190469">1190469</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Discriminant+Analysis+and+Statistical+Pattern+Recognition&amp;rft.pub=Wiley+Interscience&amp;rft.date=2004&amp;rft.isbn=978-0-471-69115-0&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D1190469&amp;rft.aulast=McLachlan&amp;rft.aufirst=G.+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text">Analyzing Quantitative Data: An Introduction for Social Researchers, Debra Wetcher-Hendricks, p.288</span>
</li>
<li id="cite_note-Martinez:2001-4"><span class="mw-cite-backlink">^ <a href="#cite_ref-Martinez:2001_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Martinez:2001_4-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Martinez, A. M.; Kak, A. C. (2001). <a rel="nofollow" class="external text" href="http://www.ece.osu.edu/~aleix/pami01.pdf">"PCA versus LDA"</a> <span class="cs1-format">(PDF)</span>. <i><a href="/wiki/IEEE_Transactions_on_Pattern_Analysis_and_Machine_Intelligence" title="IEEE Transactions on Pattern Analysis and Machine Intelligence">IEEE Transactions on Pattern Analysis and Machine Intelligence</a></i>. <b>23</b> (=2): 228–233. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F34.908974">10.1109/34.908974</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence&amp;rft.atitle=PCA+versus+LDA&amp;rft.volume=23&amp;rft.issue=%3D2&amp;rft.pages=228-233&amp;rft.date=2001&amp;rft_id=info%3Adoi%2F10.1109%2F34.908974&amp;rft.aulast=Martinez&amp;rft.aufirst=A.+M.&amp;rft.au=Kak%2C+A.+C.&amp;rft_id=http%3A%2F%2Fwww.ece.osu.edu%2F~aleix%2Fpami01.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-Abdi_2007-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-Abdi_2007_5-0">^</a></b></span> <span class="reference-text">Abdi, H. (2007) <a rel="nofollow" class="external text" href="http://www.utdallas.edu/~herve/Abdi-DCA2007-pretty.pdf">"Discriminant correspondence analysis."</a> In: N.J. Salkind (Ed.): <i>Encyclopedia of Measurement and Statistic</i>. Thousand Oaks (CA): Sage. pp.&#160;270–275.</span>
</li>
<li id="cite_note-Perriere_2003-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-Perriere_2003_6-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Perriere, G.; Thioulouse, J. (2003). "Use of Correspondence Discriminant Analysis to predict the subcellular location of bacterial proteins". <i>Computer Methods and Programs in Biomedicine</i>. <b>70</b> (2): 99–105. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fs0169-2607%2802%2900011-1">10.1016/s0169-2607(02)00011-1</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/12507786">12507786</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computer+Methods+and+Programs+in+Biomedicine&amp;rft.atitle=Use+of+Correspondence+Discriminant+Analysis+to+predict+the+subcellular+location+of+bacterial+proteins&amp;rft.volume=70&amp;rft.issue=2&amp;rft.pages=99-105&amp;rft.date=2003&amp;rft_id=info%3Adoi%2F10.1016%2Fs0169-2607%2802%2900011-1&amp;rft_id=info%3Apmid%2F12507786&amp;rft.aulast=Perriere&amp;rft.aufirst=G.&amp;rft.au=Thioulouse%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-buy-7"><span class="mw-cite-backlink">^ <a href="#cite_ref-buy_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-buy_7-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-buy_7-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-buy_7-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-buy_7-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-buy_7-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-buy_7-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-buy_7-7"><sup><i><b>h</b></i></sup></a> <a href="#cite_ref-buy_7-8"><sup><i><b>i</b></i></sup></a> <a href="#cite_ref-buy_7-9"><sup><i><b>j</b></i></sup></a></span> <span class="reference-text">BÖKEOĞLU ÇOKLUK, Ö, &amp; BÜYÜKÖZTÜRK, Ş. (2008). <a rel="nofollow" class="external text" href="https://pdfs.semanticscholar.org/76b1/c725b926d91db6eb52e83ab1596e6eb115ca.pdf">Discriminant function analysis: Concept and application</a>. Eğitim araştırmaları dergisi, (33), 73-92.</span>
</li>
<li id="cite_note-cohen-8"><span class="mw-cite-backlink">^ <a href="#cite_ref-cohen_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-cohen_8-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Cohen et al. Applied Multiple Regression/Correlation Analysis for the Behavioural Sciences 3rd ed. (2003). Taylor &amp; Francis Group.</span>
</li>
<li id="cite_note-green-9"><span class="mw-cite-backlink">^ <a href="#cite_ref-green_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-green_9-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-green_9-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-green_9-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-green_9-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-green_9-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-green_9-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-green_9-7"><sup><i><b>h</b></i></sup></a> <a href="#cite_ref-green_9-8"><sup><i><b>i</b></i></sup></a> <a href="#cite_ref-green_9-9"><sup><i><b>j</b></i></sup></a> <a href="#cite_ref-green_9-10"><sup><i><b>k</b></i></sup></a></span> <span class="reference-text">Green, S.B. Salkind, N. J. &amp; Akey, T. M. (2008). <a rel="nofollow" class="external text" href="https://www.tandfonline.com/doi/pdf/10.1198/tas.2005.s139">Using SPSS for Windows and Macintosh: Analyzing and understanding data</a>. New Jersey: Prentice Hall.</span>
</li>
<li id="cite_note-Venables:2002-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-Venables:2002_10-0">^</a></b></span> <span class="reference-text"><cite class="citation book">Venables, W. N.; <a href="/wiki/Brian_Ripley" class="mw-redirect" title="Brian Ripley">Ripley, B. D.</a> (2002). <i>Modern Applied Statistics with S</i> (4th ed.). Springer Verlag. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-387-95457-8" title="Special:BookSources/978-0-387-95457-8"><bdi>978-0-387-95457-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Modern+Applied+Statistics+with+S&amp;rft.edition=4th&amp;rft.pub=Springer+Verlag&amp;rft.date=2002&amp;rft.isbn=978-0-387-95457-8&amp;rft.aulast=Venables&amp;rft.aufirst=W.+N.&amp;rft.au=Ripley%2C+B.+D.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text">Lachenbruch, P. A. (1975). <i>Discriminant analysis</i>. NY: Hafner</span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text">Klecka, William R. (1980). <i>Discriminant analysis</i>. Quantitative Applications in the Social Sciences Series, No. 19. Thousand Oaks, CA: Sage Publications.</span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text">Hardle, W., Simar, L. (2007). <i>Applied Multivariate Statistical Analysis</i>. Springer Berlin Heidelberg. pp.&#160;289–303.</span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text">Garson, G. D. (2008). Discriminant function analysis. <a rel="nofollow" class="external free" href="https://web.archive.org/web/20080312065328/http://www2.chass.ncsu.edu/garson/pA765/discrim.htm">https://web.archive.org/web/20080312065328/http://www2.chass.ncsu.edu/garson/pA765/discrim.htm</a>.</span>
</li>
<li id="cite_note-har-15"><span class="mw-cite-backlink">^ <a href="#cite_ref-har_15-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-har_15-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-har_15-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text">Hardle, W., Simar, L. (2007). <i><a rel="nofollow" class="external text" href="https://pdfs.semanticscholar.org/e49a/3ed1560a0979f5ca0146c1aca7ef98e64af7.pdf">Applied Multivariate Statistical Analysis</a></i>. Springer Berlin Heidelberg. pp. 289-303.</span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><cite class="citation journal">Israel, Steven A. (June 2006). "Performance Metrics: How and When". <i>Geocarto International</i>. <b>21</b> (2): 23–32. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1080%2F10106040608542380">10.1080/10106040608542380</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1010-6049">1010-6049</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Geocarto+International&amp;rft.atitle=Performance+Metrics%3A+How+and+When&amp;rft.volume=21&amp;rft.issue=2&amp;rft.pages=23-32&amp;rft.date=2006-06&amp;rft_id=info%3Adoi%2F10.1080%2F10106040608542380&amp;rft.issn=1010-6049&amp;rft.aulast=Israel&amp;rft.aufirst=Steven+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-garson-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-garson_17-0">^</a></b></span> <span class="reference-text">Garson, G. D. (2008). Discriminant function analysis. <cite class="citation web"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20080312065328/http://www2.chass.ncsu.edu/garson/pA765/discrim.htm">"Archived copy"</a>. Archived from <a rel="nofollow" class="external text" href="http://www2.chass.ncsu.edu/garson/pa765/discrim.htm">the original</a> on 2008-03-12<span class="reference-accessdate">. Retrieved <span class="nowrap">2008-03-04</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Archived+copy&amp;rft_id=http%3A%2F%2Fwww2.chass.ncsu.edu%2Fgarson%2Fpa765%2Fdiscrim.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: archived copy as title (<a href="/wiki/Category:CS1_maint:_archived_copy_as_title" title="Category:CS1 maint: archived copy as title">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/> .</span>
</li>
<li id="cite_note-Rao:1948-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-Rao:1948_18-0">^</a></b></span> <span class="reference-text"><cite class="citation journal"><a href="/wiki/Calyampudi_Radhakrishna_Rao" class="mw-redirect" title="Calyampudi Radhakrishna Rao">Rao, R. C.</a> (1948). "The utilization of multiple measurements in problems of biological classification". <i>Journal of the Royal Statistical Society, Series B</i>. <b>10</b> (2): 159–203. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/2983775">2983775</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Royal+Statistical+Society%2C+Series+B&amp;rft.atitle=The+utilization+of+multiple+measurements+in+problems+of+biological+classification&amp;rft.volume=10&amp;rft.issue=2&amp;rft.pages=159-203&amp;rft.date=1948&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2983775&amp;rft.aulast=Rao&amp;rft.aufirst=R.+C.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-:0-19"><span class="mw-cite-backlink">^ <a href="#cite_ref-:0_19-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_19-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Aliyari Ghassabeh, Youness; Rudzicz, Frank; Moghaddam, Hamid Abrishami (2015-06-01). "Fast incremental LDA feature extraction". <i>Pattern Recognition</i>. <b>48</b> (6): 1999–2012. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.patcog.2014.12.012">10.1016/j.patcog.2014.12.012</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Pattern+Recognition&amp;rft.atitle=Fast+incremental+LDA+feature+extraction&amp;rft.volume=48&amp;rft.issue=6&amp;rft.pages=1999-2012&amp;rft.date=2015-06-01&amp;rft_id=info%3Adoi%2F10.1016%2Fj.patcog.2014.12.012&amp;rft.aulast=Aliyari+Ghassabeh&amp;rft.aufirst=Youness&amp;rft.au=Rudzicz%2C+Frank&amp;rft.au=Moghaddam%2C+Hamid+Abrishami&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-:1-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-:1_20-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Chatterjee, C.; Roychowdhury, V.P. (1997-05-01). "On self-organizing algorithms and networks for class-separability features". <i>IEEE Transactions on Neural Networks</i>. <b>8</b> (3): 663–678. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F72.572105">10.1109/72.572105</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1045-9227">1045-9227</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/18255669">18255669</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Neural+Networks&amp;rft.atitle=On+self-organizing+algorithms+and+networks+for+class-separability+features&amp;rft.volume=8&amp;rft.issue=3&amp;rft.pages=663-678&amp;rft.date=1997-05-01&amp;rft.issn=1045-9227&amp;rft_id=info%3Apmid%2F18255669&amp;rft_id=info%3Adoi%2F10.1109%2F72.572105&amp;rft.aulast=Chatterjee&amp;rft.aufirst=C.&amp;rft.au=Roychowdhury%2C+V.P.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><cite class="citation journal">Demir, G. K.; Ozmehmet, K. (2005-03-01). "Online Local Learning Algorithms for Linear Discriminant Analysis". <i>Pattern Recogn. Lett</i>. <b>26</b> (4): 421–431. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.patrec.2004.08.005">10.1016/j.patrec.2004.08.005</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0167-8655">0167-8655</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Pattern+Recogn.+Lett.&amp;rft.atitle=Online+Local+Learning+Algorithms+for+Linear+Discriminant+Analysis&amp;rft.volume=26&amp;rft.issue=4&amp;rft.pages=421-431&amp;rft.date=2005-03-01&amp;rft_id=info%3Adoi%2F10.1016%2Fj.patrec.2004.08.005&amp;rft.issn=0167-8655&amp;rft.aulast=Demir&amp;rft.aufirst=G.+K.&amp;rft.au=Ozmehmet%2C+K.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><cite class="citation journal">Yu, H.; Yang, J. (2001). "A direct LDA algorithm for high-dimensional data — with application to face recognition". <i>Pattern Recognition</i>. <b>34</b> (10): 2067–2069. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.3507">10.1.1.70.3507</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fs0031-3203%2800%2900162-x">10.1016/s0031-3203(00)00162-x</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Pattern+Recognition&amp;rft.atitle=A+direct+LDA+algorithm+for+high-dimensional+data+%E2%80%94+with+application+to+face+recognition&amp;rft.volume=34&amp;rft.issue=10&amp;rft.pages=2067-2069&amp;rft.date=2001&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.70.3507&amp;rft_id=info%3Adoi%2F10.1016%2Fs0031-3203%2800%2900162-x&amp;rft.aulast=Yu&amp;rft.aufirst=H.&amp;rft.au=Yang%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-Friedman:2001-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-Friedman:2001_23-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Friedman, J. H. (1989). <a rel="nofollow" class="external text" href="http://www.slac.stanford.edu/cgi-wrap/getdoc/slac-pub-4389.pdf">"Regularized Discriminant Analysis"</a> <span class="cs1-format">(PDF)</span>. <i><a href="/wiki/Journal_of_the_American_Statistical_Association" title="Journal of the American Statistical Association">Journal of the American Statistical Association</a></i>. <b>84</b> (405): 165–175. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.382.2682">10.1.1.382.2682</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.2307%2F2289860">10.2307/2289860</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/2289860">2289860</a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a>&#160;<a rel="nofollow" class="external text" href="//www.ams.org/mathscinet-getitem?mr=0999675">0999675</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Regularized+Discriminant+Analysis&amp;rft.volume=84&amp;rft.issue=405&amp;rft.pages=165-175&amp;rft.date=1989&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.382.2682&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D0999675&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2289860&amp;rft_id=info%3Adoi%2F10.2307%2F2289860&amp;rft.aulast=Friedman&amp;rft.aufirst=J.+H.&amp;rft_id=http%3A%2F%2Fwww.slac.stanford.edu%2Fcgi-wrap%2Fgetdoc%2Fslac-pub-4389.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><cite class="citation journal">Ahdesmäki, M.; Strimmer, K. (2010). "Feature selection in omics prediction problems using cat scores and false nondiscovery rate control". <i>Annals of Applied Statistics</i>. <b>4</b> (1): 503–519. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/0903.2003">0903.2003</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1214%2F09-aoas277">10.1214/09-aoas277</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annals+of+Applied+Statistics&amp;rft.atitle=Feature+selection+in+omics+prediction+problems+using+cat+scores+and+false+nondiscovery+rate+control&amp;rft.volume=4&amp;rft.issue=1&amp;rft.pages=503-519&amp;rft.date=2010&amp;rft_id=info%3Aarxiv%2F0903.2003&amp;rft_id=info%3Adoi%2F10.1214%2F09-aoas277&amp;rft.aulast=Ahdesm%C3%A4ki&amp;rft.aufirst=M.&amp;rft.au=Strimmer%2C+K.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><cite class="citation journal">Preisner, O; Guiomar, R; Machado, J; Menezes, JC; Lopes, JA (2010). <a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2876429">"Application of Fourier transform infrared spectroscopy and chemometrics for differentiation of Salmonella enterica serovar Enteritidis phage types"</a>. <i>Appl Environ Microbiol</i>. <b>76</b> (11): 3538–3544. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1128%2Faem.01589-09">10.1128/aem.01589-09</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2876429">2876429</a></span>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/20363777">20363777</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Appl+Environ+Microbiol&amp;rft.atitle=Application+of+Fourier+transform+infrared+spectroscopy+and+chemometrics+for+differentiation+of+Salmonella+enterica+serovar+Enteritidis+phage+types&amp;rft.volume=76&amp;rft.issue=11&amp;rft.pages=3538-3544&amp;rft.date=2010&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2876429&amp;rft_id=info%3Apmid%2F20363777&amp;rft_id=info%3Adoi%2F10.1128%2Faem.01589-09&amp;rft.aulast=Preisner&amp;rft.aufirst=O&amp;rft.au=Guiomar%2C+R&amp;rft.au=Machado%2C+J&amp;rft.au=Menezes%2C+JC&amp;rft.au=Lopes%2C+JA&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2876429&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite class="citation journal">David, DE; Lynne, AM; Han, J; Foley, SL (2010). <a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2976202">"Evaluation of virulence factor profiling in the characterization of veterinary Escherichia coli isolates"</a>. <i>Appl Environ Microbiol</i>. <b>76</b> (22): 7509–7513. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1128%2Faem.00726-10">10.1128/aem.00726-10</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2976202">2976202</a></span>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/20889790">20889790</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Appl+Environ+Microbiol&amp;rft.atitle=Evaluation+of+virulence+factor+profiling+in+the+characterization+of+veterinary+Escherichia+coli+isolates&amp;rft.volume=76&amp;rft.issue=22&amp;rft.pages=7509-7513&amp;rft.date=2010&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2976202&amp;rft_id=info%3Apmid%2F20889790&amp;rft_id=info%3Adoi%2F10.1128%2Faem.00726-10&amp;rft.aulast=David&amp;rft.aufirst=DE&amp;rft.au=Lynne%2C+AM&amp;rft.au=Han%2C+J&amp;rft.au=Foley%2C+SL&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2976202&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><cite class="citation journal">Tahmasebi, P.; Hezarkhani, A.; Mortazavi, M. (2010). <a rel="nofollow" class="external text" href="http://ajbasweb.com/old/ajbas/2010/564-576.pdf">"Application of discriminant analysis for alteration separation; sungun copper deposit, East Azerbaijan, Iran. Australian"</a> <span class="cs1-format">(PDF)</span>. <i>Journal of Basic and Applied Sciences</i>. <b>6</b> (4): 564–576.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Basic+and+Applied+Sciences&amp;rft.atitle=Application+of+discriminant+analysis+for+alteration+separation%3B+sungun+copper+deposit%2C+East+Azerbaijan%2C+Iran.+Australian&amp;rft.volume=6&amp;rft.issue=4&amp;rft.pages=564-576&amp;rft.date=2010&amp;rft.aulast=Tahmasebi&amp;rft.aufirst=P.&amp;rft.au=Hezarkhani%2C+A.&amp;rft.au=Mortazavi%2C+M.&amp;rft_id=http%3A%2F%2Fajbasweb.com%2Fold%2Fajbas%2F2010%2F564-576.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text"><cite class="citation book">Trevor Hastie; Robert Tibshirani; Jerome Friedman. <i>The Elements of Statistical Learning. Data Mining, Inference, and Prediction</i> (second ed.). Springer. p.&#160;128.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Elements+of+Statistical+Learning.+Data+Mining%2C+Inference%2C+and+Prediction&amp;rft.pages=128&amp;rft.edition=second&amp;rft.pub=Springer&amp;rft.au=Trevor+Hastie&amp;rft.au=Robert+Tibshirani&amp;rft.au=Jerome+Friedman&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text">Kainen P.C. (1997) <a rel="nofollow" class="external text" href="https://pdfs.semanticscholar.org/708f/8e0a95ba5977072651c0681f3c7b8f09eca3.pdf">Utilizing geometric anomalies of high dimension: When complexity makes computation easier</a>. In: Kárný M., Warwick K. (eds) Computer Intensive Methods in Control and Signal Processing: The Curse of Dimensionality, Springer, 1997, pp. 282–294.</span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text">Donoho, D., Tanner, J. (2009) <a rel="nofollow" class="external text" href="https://arxiv.org/pdf/0906.2530.pdf">Observed universality of phase transitions in high-dimensional geometry, with implications for modern data analysis and signal processing</a>, Phil. Trans. R. Soc. A 367, 4273–4293.</span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><cite class="citation journal">Gorban, Alexander N.; Golubkov, Alexander; Grechuck, Bogdan; Mirkes, Evgeny M.; Tyukin, Ivan Y. (2018). "Correction of AI systems by linear discriminants: Probabilistic foundations". <i>Information Sciences</i>. <b>466</b>: 303–322. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1811.05321">1811.05321</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.ins.2018.07.040">10.1016/j.ins.2018.07.040</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Information+Sciences&amp;rft.atitle=Correction+of+AI+systems+by+linear+discriminants%3A+Probabilistic+foundations&amp;rft.volume=466&amp;rft.pages=303-322&amp;rft.date=2018&amp;rft_id=info%3Aarxiv%2F1811.05321&amp;rft_id=info%3Adoi%2F10.1016%2Fj.ins.2018.07.040&amp;rft.aulast=Gorban&amp;rft.aufirst=Alexander+N.&amp;rft.au=Golubkov%2C+Alexander&amp;rft.au=Grechuck%2C+Bogdan&amp;rft.au=Mirkes%2C+Evgeny+M.&amp;rft.au=Tyukin%2C+Ivan+Y.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text">Guédon, O., Milman, E. (2011) <a rel="nofollow" class="external text" href="https://arxiv.org/pdf/1011.0943.pdf">Interpolating thin-shell and sharp large-deviation estimates for isotropic log-concave measures</a>, Geom. Funct. Anal. 21 (5), 1043–1068.</span>
</li>
<li id="cite_note-GMT2019-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-GMT2019_33-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Gorban, Alexander N.; Makarov, Valeri A.; Tyukin, Ivan Y. (July 2019). "The unreasonable effectiveness of small neural ensembles in high-dimensional brain". <i>Physics of Life Reviews</i>. <b>29</b>: 55–88. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1809.07656">1809.07656</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.plrev.2018.09.005">10.1016/j.plrev.2018.09.005</a></span>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/30366739">30366739</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Physics+of+Life+Reviews&amp;rft.atitle=The+unreasonable+effectiveness+of+small+neural+ensembles+in+high-dimensional+brain&amp;rft.volume=29&amp;rft.pages=55-88&amp;rft.date=2019-07&amp;rft_id=info%3Aarxiv%2F1809.07656&amp;rft_id=info%3Apmid%2F30366739&amp;rft_id=info%3Adoi%2F10.1016%2Fj.plrev.2018.09.005&amp;rft.aulast=Gorban&amp;rft.aufirst=Alexander+N.&amp;rft.au=Makarov%2C+Valeri+A.&amp;rft.au=Tyukin%2C+Ivan+Y.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=23" title="Edit section: Further reading">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><cite class="citation book">Duda, R. O.; Hart, P. E.; Stork, D. H. (2000). <i>Pattern Classification</i> (2nd ed.). Wiley Interscience. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-471-05669-0" title="Special:BookSources/978-0-471-05669-0"><bdi>978-0-471-05669-0</bdi></a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a>&#160;<a rel="nofollow" class="external text" href="//www.ams.org/mathscinet-getitem?mr=1802993">1802993</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Pattern+Classification&amp;rft.edition=2nd&amp;rft.pub=Wiley+Interscience&amp;rft.date=2000&amp;rft.isbn=978-0-471-05669-0&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D1802993&amp;rft.aulast=Duda&amp;rft.aufirst=R.+O.&amp;rft.au=Hart%2C+P.+E.&amp;rft.au=Stork%2C+D.+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite class="citation book">Hilbe, J. M. (2009). <i>Logistic Regression Models</i>. Chapman &amp; Hall/CRC Press. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4200-7575-5" title="Special:BookSources/978-1-4200-7575-5"><bdi>978-1-4200-7575-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Logistic+Regression+Models&amp;rft.pub=Chapman+%26+Hall%2FCRC+Press&amp;rft.date=2009&amp;rft.isbn=978-1-4200-7575-5&amp;rft.aulast=Hilbe&amp;rft.aufirst=J.+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite class="citation book">Mika, S.;  et al. (1999). <i>Fisher Discriminant Analysis with Kernels</i>. <i>IEEE Conference on Neural Networks for Signal Processing IX</i>. pp.&#160;41–48. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.9904">10.1.1.35.9904</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FNNSP.1999.788121">10.1109/NNSP.1999.788121</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-7803-5673-3" title="Special:BookSources/978-0-7803-5673-3"><bdi>978-0-7803-5673-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Fisher+Discriminant+Analysis+with+Kernels&amp;rft.pages=41-48&amp;rft.date=1999&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.35.9904&amp;rft_id=info%3Adoi%2F10.1109%2FNNSP.1999.788121&amp;rft.isbn=978-0-7803-5673-3&amp;rft.au=Mika%2C+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite class="citation journal">McFarland, H. Richard; Donald, St. P. Richards (2001). "Exact Misclassification Probabilities for Plug-In Normal Quadratic Discriminant Functions. I. The Equal-Means Case". <i>Journal of Multivariate Analysis</i>. <b>77</b> (1): 21–53. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1006%2Fjmva.2000.1924">10.1006/jmva.2000.1924</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Multivariate+Analysis&amp;rft.atitle=Exact+Misclassification+Probabilities+for+Plug-In+Normal+Quadratic+Discriminant+Functions.+I.+The+Equal-Means+Case&amp;rft.volume=77&amp;rft.issue=1&amp;rft.pages=21-53&amp;rft.date=2001&amp;rft_id=info%3Adoi%2F10.1006%2Fjmva.2000.1924&amp;rft.aulast=McFarland&amp;rft.aufirst=H.+Richard&amp;rft.au=Donald%2C+St.+P.+Richards&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite class="citation journal">McFarland, H. Richard; Donald, St. P. Richards (2002). "Exact Misclassification Probabilities for Plug-In Normal Quadratic Discriminant Functions. II. The Heterogeneous Case". <i>Journal of Multivariate Analysis</i>. <b>82</b> (2): 299–330. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1006%2Fjmva.2001.2034">10.1006/jmva.2001.2034</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Multivariate+Analysis&amp;rft.atitle=Exact+Misclassification+Probabilities+for+Plug-In+Normal+Quadratic+Discriminant+Functions.+II.+The+Heterogeneous+Case&amp;rft.volume=82&amp;rft.issue=2&amp;rft.pages=299-330&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1006%2Fjmva.2001.2034&amp;rft.aulast=McFarland&amp;rft.aufirst=H.+Richard&amp;rft.au=Donald%2C+St.+P.+Richards&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite class="citation journal">Haghighat, M.; Abdel-Mottaleb, M.; Alhalabi, W. (2016). "Discriminant Correlation Analysis: Real-Time Feature Level Fusion for Multimodal Biometric Recognition". <i>IEEE Transactions on Information Forensics and Security</i>. <b>11</b> (9): 1984–1996. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FTIFS.2016.2569061">10.1109/TIFS.2016.2569061</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Information+Forensics+and+Security&amp;rft.atitle=Discriminant+Correlation+Analysis%3A+Real-Time+Feature+Level+Fusion+for+Multimodal+Biometric+Recognition&amp;rft.volume=11&amp;rft.issue=9&amp;rft.pages=1984-1996&amp;rft.date=2016&amp;rft_id=info%3Adoi%2F10.1109%2FTIFS.2016.2569061&amp;rft.aulast=Haghighat&amp;rft.aufirst=M.&amp;rft.au=Abdel-Mottaleb%2C+M.&amp;rft.au=Alhalabi%2C+W.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinear+discriminant+analysis" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit&amp;section=24" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table role="presentation" class="mbox-small plainlinks sistersitebox" style="background-color:#f9f9f9;border:1px solid #aaa;color:#000">
<tbody><tr>
<td class="mbox-image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/9/91/Wikiversity-logo.svg/40px-Wikiversity-logo.svg.png" decoding="async" width="40" height="32" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/91/Wikiversity-logo.svg/60px-Wikiversity-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/91/Wikiversity-logo.svg/80px-Wikiversity-logo.svg.png 2x" data-file-width="1000" data-file-height="800" /></td>
<td class="mbox-text plainlist">Wikiversity has learning resources about <i><b><a href="https://en.wikiversity.org/wiki/Discriminant_function_analysis" class="extiw" title="v:Discriminant function analysis">Discriminant function analysis</a></b></i></td></tr>
</tbody></table>
<ul><li><a rel="nofollow" class="external text" href="https://github.com/mhaghighat/dcaFuse">Discriminant Correlation Analysis (DCA) of the Haghighat article (see above)</a></li>
<li><a rel="nofollow" class="external text" href="http://www.alglib.net/dataanalysis/lineardiscriminantanalysis.php">ALGLIB</a> contains open-source LDA implementation in C# / C++ / Pascal / VBA.</li>
<li><a rel="nofollow" class="external text" href="http://www.psychometrica.de/lds.html">Psychometrica.de</a><sup class="noprint Inline-Template"><span style="white-space: nowrap;">&#91;<i><a href="/wiki/Wikipedia:Link_rot" title="Wikipedia:Link rot"><span title="&#160;Dead link since December 2017">permanent dead link</span></a></i>&#93;</span></sup> open-source LDA implementation in Java</li>
<li><a rel="nofollow" class="external text" href="http://people.revoledu.com/kardi/tutorial/LDA/index.html">LDA tutorial using MS Excel</a></li>
<li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20150405124836/http://biostat.katerynakon.in.ua/en/prognosis/discriminant-analysis.html">Biomedical statistics. Discriminant analysis</a></li>
<li><a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=azXCzI57Yfc"><span class="plainlinks">StatQuest: Linear Discriminant Analysis (LDA) clearly explained</span></a> on <a href="/wiki/YouTube" title="YouTube">YouTube</a></li>
<li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20080312065328/http://www2.chass.ncsu.edu/garson/pA765/discrim.htm">Course notes, Discriminant function analysis by G. David Garson, NC State University</a></li>
<li><a rel="nofollow" class="external text" href="http://people.revoledu.com/kardi/tutorial/LDA/">Discriminant analysis tutorial in Microsoft Excel by Kardi Teknomo</a></li>
<li><a rel="nofollow" class="external text" href="http://www.psychstat.missouristate.edu/multibook/mlt03m.html">Course notes, Discriminant function analysis by David W. Stockburger, Missouri State University</a></li>
<li><a rel="nofollow" class="external text" href="http://userwww.sfsu.edu/~efc/classes/biol710/discrim/discrim.pdf">Discriminant function analysis (DA) by John Poulsen and Aaron French, San Francisco State University</a></li></ul>
<div role="navigation" class="navbox" aria-labelledby="Statistics" style="padding:3px"><table class="nowraplinks hlist mw-collapsible uncollapsed navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Statistics" title="Template:Statistics"><abbr title="View this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Statistics" title="Template talk:Statistics"><abbr title="Discuss this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Statistics&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">e</abbr></a></li></ul></div><div id="Statistics" style="font-size:114%;margin:0 4em"><a href="/wiki/Statistics" title="Statistics">Statistics</a></div></th></tr><tr><td class="navbox-abovebelow" colspan="2"><div id="*_Outline&amp;#10;*_Index">
<ul><li><a href="/wiki/Outline_of_statistics" title="Outline of statistics">Outline</a></li>
<li><a href="/wiki/List_of_statistics_articles" title="List of statistics articles">Index</a></li></ul>
</div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Descriptive_statistics" style="font-size:114%;margin:0 4em"><a href="/wiki/Descriptive_statistics" title="Descriptive statistics">Descriptive statistics</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Continuous_probability_distribution" class="mw-redirect" title="Continuous probability distribution">Continuous data</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Central_tendency" title="Central tendency">Center</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Mean" title="Mean">Mean</a>
<ul><li><a href="/wiki/Arithmetic_mean" title="Arithmetic mean">arithmetic</a></li>
<li><a href="/wiki/Geometric_mean" title="Geometric mean">geometric</a></li>
<li><a href="/wiki/Harmonic_mean" title="Harmonic mean">harmonic</a></li></ul></li>
<li><a href="/wiki/Median" title="Median">Median</a></li>
<li><a href="/wiki/Mode_(statistics)" title="Mode (statistics)">Mode</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Statistical_dispersion" title="Statistical dispersion">Dispersion</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Variance#Sample_variance" title="Variance">Variance</a></li>
<li><a href="/wiki/Standard_deviation" title="Standard deviation">Standard deviation</a></li>
<li><a href="/wiki/Coefficient_of_variation" title="Coefficient of variation">Coefficient of variation</a></li>
<li><a href="/wiki/Percentile" title="Percentile">Percentile</a></li>
<li><a href="/wiki/Range_(statistics)" title="Range (statistics)">Range</a></li>
<li><a href="/wiki/Interquartile_range" title="Interquartile range">Interquartile range</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Shape_of_the_distribution" class="mw-redirect" title="Shape of the distribution">Shape</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Central_limit_theorem" title="Central limit theorem">Central limit theorem</a></li>
<li><a href="/wiki/Moment_(mathematics)" title="Moment (mathematics)">Moments</a>
<ul><li><a href="/wiki/Skewness" title="Skewness">Skewness</a></li>
<li><a href="/wiki/Kurtosis" title="Kurtosis">Kurtosis</a></li>
<li><a href="/wiki/L-moment" title="L-moment">L-moments</a></li></ul></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Count_data" title="Count data">Count data</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Index_of_dispersion" title="Index of dispersion">Index of dispersion</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em">Summary tables</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Grouped_data" title="Grouped data">Grouped data</a></li>
<li><a href="/wiki/Frequency_distribution" title="Frequency distribution">Frequency distribution</a></li>
<li><a href="/wiki/Contingency_table" title="Contingency table">Contingency table</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Correlation_and_dependence" title="Correlation and dependence">Dependence</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Pearson_correlation_coefficient" title="Pearson correlation coefficient">Pearson product-moment correlation</a></li>
<li><a href="/wiki/Rank_correlation" title="Rank correlation">Rank correlation</a>
<ul><li><a href="/wiki/Spearman%27s_rank_correlation_coefficient" title="Spearman&#39;s rank correlation coefficient">Spearman's ρ</a></li>
<li><a href="/wiki/Kendall_rank_correlation_coefficient" title="Kendall rank correlation coefficient">Kendall's τ</a></li></ul></li>
<li><a href="/wiki/Partial_correlation" title="Partial correlation">Partial correlation</a></li>
<li><a href="/wiki/Scatter_plot" title="Scatter plot">Scatter plot</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Statistical_graphics" title="Statistical graphics">Graphics</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Bar_chart" title="Bar chart">Bar chart</a></li>
<li><a href="/wiki/Biplot" title="Biplot">Biplot</a></li>
<li><a href="/wiki/Box_plot" title="Box plot">Box plot</a></li>
<li><a href="/wiki/Control_chart" title="Control chart">Control chart</a></li>
<li><a href="/wiki/Correlogram" title="Correlogram">Correlogram</a></li>
<li><a href="/wiki/Fan_chart_(statistics)" title="Fan chart (statistics)">Fan chart</a></li>
<li><a href="/wiki/Forest_plot" title="Forest plot">Forest plot</a></li>
<li><a href="/wiki/Histogram" title="Histogram">Histogram</a></li>
<li><a href="/wiki/Pie_chart" title="Pie chart">Pie chart</a></li>
<li><a href="/wiki/Q%E2%80%93Q_plot" title="Q–Q plot">Q–Q plot</a></li>
<li><a href="/wiki/Run_chart" title="Run chart">Run chart</a></li>
<li><a href="/wiki/Scatter_plot" title="Scatter plot">Scatter plot</a></li>
<li><a href="/wiki/Stem-and-leaf_display" title="Stem-and-leaf display">Stem-and-leaf display</a></li>
<li><a href="/wiki/Radar_chart" title="Radar chart">Radar chart</a></li>
<li><a href="/wiki/Violin_plot" title="Violin plot">Violin plot</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Data_collection" style="font-size:114%;margin:0 4em"><a href="/wiki/Data_collection" title="Data collection">Data collection</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Design_of_experiments" title="Design of experiments">Study design</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Population_(statistics)" class="mw-redirect" title="Population (statistics)">Population</a></li>
<li><a href="/wiki/Statistic" title="Statistic">Statistic</a></li>
<li><a href="/wiki/Effect_size" title="Effect size">Effect size</a></li>
<li><a href="/wiki/Statistical_power" class="mw-redirect" title="Statistical power">Statistical power</a></li>
<li><a href="/wiki/Optimal_design" title="Optimal design">Optimal design</a></li>
<li><a href="/wiki/Sample_size_determination" title="Sample size determination">Sample size determination</a></li>
<li><a href="/wiki/Replication_(statistics)" title="Replication (statistics)">Replication</a></li>
<li><a href="/wiki/Missing_data" title="Missing data">Missing data</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Survey_methodology" title="Survey methodology">Survey methodology</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Sampling_(statistics)" title="Sampling (statistics)">Sampling</a>
<ul><li><a href="/wiki/Stratified_sampling" title="Stratified sampling">stratified</a></li>
<li><a href="/wiki/Cluster_sampling" title="Cluster sampling">cluster</a></li></ul></li>
<li><a href="/wiki/Standard_error" title="Standard error">Standard error</a></li>
<li><a href="/wiki/Opinion_poll" title="Opinion poll">Opinion poll</a></li>
<li><a href="/wiki/Questionnaire" title="Questionnaire">Questionnaire</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Experiment" title="Experiment">Controlled experiments</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Scientific_control" title="Scientific control">Scientific control</a></li>
<li><a href="/wiki/Randomized_experiment" title="Randomized experiment">Randomized experiment</a></li>
<li><a href="/wiki/Randomized_controlled_trial" title="Randomized controlled trial">Randomized controlled trial</a></li>
<li><a href="/wiki/Random_assignment" title="Random assignment">Random assignment</a></li>
<li><a href="/wiki/Blocking_(statistics)" title="Blocking (statistics)">Blocking</a></li>
<li><a href="/wiki/Interaction_(statistics)" title="Interaction (statistics)">Interaction</a></li>
<li><a href="/wiki/Factorial_experiment" title="Factorial experiment">Factorial experiment</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em">Adaptive Designs</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Adaptive_clinical_trial" title="Adaptive clinical trial">Adaptive clinical trial</a></li>
<li><a href="/wiki/Up-and-Down_Designs" title="Up-and-Down Designs">Up-and-Down Designs</a></li>
<li><a href="/wiki/Stochastic_approximation" title="Stochastic approximation">Stochastic approximation</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Observational_study" title="Observational study">Observational Studies</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Cross-sectional_study" title="Cross-sectional study">Cross-sectional study</a></li>
<li><a href="/wiki/Cohort_study" title="Cohort study">Cohort study</a></li>
<li><a href="/wiki/Natural_experiment" title="Natural experiment">Natural experiment</a></li>
<li><a href="/wiki/Quasi-experiment" title="Quasi-experiment">Quasi-experiment</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Statistical_inference" style="font-size:114%;margin:0 4em"><a href="/wiki/Statistical_inference" title="Statistical inference">Statistical inference</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Statistical_theory" title="Statistical theory">Statistical theory</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Population_(statistics)" class="mw-redirect" title="Population (statistics)">Population</a></li>
<li><a href="/wiki/Statistic" title="Statistic">Statistic</a></li>
<li><a href="/wiki/Probability_distribution" title="Probability distribution">Probability distribution</a></li>
<li><a href="/wiki/Sampling_distribution" title="Sampling distribution">Sampling distribution</a>
<ul><li><a href="/wiki/Order_statistic" title="Order statistic">Order statistic</a></li></ul></li>
<li><a href="/wiki/Empirical_distribution_function" title="Empirical distribution function">Empirical distribution</a>
<ul><li><a href="/wiki/Density_estimation" title="Density estimation">Density estimation</a></li></ul></li>
<li><a href="/wiki/Statistical_model" title="Statistical model">Statistical model</a>
<ul><li><a href="/wiki/Model_specification" class="mw-redirect" title="Model specification">Model specification</a></li>
<li><a href="/wiki/Lp_space" title="Lp space">L<sup><i>p</i></sup> space</a></li></ul></li>
<li><a href="/wiki/Statistical_parameter" title="Statistical parameter">Parameter</a>
<ul><li><a href="/wiki/Location_parameter" title="Location parameter">location</a></li>
<li><a href="/wiki/Scale_parameter" title="Scale parameter">scale</a></li>
<li><a href="/wiki/Shape_parameter" title="Shape parameter">shape</a></li></ul></li>
<li><a href="/wiki/Parametric_statistics" title="Parametric statistics">Parametric family</a>
<ul><li><a href="/wiki/Likelihood_function" title="Likelihood function">Likelihood</a>&#160;<a href="/wiki/Monotone_likelihood_ratio" title="Monotone likelihood ratio"><span style="font-size:85%;">(monotone)</span></a></li>
<li><a href="/wiki/Location%E2%80%93scale_family" title="Location–scale family">Location–scale family</a></li>
<li><a href="/wiki/Exponential_family" title="Exponential family">Exponential family</a></li></ul></li>
<li><a href="/wiki/Completeness_(statistics)" title="Completeness (statistics)">Completeness</a></li>
<li><a href="/wiki/Sufficient_statistic" title="Sufficient statistic">Sufficiency</a></li>
<li><a href="/wiki/Plug-in_principle" class="mw-redirect" title="Plug-in principle">Statistical functional</a>
<ul><li><a href="/wiki/Bootstrapping_(statistics)" title="Bootstrapping (statistics)">Bootstrap</a></li>
<li><a href="/wiki/U-statistic" title="U-statistic">U</a></li>
<li><a href="/wiki/V-statistic" title="V-statistic">V</a></li></ul></li>
<li><a href="/wiki/Optimal_decision" title="Optimal decision">Optimal decision</a>
<ul><li><a href="/wiki/Loss_function" title="Loss function">loss function</a></li></ul></li>
<li><a href="/wiki/Efficiency_(statistics)" title="Efficiency (statistics)">Efficiency</a></li>
<li><a href="/wiki/Statistical_distance" title="Statistical distance">Statistical distance</a>
<ul><li><a href="/wiki/Divergence_(statistics)" title="Divergence (statistics)">divergence</a></li></ul></li>
<li><a href="/wiki/Asymptotic_theory_(statistics)" title="Asymptotic theory (statistics)">Asymptotics</a></li>
<li><a href="/wiki/Robust_statistics" title="Robust statistics">Robustness</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Frequentist_inference" title="Frequentist inference">Frequentist inference</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Point_estimation" title="Point estimation">Point estimation</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Estimating_equations" title="Estimating equations">Estimating equations</a>
<ul><li><a href="/wiki/Maximum_likelihood" class="mw-redirect" title="Maximum likelihood">Maximum likelihood</a></li>
<li><a href="/wiki/Method_of_moments_(statistics)" title="Method of moments (statistics)">Method of moments</a></li>
<li><a href="/wiki/M-estimator" title="M-estimator">M-estimator</a></li>
<li><a href="/wiki/Minimum_distance_estimation" title="Minimum distance estimation">Minimum distance</a></li></ul></li>
<li><a href="/wiki/Bias_of_an_estimator" title="Bias of an estimator">Unbiased estimators</a>
<ul><li><a href="/wiki/Minimum-variance_unbiased_estimator" title="Minimum-variance unbiased estimator">Mean-unbiased minimum-variance</a>
<ul><li><a href="/wiki/Rao%E2%80%93Blackwell_theorem" title="Rao–Blackwell theorem">Rao–Blackwellization</a></li>
<li><a href="/wiki/Lehmann%E2%80%93Scheff%C3%A9_theorem" title="Lehmann–Scheffé theorem">Lehmann–Scheffé theorem</a></li></ul></li>
<li><a href="/wiki/Median-unbiased_estimator" class="mw-redirect" title="Median-unbiased estimator">Median unbiased</a></li></ul></li>
<li><a href="/wiki/Plug-in_principle" class="mw-redirect" title="Plug-in principle">Plug-in</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Interval_estimation" title="Interval estimation">Interval estimation</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Confidence_interval" title="Confidence interval">Confidence interval</a></li>
<li><a href="/wiki/Pivotal_quantity" title="Pivotal quantity">Pivot</a></li>
<li><a href="/wiki/Likelihood_interval" class="mw-redirect" title="Likelihood interval">Likelihood interval</a></li>
<li><a href="/wiki/Prediction_interval" title="Prediction interval">Prediction interval</a></li>
<li><a href="/wiki/Tolerance_interval" title="Tolerance interval">Tolerance interval</a></li>
<li><a href="/wiki/Resampling_(statistics)" title="Resampling (statistics)">Resampling</a>
<ul><li><a href="/wiki/Bootstrapping_(statistics)" title="Bootstrapping (statistics)">Bootstrap</a></li>
<li><a href="/wiki/Jackknife_resampling" title="Jackknife resampling">Jackknife</a></li></ul></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Statistical_hypothesis_testing" title="Statistical hypothesis testing">Testing hypotheses</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/One-_and_two-tailed_tests" title="One- and two-tailed tests">1- &amp; 2-tails</a></li>
<li><a href="/wiki/Power_(statistics)" title="Power (statistics)">Power</a>
<ul><li><a href="/wiki/Uniformly_most_powerful_test" title="Uniformly most powerful test">Uniformly most powerful test</a></li></ul></li>
<li><a href="/wiki/Permutation_test" class="mw-redirect" title="Permutation test">Permutation test</a>
<ul><li><a href="/wiki/Randomization_test" class="mw-redirect" title="Randomization test">Randomization test</a></li></ul></li>
<li><a href="/wiki/Multiple_comparisons" class="mw-redirect" title="Multiple comparisons">Multiple comparisons</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Parametric_statistics" title="Parametric statistics">Parametric tests</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Likelihood-ratio_test" title="Likelihood-ratio test">Likelihood-ratio</a></li>
<li><a href="/wiki/Score_test" title="Score test">Score/Lagrange multiplier</a></li>
<li><a href="/wiki/Wald_test" title="Wald test">Wald</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em">Specific tests</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><td colspan="2" class="navbox-list navbox-even" style="width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Z-test" title="Z-test"><i>Z</i>-test <span style="font-size:90%;">(normal)</span></a></li>
<li><a href="/wiki/Student%27s_t-test" title="Student&#39;s t-test">Student's <i>t</i>-test</a></li>
<li><a href="/wiki/F-test" title="F-test"><i>F</i>-test</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Goodness_of_fit" title="Goodness of fit">Goodness of fit</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Chi-squared_test" title="Chi-squared test">Chi-squared</a></li>
<li><a href="/wiki/G-test" title="G-test"><i>G</i>-test</a></li>
<li><a href="/wiki/Kolmogorov%E2%80%93Smirnov_test" title="Kolmogorov–Smirnov test">Kolmogorov–Smirnov</a></li>
<li><a href="/wiki/Anderson%E2%80%93Darling_test" title="Anderson–Darling test">Anderson–Darling</a></li>
<li><a href="/wiki/Lilliefors_test" title="Lilliefors test">Lilliefors</a></li>
<li><a href="/wiki/Jarque%E2%80%93Bera_test" title="Jarque–Bera test">Jarque–Bera</a></li>
<li><a href="/wiki/Shapiro%E2%80%93Wilk_test" title="Shapiro–Wilk test">Normality <span style="font-size:90%;">(Shapiro–Wilk)</span></a></li>
<li><a href="/wiki/Likelihood-ratio_test" title="Likelihood-ratio test">Likelihood-ratio test</a></li>
<li><a href="/wiki/Model_selection" title="Model selection">Model selection</a>
<ul><li><a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">Cross validation</a></li>
<li><a href="/wiki/Akaike_information_criterion" title="Akaike information criterion">AIC</a></li>
<li><a href="/wiki/Bayesian_information_criterion" title="Bayesian information criterion">BIC</a></li></ul></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Rank_statistics" class="mw-redirect" title="Rank statistics">Rank statistics</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Sign_test" title="Sign test">Sign</a>
<ul><li><a href="/wiki/Sample_median" class="mw-redirect" title="Sample median">Sample median</a></li></ul></li>
<li><a href="/wiki/Wilcoxon_signed-rank_test" title="Wilcoxon signed-rank test">Signed rank <span style="font-size:90%;">(Wilcoxon)</span></a>
<ul><li><a href="/wiki/Hodges%E2%80%93Lehmann_estimator" title="Hodges–Lehmann estimator">Hodges–Lehmann estimator</a></li></ul></li>
<li><a href="/wiki/Mann%E2%80%93Whitney_U_test" title="Mann–Whitney U test">Rank sum <span style="font-size:90%;">(Mann–Whitney)</span></a></li>
<li><a href="/wiki/Nonparametric_statistics" title="Nonparametric statistics">Nonparametric</a> <a href="/wiki/Analysis_of_variance" title="Analysis of variance">anova</a>
<ul><li><a href="/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance" title="Kruskal–Wallis one-way analysis of variance">1-way <span style="font-size:90%;">(Kruskal–Wallis)</span></a></li>
<li><a href="/wiki/Friedman_test" title="Friedman test">2-way <span style="font-size:90%;">(Friedman)</span></a></li>
<li><a href="/wiki/Jonckheere%27s_trend_test" title="Jonckheere&#39;s trend test">Ordered alternative <span style="font-size:90%;">(Jonckheere–Terpstra)</span></a></li></ul></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Bayesian_inference" title="Bayesian inference">Bayesian inference</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Bayesian_probability" title="Bayesian probability">Bayesian probability</a>
<ul><li><a href="/wiki/Prior_probability" title="Prior probability">prior</a></li>
<li><a href="/wiki/Posterior_probability" title="Posterior probability">posterior</a></li></ul></li>
<li><a href="/wiki/Credible_interval" title="Credible interval">Credible interval</a></li>
<li><a href="/wiki/Bayes_factor" title="Bayes factor">Bayes factor</a></li>
<li><a href="/wiki/Bayes_estimator" title="Bayes estimator">Bayesian estimator</a>
<ul><li><a href="/wiki/Maximum_a_posteriori_estimation" title="Maximum a posteriori estimation">Maximum posterior estimator</a></li></ul></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="CorrelationRegression_analysis" style="font-size:114%;margin:0 4em"><div class="hlist hlist-separated"><ul><li><a href="/wiki/Correlation_and_dependence" title="Correlation and dependence">Correlation</a></li><li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression analysis</a></li></ul></div></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Correlation_and_dependence" title="Correlation and dependence">Correlation</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Pearson_product-moment_correlation_coefficient" class="mw-redirect" title="Pearson product-moment correlation coefficient">Pearson product-moment</a></li>
<li><a href="/wiki/Partial_correlation" title="Partial correlation">Partial correlation</a></li>
<li><a href="/wiki/Confounding" title="Confounding">Confounding variable</a></li>
<li><a href="/wiki/Coefficient_of_determination" title="Coefficient of determination">Coefficient of determination</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Regression_analysis" title="Regression analysis">Regression analysis</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Errors_and_residuals_in_statistics" class="mw-redirect" title="Errors and residuals in statistics">Errors and residuals</a></li>
<li><a href="/wiki/Regression_validation" title="Regression validation">Regression validation</a></li>
<li><a href="/wiki/Mixed_model" title="Mixed model">Mixed effects models</a></li>
<li><a href="/wiki/Simultaneous_equations_model" title="Simultaneous equations model">Simultaneous equations models</a></li>
<li><a href="/wiki/Multivariate_adaptive_regression_splines" class="mw-redirect" title="Multivariate adaptive regression splines">Multivariate adaptive regression splines (MARS)</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Simple_linear_regression" title="Simple linear regression">Simple linear regression</a></li>
<li><a href="/wiki/Ordinary_least_squares" title="Ordinary least squares">Ordinary least squares</a></li>
<li><a href="/wiki/General_linear_model" title="General linear model">General linear model</a></li>
<li><a href="/wiki/Bayesian_linear_regression" title="Bayesian linear regression">Bayesian regression</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em">Non-standard predictors</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Nonlinear_regression" title="Nonlinear regression">Nonlinear regression</a></li>
<li><a href="/wiki/Nonparametric_regression" title="Nonparametric regression">Nonparametric</a></li>
<li><a href="/wiki/Semiparametric_regression" title="Semiparametric regression">Semiparametric</a></li>
<li><a href="/wiki/Isotonic_regression" title="Isotonic regression">Isotonic</a></li>
<li><a href="/wiki/Robust_regression" title="Robust regression">Robust</a></li>
<li><a href="/wiki/Heteroscedasticity" title="Heteroscedasticity">Heteroscedasticity</a></li>
<li><a href="/wiki/Homoscedasticity" title="Homoscedasticity">Homoscedasticity</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Generalized_linear_model" title="Generalized linear model">Generalized linear model</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Exponential_family" title="Exponential family">Exponential families</a></li>
<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic <span style="font-size:90%;">(Bernoulli)</span></a>&#160;/&#32;<a href="/wiki/Binomial_regression" title="Binomial regression">Binomial</a>&#160;/&#32;<a href="/wiki/Poisson_regression" title="Poisson regression">Poisson regressions</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Partition_of_sums_of_squares" title="Partition of sums of squares">Partition of variance</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Analysis_of_variance" title="Analysis of variance">Analysis of variance (ANOVA, anova)</a></li>
<li><a href="/wiki/Analysis_of_covariance" title="Analysis of covariance">Analysis of covariance</a></li>
<li><a href="/wiki/Multivariate_analysis_of_variance" title="Multivariate analysis of variance">Multivariate ANOVA</a></li>
<li><a href="/wiki/Degrees_of_freedom_(statistics)" title="Degrees of freedom (statistics)">Degrees of freedom</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks mw-collapsible uncollapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Categorical_/_Multivariate_/_Time-series_/_Survival_analysis" style="font-size:114%;margin:0 4em"><a href="/wiki/Categorical_variable" title="Categorical variable">Categorical</a>&#160;/&#32;<a href="/wiki/Multivariate_statistics" title="Multivariate statistics">Multivariate</a>&#160;/&#32;<a href="/wiki/Time_series" title="Time series">Time-series</a>&#160;/&#32;<a href="/wiki/Survival_analysis" title="Survival analysis">Survival analysis</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Categorical_variable" title="Categorical variable">Categorical</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Cohen%27s_kappa" title="Cohen&#39;s kappa">Cohen's kappa</a></li>
<li><a href="/wiki/Contingency_table" title="Contingency table">Contingency table</a></li>
<li><a href="/wiki/Graphical_model" title="Graphical model">Graphical model</a></li>
<li><a href="/wiki/Poisson_regression" title="Poisson regression">Log-linear model</a></li>
<li><a href="/wiki/McNemar%27s_test" title="McNemar&#39;s test">McNemar's test</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Multivariate_statistics" title="Multivariate statistics">Multivariate</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/General_linear_model" title="General linear model">Regression</a></li>
<li><a href="/wiki/Multivariate_analysis_of_variance" title="Multivariate analysis of variance">Manova</a></li>
<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">Principal components</a></li>
<li><a href="/wiki/Canonical_correlation" title="Canonical correlation">Canonical correlation</a></li>
<li><a class="mw-selflink selflink">Discriminant analysis</a></li>
<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Cluster analysis</a></li>
<li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>
<li><a href="/wiki/Structural_equation_modeling" title="Structural equation modeling">Structural equation model</a>
<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li></ul></li>
<li><a href="/wiki/Multivariate_distribution" class="mw-redirect" title="Multivariate distribution">Multivariate distributions</a>
<ul><li><a href="/wiki/Elliptical_distribution" title="Elliptical distribution">Elliptical distributions</a>
<ul><li><a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">Normal</a></li></ul></li></ul></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Time_series" title="Time series">Time-series</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;">General</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Decomposition_of_time_series" title="Decomposition of time series">Decomposition</a></li>
<li><a href="/wiki/Trend_estimation" class="mw-redirect" title="Trend estimation">Trend</a></li>
<li><a href="/wiki/Stationary_process" title="Stationary process">Stationarity</a></li>
<li><a href="/wiki/Seasonal_adjustment" title="Seasonal adjustment">Seasonal adjustment</a></li>
<li><a href="/wiki/Exponential_smoothing" title="Exponential smoothing">Exponential smoothing</a></li>
<li><a href="/wiki/Cointegration" title="Cointegration">Cointegration</a></li>
<li><a href="/wiki/Structural_break" title="Structural break">Structural break</a></li>
<li><a href="/wiki/Granger_causality" title="Granger causality">Granger causality</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;">Specific tests</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Dickey%E2%80%93Fuller_test" title="Dickey–Fuller test">Dickey–Fuller</a></li>
<li><a href="/wiki/Johansen_test" title="Johansen test">Johansen</a></li>
<li><a href="/wiki/Ljung%E2%80%93Box_test" title="Ljung–Box test">Q-statistic <span style="font-size:90%;">(Ljung–Box)</span></a></li>
<li><a href="/wiki/Durbin%E2%80%93Watson_statistic" title="Durbin–Watson statistic">Durbin–Watson</a></li>
<li><a href="/wiki/Breusch%E2%80%93Godfrey_test" title="Breusch–Godfrey test">Breusch–Godfrey</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Time_domain" title="Time domain">Time domain</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Autocorrelation" title="Autocorrelation">Autocorrelation (ACF)</a>
<ul><li><a href="/wiki/Partial_autocorrelation_function" title="Partial autocorrelation function">partial (PACF)</a></li></ul></li>
<li><a href="/wiki/Cross-correlation" title="Cross-correlation">Cross-correlation (XCF)</a></li>
<li><a href="/wiki/Autoregressive%E2%80%93moving-average_model" title="Autoregressive–moving-average model">ARMA model</a></li>
<li><a href="/wiki/Box%E2%80%93Jenkins_method" title="Box–Jenkins method">ARIMA model <span style="font-size:90%;">(Box–Jenkins)</span></a></li>
<li><a href="/wiki/Autoregressive_conditional_heteroskedasticity" title="Autoregressive conditional heteroskedasticity">Autoregressive conditional heteroskedasticity (ARCH)</a></li>
<li><a href="/wiki/Vector_autoregression" title="Vector autoregression">Vector autoregression (VAR)</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Frequency_domain" title="Frequency domain">Frequency domain</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Spectral_density_estimation" title="Spectral density estimation">Spectral density estimation</a></li>
<li><a href="/wiki/Fourier_analysis" title="Fourier analysis">Fourier analysis</a></li>
<li><a href="/wiki/Wavelet" title="Wavelet">Wavelet</a></li>
<li><a href="/wiki/Whittle_likelihood" title="Whittle likelihood">Whittle likelihood</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Survival_analysis" title="Survival analysis">Survival</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Survival_function" title="Survival function">Survival function</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Kaplan%E2%80%93Meier_estimator" title="Kaplan–Meier estimator">Kaplan–Meier estimator (product limit)</a></li>
<li><a href="/wiki/Proportional_hazards_model" title="Proportional hazards model">Proportional hazards models</a></li>
<li><a href="/wiki/Accelerated_failure_time_model" title="Accelerated failure time model">Accelerated failure time (AFT) model</a></li>
<li><a href="/wiki/First-hitting-time_model" title="First-hitting-time model">First hitting time</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;"><a href="/wiki/Failure_rate" title="Failure rate">Hazard function</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Nelson%E2%80%93Aalen_estimator" title="Nelson–Aalen estimator">Nelson–Aalen estimator</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%;font-weight:normal;">Test</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Log-rank_test" class="mw-redirect" title="Log-rank test">Log-rank test</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Applications" style="font-size:114%;margin:0 4em"><a href="/wiki/List_of_fields_of_application_of_statistics" title="List of fields of application of statistics">Applications</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Biostatistics" title="Biostatistics">Biostatistics</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Bioinformatics" title="Bioinformatics">Bioinformatics</a></li>
<li><a href="/wiki/Clinical_trial" title="Clinical trial">Clinical trials</a>&#160;/&#32;<a href="/wiki/Clinical_study_design" title="Clinical study design">studies</a></li>
<li><a href="/wiki/Epidemiology" title="Epidemiology">Epidemiology</a></li>
<li><a href="/wiki/Medical_statistics" title="Medical statistics">Medical statistics</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Engineering_statistics" title="Engineering statistics">Engineering statistics</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Chemometrics" title="Chemometrics">Chemometrics</a></li>
<li><a href="/wiki/Methods_engineering" title="Methods engineering">Methods engineering</a></li>
<li><a href="/wiki/Probabilistic_design" title="Probabilistic design">Probabilistic design</a></li>
<li><a href="/wiki/Statistical_process_control" title="Statistical process control">Process</a>&#160;/&#32;<a href="/wiki/Quality_control" title="Quality control">quality control</a></li>
<li><a href="/wiki/Reliability_engineering" title="Reliability engineering">Reliability</a></li>
<li><a href="/wiki/System_identification" title="System identification">System identification</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Social_statistics" title="Social statistics">Social statistics</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Actuarial_science" title="Actuarial science">Actuarial science</a></li>
<li><a href="/wiki/Census" title="Census">Census</a></li>
<li><a href="/wiki/Crime_statistics" title="Crime statistics">Crime statistics</a></li>
<li><a href="/wiki/Demographic_statistics" title="Demographic statistics">Demography</a></li>
<li><a href="/wiki/Econometrics" title="Econometrics">Econometrics</a></li>
<li><a href="/wiki/Jurimetrics" title="Jurimetrics">Jurimetrics</a></li>
<li><a href="/wiki/National_accounts" title="National accounts">National accounts</a></li>
<li><a href="/wiki/Official_statistics" title="Official statistics">Official statistics</a></li>
<li><a href="/wiki/Population_statistics" class="mw-redirect" title="Population statistics">Population statistics</a></li>
<li><a href="/wiki/Psychometrics" title="Psychometrics">Psychometrics</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:12.5em"><a href="/wiki/Spatial_analysis" title="Spatial analysis">Spatial statistics</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Cartography" title="Cartography">Cartography</a></li>
<li><a href="/wiki/Environmental_statistics" title="Environmental statistics">Environmental statistics</a></li>
<li><a href="/wiki/Geographic_information_system" title="Geographic information system">Geographic information system</a></li>
<li><a href="/wiki/Geostatistics" title="Geostatistics">Geostatistics</a></li>
<li><a href="/wiki/Kriging" title="Kriging">Kriging</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td class="navbox-abovebelow" colspan="2"><div>
<ul><li><img alt="Category" src="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png" decoding="async" title="Category" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x" data-file-width="36" data-file-height="31" /><b><a href="/wiki/Category:Statistics" title="Category:Statistics">Category</a></b></li>
<li><b><a href="/wiki/File:Nuvola_apps_edu_mathematics_blue-p.svg" class="image"><img alt="Nuvola apps edu mathematics blue-p.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/28px-Nuvola_apps_edu_mathematics_blue-p.svg.png" decoding="async" width="28" height="28" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/42px-Nuvola_apps_edu_mathematics_blue-p.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg/56px-Nuvola_apps_edu_mathematics_blue-p.svg.png 2x" data-file-width="128" data-file-height="128" /></a> <a href="/wiki/Portal:Mathematics" title="Portal:Mathematics">Mathematics&#32;portal</a></b></li>
<li><img alt="Commons page" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" decoding="async" title="Commons page" width="12" height="16" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376" /><b><a href="https://commons.wikimedia.org/wiki/Category:Statistics" class="extiw" title="commons:Category:Statistics">Commons</a></b></li>
<li><img alt="WikiProject" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/37/People_icon.svg/16px-People_icon.svg.png" decoding="async" title="WikiProject" width="16" height="16" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/37/People_icon.svg/24px-People_icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/37/People_icon.svg/32px-People_icon.svg.png 2x" data-file-width="100" data-file-height="100" /> <b><a href="/wiki/Wikipedia:WikiProject_Statistics" title="Wikipedia:WikiProject Statistics">WikiProject</a></b></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw1381
Cached time: 20200315163756
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.804 seconds
Real time usage: 1.059 seconds
Preprocessor visited node count: 3859/1000000
Post‐expand include size: 220386/2097152 bytes
Template argument size: 4777/2097152 bytes
Highest expansion depth: 15/40
Expensive parser function count: 12/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 93334/5000000 bytes
Number of Wikibase entities loaded: 8/400
Lua time usage: 0.375/10.000 seconds
Lua memory usage: 6.72 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  745.749      1 -total
 48.15%  359.085      1 Template:Reflist
 40.87%  304.796     19 Template:Cite_journal
 15.20%  113.344      1 Template:Statistics
 14.76%  110.047      5 Template:Clarify
 14.55%  108.516      1 Template:Navbox_with_collapsible_groups
 13.33%   99.414      5 Template:Fix-span
  8.97%   66.869     12 Template:Category_handler
  7.54%   56.224     11 Template:Navbox
  4.66%   34.788      5 Template:Replace
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:1470657-0!canonical!math=5 and timestamp 20200315163811 and revision id 945697526
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>
		<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Linear_discriminant_analysis&amp;oldid=945697526">https://en.wikipedia.org/w/index.php?title=Linear_discriminant_analysis&amp;oldid=945697526</a>"</div>
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Classification_algorithms" title="Category:Classification algorithms">Classification algorithms</a></li><li><a href="/wiki/Category:Market_research" title="Category:Market research">Market research</a></li><li><a href="/wiki/Category:Market_segmentation" title="Category:Market segmentation">Market segmentation</a></li><li><a href="/wiki/Category:Statistical_classification" title="Category:Statistical classification">Statistical classification</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:CS1_maint:_archived_copy_as_title" title="Category:CS1 maint: archived copy as title">CS1 maint: archived copy as title</a></li><li><a href="/wiki/Category:Wikipedia_articles_needing_clarification_from_April_2019" title="Category:Wikipedia articles needing clarification from April 2019">Wikipedia articles needing clarification from April 2019</a></li><li><a href="/wiki/Category:Wikipedia_articles_needing_clarification_from_April_2012" title="Category:Wikipedia articles needing clarification from April 2012">Wikipedia articles needing clarification from April 2012</a></li><li><a href="/wiki/Category:All_articles_with_dead_external_links" title="Category:All articles with dead external links">All articles with dead external links</a></li><li><a href="/wiki/Category:Articles_with_dead_external_links_from_December_2017" title="Category:Articles with dead external links from December 2017">Articles with dead external links from December 2017</a></li><li><a href="/wiki/Category:Articles_with_permanently_dead_external_links" title="Category:Articles with permanently dead external links">Articles with permanently dead external links</a></li></ul></div></div>
		<div class="visualClear"></div>
		
	</div>
</div>
<div id='mw-data-after-content'>
	<div class="read-more-container"></div>
</div>

<div id="mw-navigation">
    <h2>Navigation menu</h2>
    <div id="mw-head">
        
<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
	<h3 id="p-personal-label">Personal tools</h3>
	<ul >
		
		<li id="pt-anonuserpage">Not logged in</li>
		<li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Linear+discriminant+analysis" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Linear+discriminant+analysis" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>
	</ul>
</div>

        <div id="left-navigation">
            <div id="p-namespaces" role="navigation" class="vectorTabs " aria-labelledby="p-namespaces-label">
	<h3 id="p-namespaces-label">Namespaces</h3>
	<ul >
		<li id="ca-nstab-main" class="selected"><a href="/wiki/Linear_discriminant_analysis" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Linear_discriminant_analysis" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></li>
	</ul>
</div>
<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
	<h3 id="p-variants-label">
		<span>Variants</span>
	</h3>
	<ul class="menu" >
		
	</ul>
</div>

        </div>
        <div id="right-navigation">
            <div id="p-views" role="navigation" class="vectorTabs " aria-labelledby="p-views-label">
	<h3 id="p-views-label">Views</h3>
	<ul >
		<li id="ca-view" class="collapsible selected"><a href="/wiki/Linear_discriminant_analysis">Read</a></li><li id="ca-edit" class="collapsible"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history" class="collapsible"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li>
	</ul>
</div>
<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
	<h3 id="p-cactions-label">
		<span>More</span>
	</h3>
	<ul class="menu" >
		
	</ul>
</div>
<div id="p-search" role="search">
	<h3 >
		<label for="searchInput">Search</label>
	</h3>
	<form action="/w/index.php" id="searchform">
		<div id="simpleSearch">
			<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/>
			<input type="hidden" value="Special:Search" name="title"/>
			<input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/>
			<input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>
		</div>
	</form>
</div>

        </div>
    </div>
    
<div id="mw-panel">
	<div id="p-logo" role="banner">
		<a  title="Visit the main page" class="mw-wiki-logo" href="/wiki/Main_Page"></a>
	</div>
	<div class="portal" role="navigation" id="p-navigation"  aria-labelledby="p-navigation-label">
		<h3  id="p-navigation-label">
			Navigation
		</h3>
		<div class="body">
			<ul><li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Wikipedia:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li></ul>
			
		</div>
	</div>
	
	<div class="portal" role="navigation" id="p-interaction"  aria-labelledby="p-interaction-label">
		<h3  id="p-interaction-label">
			Interaction
		</h3>
		<div class="body">
			<ul><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li></ul>
			
		</div>
	</div>
	
	<div class="portal" role="navigation" id="p-tb"  aria-labelledby="p-tb-label">
		<h3  id="p-tb-label">
			Tools
		</h3>
		<div class="body">
			<ul><li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Linear_discriminant_analysis" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Linear_discriminant_analysis" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;oldid=945697526" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q1228929" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Linear_discriminant_analysis&amp;id=945697526" title="Information on how to cite this page">Cite this page</a></li></ul>
			
		</div>
	</div>
	
	<div class="portal" role="navigation" id="p-wikibase-otherprojects"  aria-labelledby="p-wikibase-otherprojects-label">
		<h3  id="p-wikibase-otherprojects-label">
			In other projects
		</h3>
		<div class="body">
			<ul><li class="wb-otherproject-link wb-otherproject-commons"><a href="https://commons.wikimedia.org/wiki/Category:Discriminant_analysis" hreflang="en">Wikimedia Commons</a></li></ul>
			
		</div>
	</div>
	
	<div class="portal" role="navigation" id="p-coll-print_export"  aria-labelledby="p-coll-print_export-label">
		<h3  id="p-coll-print_export-label">
			Print/export
		</h3>
		<div class="body">
			<ul><li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Linear+discriminant+analysis">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Linear+discriminant+analysis&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Linear_discriminant_analysis&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li></ul>
			
		</div>
	</div>
	
	<div class="portal" role="navigation" id="p-lang"  aria-labelledby="p-lang-label">
		<h3  id="p-lang-label">
			Languages
		</h3>
		<div class="body">
			<ul><li class="interlanguage-link interwiki-ar"><a href="https://ar.wikipedia.org/wiki/%D8%AA%D8%AD%D9%84%D9%8A%D9%84_%D8%A7%D9%84%D8%AA%D9%85%D9%8A%D9%8A%D8%B2_%D8%A7%D9%84%D8%AE%D8%B7%D9%8A" title="تحليل التمييز الخطي – Arabic" lang="ar" hreflang="ar" class="interlanguage-link-target">العربية</a></li><li class="interlanguage-link interwiki-de"><a href="https://de.wikipedia.org/wiki/Diskriminanzfunktion" title="Diskriminanzfunktion – German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/An%C3%A1lisis_discriminante_lineal" title="Análisis discriminante lineal – Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-eo"><a href="https://eo.wikipedia.org/wiki/Lineara_diskriminanta_analitiko" title="Lineara diskriminanta analitiko – Esperanto" lang="eo" hreflang="eo" class="interlanguage-link-target">Esperanto</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D8%A2%D9%86%D8%A7%D9%84%DB%8C%D8%B2_%D8%A7%D9%81%D8%AA%D8%B1%D8%A7%D9%82%DB%8C_%D8%AE%D8%B7%DB%8C" title="آنالیز افتراقی خطی – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Analyse_discriminante_lin%C3%A9aire" title="Analyse discriminante linéaire – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-hr"><a href="https://hr.wikipedia.org/wiki/Linearna_analiza_razli%C4%8Ditih" title="Linearna analiza različitih – Croatian" lang="hr" hreflang="hr" class="interlanguage-link-target">Hrvatski</a></li><li class="interlanguage-link interwiki-id"><a href="https://id.wikipedia.org/wiki/Analisis_diskriminan_linear" title="Analisis diskriminan linear – Indonesian" lang="id" hreflang="id" class="interlanguage-link-target">Bahasa Indonesia</a></li><li class="interlanguage-link interwiki-it"><a href="https://it.wikipedia.org/wiki/Analisi_discriminante_lineare" title="Analisi discriminante lineare – Italian" lang="it" hreflang="it" class="interlanguage-link-target">Italiano</a></li><li class="interlanguage-link interwiki-hu"><a href="https://hu.wikipedia.org/wiki/Line%C3%A1ris_diszkriminancia-anal%C3%ADzis" title="Lineáris diszkriminancia-analízis – Hungarian" lang="hu" hreflang="hu" class="interlanguage-link-target">Magyar</a></li><li class="interlanguage-link interwiki-pl"><a href="https://pl.wikipedia.org/wiki/Liniowa_analiza_dyskryminacyjna" title="Liniowa analiza dyskryminacyjna – Polish" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D0%B9_%D0%B4%D0%B8%D1%81%D0%BA%D1%80%D0%B8%D0%BC%D0%B8%D0%BD%D0%B0%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7" title="Линейный дискриминантный анализ – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-su"><a href="https://su.wikipedia.org/wiki/Fisher%27s_linear_discriminator" title="Fisher&#039;s linear discriminator – Sundanese" lang="su" hreflang="su" class="interlanguage-link-target">Sunda</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%9B%D1%96%D0%BD%D1%96%D0%B9%D0%BD%D0%B8%D0%B9_%D1%80%D0%BE%D0%B7%D0%B4%D1%96%D0%BB%D1%8E%D0%B2%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D1%96%D0%B7" title="Лінійний розділювальний аналіз – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E7%B7%9A%E6%80%A7%E5%88%A4%E5%88%A5%E5%88%86%E6%9E%90" title="線性判別分析 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li></ul>
			<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q1228929#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
		</div>
	</div>
	
</div>

</div>


<div id="footer" role="contentinfo" >
	<ul id="footer-info" class="">
		<li id="footer-info-lastmod"> This page was last edited on 15 March 2020, at 16:38<span class="anonymous-show">&#160;(UTC)</span>.</li>
		<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
	</ul>
	<ul id="footer-places" class="">
		<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
		<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
		<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
		<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
		<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
		<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
		<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
		<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Linear_discriminant_analysis&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
	</ul>
	<ul id="footer-icons" class="noprint">
		<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a></li>
		<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a></li>
	</ul>
	<div style="clear: both;"></div>
</div>


<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.804","walltime":"1.059","ppvisitednodes":{"value":3859,"limit":1000000},"postexpandincludesize":{"value":220386,"limit":2097152},"templateargumentsize":{"value":4777,"limit":2097152},"expansiondepth":{"value":15,"limit":40},"expensivefunctioncount":{"value":12,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":93334,"limit":5000000},"entityaccesscount":{"value":8,"limit":400},"timingprofile":["100.00%  745.749      1 -total"," 48.15%  359.085      1 Template:Reflist"," 40.87%  304.796     19 Template:Cite_journal"," 15.20%  113.344      1 Template:Statistics"," 14.76%  110.047      5 Template:Clarify"," 14.55%  108.516      1 Template:Navbox_with_collapsible_groups"," 13.33%   99.414      5 Template:Fix-span","  8.97%   66.869     12 Template:Category_handler","  7.54%   56.224     11 Template:Navbox","  4.66%   34.788      5 Template:Replace"]},"scribunto":{"limitreport-timeusage":{"value":"0.375","limit":"10.000"},"limitreport-memusage":{"value":7049742,"limit":52428800},"limitreport-logs":"table#1 {\n}\n"},"cachereport":{"origin":"mw1381","timestamp":"20200315163756","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Linear discriminant analysis","url":"https:\/\/en.wikipedia.org\/wiki\/Linear_discriminant_analysis","sameAs":"http:\/\/www.wikidata.org\/entity\/Q1228929","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q1228929","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2005-02-05T22:31:51Z","dateModified":"2020-03-15T16:38:11Z","headline":"method used in statistics, pattern recognition and machine learning"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":97,"wgHostname":"mw1384"});});</script></body></html>
