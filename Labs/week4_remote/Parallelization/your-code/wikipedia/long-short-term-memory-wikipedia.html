
<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Long short-term memory - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"XngcawpAICMAAFJTf7MAAAAB","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Long_short-term_memory","wgTitle":"Long short-term memory","wgCurRevisionId":946900344,"wgRevisionId":946900344,"wgArticleId":10711453,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["All articles with unsourced statements","Articles with unsourced statements from October 2017","Artificial neural networks"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Long_short-term_memory","wgRelevantArticleId":10711453,"wgIsProbablyEditable":!0,
"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q6673524","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.toc.styles":"ready","skins.vector.styles.legacy":"ready","wikibase.client.init":"ready",
"ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.startup","skins.vector.js","mediawiki.page.ready","mediawiki.toc","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.toc.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.35.0-wmf.24"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/1200px-The_LSTM_cell.png"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Long_short-term_memory&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Long_short-term_memory&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Long_short-term_memory"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Long_short-term_memory rootpage-Long_short-term_memory skin-vector action-view">
<div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading" class="firstHeading" lang="en">Long short-term memory</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
		<div id="contentSub"></div>
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#p-search">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a> and<br /><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0.2em 0 0.4em;padding:0.25em 0.25em 0.75em;"><a href="/wiki/File:Kernel_Machine.svg" class="image"><img alt="Kernel Machine.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/220px-Kernel_Machine.svg.png" decoding="async" width="220" height="100" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/330px-Kernel_Machine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png 2x" data-file-width="512" data-file-height="233" /></a></td></tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>
<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>
<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>
<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>
<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>
<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>
<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>
<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>
<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>
<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>
<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>
<li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>
<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>
<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>
<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br /><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b>&#160;&#8226;&#32;<b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>
<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>
<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>
<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>
<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>
<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>
<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>
<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>
<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>
<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>
<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>
<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>
<li><a href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>
<li><a href="/wiki/CURE_data_clustering_algorithm" class="mw-redirect" title="CURE data clustering algorithm">CURE</a></li>
<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>
<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>
<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation–maximization algorithm">Expectation–maximization (EM)</a></li>
<li><br /><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>
<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>
<li><a href="/wiki/Mean-shift" class="mw-redirect" title="Mean-shift">Mean-shift</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>
<li><a href="/wiki/Canonical_correlation_analysis" class="mw-redirect" title="Canonical correlation analysis">CCA</a></li>
<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>
<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>
<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>
<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>
<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>
<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>
<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>
<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/K-nearest_neighbors_classification" class="mw-redirect" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>
<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>
<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>
<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>
<ul><li><a class="mw-selflink selflink">LSTM</a></li>
<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li></ul></li>
<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>
<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>
<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>
<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>
<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>
<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State–action–reward–state–action">SARSA</a></li>
<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Bias%E2%80%93variance_dilemma" class="mw-redirect" title="Bias–variance dilemma">Bias–variance dilemma</a></li>
<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>
<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>
<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>
<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>
<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik–Chervonenkis theory">VC theory</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NeurIPS</a></li>
<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>
<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>
<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>
<li><a rel="nofollow" class="external text" href="https://arxiv.org/list/cs.LG/recent">ArXiv:cs.LG</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>
<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>
</div></div></div></td>
</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<div class="thumb tright"><div class="thumbinner" style="width:172px;"><a href="/wiki/File:The_LSTM_cell.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/170px-The_LSTM_cell.png" decoding="async" width="170" height="112" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/255px-The_LSTM_cell.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/340px-The_LSTM_cell.png 2x" data-file-width="2014" data-file-height="1322" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:The_LSTM_cell.png" class="internal" title="Enlarge"></a></div>The Long Short-Term Memory (LSTM) cell can process data sequentially and keep its hidden state through time.</div></div></div>
<p><b>Long short-term memory</b> (<b>LSTM</b>) is an artificial <a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">recurrent neural network</a> (RNN) architecture<sup id="cite_ref-lstm1997_1-0" class="reference"><a href="#cite_note-lstm1997-1">&#91;1&#93;</a></sup> used in the field of <a href="/wiki/Deep_learning" title="Deep learning">deep learning</a>. Unlike standard <a href="/wiki/Feedforward_neural_network" title="Feedforward neural network">feedforward neural networks</a>, LSTM has feedback connections. It can not only process single data points (such as images), but also entire sequences of data (such as speech or video). For example, LSTM is applicable to tasks such as unsegmented, connected <a href="/wiki/Handwriting_recognition" title="Handwriting recognition">handwriting recognition</a><sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup>, <a href="/wiki/Speech_recognition" title="Speech recognition">speech recognition</a><sup id="cite_ref-sak2014_3-0" class="reference"><a href="#cite_note-sak2014-3">&#91;3&#93;</a></sup><sup id="cite_ref-liwu2015_4-0" class="reference"><a href="#cite_note-liwu2015-4">&#91;4&#93;</a></sup> and anomaly detection in network traffic or IDS's (intrusion detection systems).
</p><p>A common LSTM unit is composed of a <b>cell</b>, an <b>input gate</b>, an <b>output gate</b> and a <b>forget gate</b>. The cell remembers values over arbitrary time intervals and the three <i>gates</i> regulate the flow of information into and out of the cell.
</p><p>LSTM networks are well-suited to <a href="/wiki/Classification_in_machine_learning" class="mw-redirect" title="Classification in machine learning">classifying</a>, <a href="/wiki/Computer_data_processing" class="mw-redirect" title="Computer data processing">processing</a> and <a href="/wiki/Predict" class="mw-redirect" title="Predict">making predictions</a> based on <a href="/wiki/Time_series" title="Time series">time series</a> data, since there can be lags of unknown duration between important events in a time series. LSTMs were developed to deal with the exploding and <a href="/wiki/Vanishing_gradient_problem" title="Vanishing gradient problem">vanishing gradient problems</a> that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, <a href="/wiki/Hidden_Markov_models" class="mw-redirect" title="Hidden Markov models">hidden Markov models</a> and other sequence learning methods in numerous applications.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (October 2017)">citation needed</span></a></i>&#93;</sup>
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Idea"><span class="tocnumber">2</span> <span class="toctext">Idea</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Architecture"><span class="tocnumber">3</span> <span class="toctext">Architecture</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Variants"><span class="tocnumber">4</span> <span class="toctext">Variants</span></a>
<ul>
<li class="toclevel-2 tocsection-5"><a href="#LSTM_with_a_forget_gate"><span class="tocnumber">4.1</span> <span class="toctext">LSTM with a forget gate</span></a>
<ul>
<li class="toclevel-3 tocsection-6"><a href="#Variables"><span class="tocnumber">4.1.1</span> <span class="toctext">Variables</span></a></li>
<li class="toclevel-3 tocsection-7"><a href="#Activation_functions"><span class="tocnumber">4.1.2</span> <span class="toctext">Activation functions</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-8"><a href="#Peephole_LSTM"><span class="tocnumber">4.2</span> <span class="toctext">Peephole LSTM</span></a></li>
<li class="toclevel-2 tocsection-9"><a href="#Peephole_convolutional_LSTM"><span class="tocnumber">4.3</span> <span class="toctext">Peephole convolutional LSTM</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-10"><a href="#Training"><span class="tocnumber">5</span> <span class="toctext">Training</span></a>
<ul>
<li class="toclevel-2 tocsection-11"><a href="#CTC_score_function"><span class="tocnumber">5.1</span> <span class="toctext">CTC score function</span></a></li>
<li class="toclevel-2 tocsection-12"><a href="#Alternatives"><span class="tocnumber">5.2</span> <span class="toctext">Alternatives</span></a>
<ul>
<li class="toclevel-3 tocsection-13"><a href="#Success"><span class="tocnumber">5.2.1</span> <span class="toctext">Success</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-14"><a href="#Applications"><span class="tocnumber">6</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1 tocsection-15"><a href="#See_also"><span class="tocnumber">7</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-16"><a href="#References"><span class="tocnumber">8</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-17"><a href="#External_links"><span class="tocnumber">9</span> <span class="toctext">External links</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=1" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>LSTM was proposed in 1997 by <a href="/wiki/Sepp_Hochreiter" title="Sepp Hochreiter">Sepp Hochreiter</a> and <a href="/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Jürgen Schmidhuber</a>.<sup id="cite_ref-lstm1997_1-1" class="reference"><a href="#cite_note-lstm1997-1">&#91;1&#93;</a></sup> By introducing Constant Error Carousel (CEC) units, LSTM deals with the exploding and vanishing gradient problems. The initial version of LSTM block included cells, input and output gates.<sup id="cite_ref-ASearchSpaceOdyssey_5-0" class="reference"><a href="#cite_note-ASearchSpaceOdyssey-5">&#91;5&#93;</a></sup>
</p><p>In 1999, <a href="/wiki/Felix_Gers" title="Felix Gers">Felix Gers</a> and his advisor <a href="/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Jürgen Schmidhuber</a> and Fred Cummins introduced the forget gate (also called “keep gate”) into LSTM architecture,<sup id="cite_ref-lstm1999_6-0" class="reference"><a href="#cite_note-lstm1999-6">&#91;6&#93;</a></sup> 
enabling the LSTM to reset its own state.<sup id="cite_ref-ASearchSpaceOdyssey_5-1" class="reference"><a href="#cite_note-ASearchSpaceOdyssey-5">&#91;5&#93;</a></sup>
</p><p>In 2000, Gers &amp; Schmidhuber &amp; Cummins added peephole connections (connections from the cell to the gates) into the architecture.<sup id="cite_ref-lstm2000_7-0" class="reference"><a href="#cite_note-lstm2000-7">&#91;7&#93;</a></sup> Additionally, the output activation function was omitted.<sup id="cite_ref-ASearchSpaceOdyssey_5-2" class="reference"><a href="#cite_note-ASearchSpaceOdyssey-5">&#91;5&#93;</a></sup>
</p><p>In 2014, Kyunghyun Cho et al. put forward a simplified variant called <a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">Gated recurrent unit</a> (GRU).<sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup>
</p><p>Among other successes, LSTM achieved record results in natural language text compression,<sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup> unsegmented connected <a href="/wiki/Handwriting_recognition" title="Handwriting recognition">handwriting recognition</a><sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup> and won the <a href="/wiki/ICDAR" class="mw-redirect" title="ICDAR">ICDAR</a> handwriting competition (2009). LSTM networks were a major component of a network that achieved a record 17.7% <a href="/wiki/Phoneme" title="Phoneme">phoneme</a> error rate on the classic <a href="/wiki/TIMIT" title="TIMIT">TIMIT</a> natural speech dataset (2013).<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup>
</p><p>As of 2016, major technology companies including <a href="/wiki/Google" title="Google">Google</a>, <a href="/wiki/Apple_Inc." title="Apple Inc.">Apple</a>, and <a href="/wiki/Microsoft" title="Microsoft">Microsoft</a> were using LSTMs as fundamental components in new products.<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">&#91;12&#93;</a></sup> For example, Google used LSTM for speech recognition on the <a href="/wiki/Smartphone" title="Smartphone">smartphone</a>,<sup id="cite_ref-Beau15_13-0" class="reference"><a href="#cite_note-Beau15-13">&#91;13&#93;</a></sup><sup id="cite_ref-GoogleVoiceSearch_14-0" class="reference"><a href="#cite_note-GoogleVoiceSearch-14">&#91;14&#93;</a></sup> for the smart assistant Allo<sup id="cite_ref-GoogleAllo_15-0" class="reference"><a href="#cite_note-GoogleAllo-15">&#91;15&#93;</a></sup> and for <a href="/wiki/Google_Translate" title="Google Translate">Google Translate</a>.<sup id="cite_ref-GoogleTranslate_16-0" class="reference"><a href="#cite_note-GoogleTranslate-16">&#91;16&#93;</a></sup><sup id="cite_ref-WiredGoogleTranslate_17-0" class="reference"><a href="#cite_note-WiredGoogleTranslate-17">&#91;17&#93;</a></sup> <a href="/wiki/Apple_Inc." title="Apple Inc.">Apple</a> uses LSTM for the "Quicktype" function on the <a href="/wiki/IPhone" title="IPhone">iPhone</a><sup id="cite_ref-AppleQuicktype_18-0" class="reference"><a href="#cite_note-AppleQuicktype-18">&#91;18&#93;</a></sup><sup id="cite_ref-AppleQuicktype2_19-0" class="reference"><a href="#cite_note-AppleQuicktype2-19">&#91;19&#93;</a></sup> and for <a href="/wiki/Siri" title="Siri">Siri</a>.<sup id="cite_ref-AppleSiri_20-0" class="reference"><a href="#cite_note-AppleSiri-20">&#91;20&#93;</a></sup> <a href="/wiki/Amazon_Inc." class="mw-redirect" title="Amazon Inc.">Amazon</a> uses LSTM for <a href="/wiki/Amazon_Alexa" title="Amazon Alexa">Amazon Alexa</a>.<sup id="cite_ref-AmazonAlexa_21-0" class="reference"><a href="#cite_note-AmazonAlexa-21">&#91;21&#93;</a></sup>
</p><p>In 2017, Facebook performed some 4.5 billion automatic translations every day using long short-term memory networks.<sup id="cite_ref-FacebookTranslate_22-0" class="reference"><a href="#cite_note-FacebookTranslate-22">&#91;22&#93;</a></sup>
</p><p>In 2017, researchers from <a href="/wiki/Michigan_State_University" title="Michigan State University">Michigan State University</a>, <a href="/wiki/IBM_Research" title="IBM Research">IBM Research</a>, and <a href="/wiki/Cornell_University" title="Cornell University">Cornell University</a> published a study in the Knowledge Discovery and Data Mining (KDD) conference.<sup id="cite_ref-23" class="reference"><a href="#cite_note-23">&#91;23&#93;</a></sup><sup id="cite_ref-24" class="reference"><a href="#cite_note-24">&#91;24&#93;</a></sup><sup id="cite_ref-25" class="reference"><a href="#cite_note-25">&#91;25&#93;</a></sup> Their study describes a novel neural network that performs better on certain data sets than the widely used long short-term memory neural network.
</p><p>Further in 2017 Microsoft reported reaching 95.1% recognition accuracy on the Switchboard corpus, incorporating a vocabulary of 165,000 words. The approach used "dialog session-based long-short-term memory".<sup id="cite_ref-26" class="reference"><a href="#cite_note-26">&#91;26&#93;</a></sup>
</p><p>In 2019, researchers from the <a href="/wiki/University_of_Waterloo" title="University of Waterloo">University of Waterloo</a> proposed a related RNN architecture, derived using the <a href="/wiki/Legendre_polynomials" title="Legendre polynomials">Legendre polynomials</a>, that represents continuous windows of time, and outperforms the LSTM on some memory-related benchmarks.<sup id="cite_ref-27" class="reference"><a href="#cite_note-27">&#91;27&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Idea">Idea</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=2" title="Edit section: Idea">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In theory, classic (or "vanilla") <a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNNs</a> can keep track of arbitrary long-term dependencies in the input sequences. The problem of vanilla RNNs is computational (or practical) in nature: when training a vanilla RNN using <a href="/wiki/Back-propagation" class="mw-redirect" title="Back-propagation">back-propagation</a>, the gradients which are back-propagated can <a href="/wiki/Vanishing_gradient_problem" title="Vanishing gradient problem">"vanish" (that is, they can tend to zero) or "explode" (that is, they can tend to infinity)</a>, because of the computations involved in the process, which use <a href="/wiki/Round-off_error" title="Round-off error">finite-precision numbers</a>. RNNs using LSTM units partially solve the <a href="/wiki/Vanishing_gradient_problem" title="Vanishing gradient problem">vanishing gradient problem</a>, because LSTM units allow gradients to also flow <i>unchanged</i>. However, LSTM networks can still suffer from the exploding gradient problem.<sup id="cite_ref-28" class="reference"><a href="#cite_note-28">&#91;28&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Architecture">Architecture</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=3" title="Edit section: Architecture">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>There are several architectures of LSTM units. A common architecture is composed of a <b>cell</b> (the memory part of the LSTM unit) and three "regulators", usually called gates, of the flow of information inside the LSTM unit: an <b>input gate</b>, an <b>output gate</b> and a <b>forget gate</b>. Some variations of the LSTM unit do not have one or more of these gates or maybe have other gates. For example, <a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">gated recurrent units</a> (GRUs) do not have an output gate.
</p><p>Intuitively, the <i>cell</i> is responsible for keeping track of the dependencies between the elements in the input sequence. The <i>input gate</i> controls the extent to which a new value flows into the cell, the <i>forget gate</i> controls the extent to which a value remains in the cell and the <i>output gate</i> controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit. The activation function of the LSTM <i>gates</i> is often the <a href="/wiki/Logistic_sigmoid_function" class="mw-redirect" title="Logistic sigmoid function">logistic sigmoid function</a>.
</p><p>There are connections into and out of the LSTM <i>gates</i>, a few of which are recurrent. The weights of these connections, which need to be learned during <a href="/wiki/Supervised_learning" title="Supervised learning">training</a>, determine how the gates operate.
</p>
<h2><span class="mw-headline" id="Variants">Variants</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=4" title="Edit section: Variants">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In the equations below, the lowercase variables represent vectors. Matrices <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle W_{q}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>W</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>q</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle W_{q}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d16355ad959593cf720b24fffe62d99af53d15d9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:3.182ex; height:2.843ex;" alt="{\displaystyle W_{q}}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle U_{q}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>U</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>q</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle U_{q}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/05e27486afb11613504d6d6b9f6bd72e322607c8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:2.576ex; height:2.843ex;" alt="{\displaystyle U_{q}}"/></span> contain, respectively, the weights of the input and recurrent connections, where the subscript <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle _{q}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>q</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle _{q}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e333a711146f91533eb5a030accc0e90948e4f92" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:0.989ex; height:1.676ex;" alt="{\displaystyle _{q}}"/></span> can either be the input gate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/add78d8608ad86e54951b8c8bd6c8d8416533d20" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.802ex; height:2.176ex;" alt="i"/></span>, output gate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle o}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>o</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle o}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0c1031f61947aa3d1cf3a70ec3e4904df2c3675d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.128ex; height:1.676ex;" alt="o"/></span>, the forget gate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span> or the memory cell <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/86a67b81c2de995bd608d5b2df50cd8cd7d92455" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;" alt="c"/></span>, depending on the activation being calculated. In this section, we are thus using a "vector notation". So, for example, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/65d6f2af820422ed59a0f14af91eee7498ebc4a2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.531ex; height:3.009ex;" alt="{\displaystyle c_{t}\in \mathbb {R} ^{h}}"/></span> is not just one cell of one LSTM unit, but contains <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle h}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>h</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle h}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b26be3e694314bc90c3215047e4a2010c6ee184a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.339ex; height:2.176ex;" alt="h"/></span> LSTM unit's cells.
</p>
<h3><span class="mw-headline" id="LSTM_with_a_forget_gate">LSTM with a forget gate</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=5" title="Edit section: LSTM with a forget gate">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The compact forms of the equations for the forward pass of an LSTM unit with a forget gate are:<sup id="cite_ref-lstm1997_1-2" class="reference"><a href="#cite_note-lstm1997-1">&#91;1&#93;</a></sup><sup id="cite_ref-lstm2000_7-1" class="reference"><a href="#cite_note-lstm2000-7">&#91;7&#93;</a></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}h_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}h_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}h_{t-1}+b_{o})\\{\tilde {c}}_{t}&amp;=\sigma _{h}(W_{c}x_{t}+U_{c}h_{t-1}+b_{c})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ {\tilde {c}}_{t}\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mrow class="MJX-TeXAtom-ORD">
                      <mover>
                        <mi>c</mi>
                        <mo stretchy="false">&#x007E;<!-- ~ --></mo>
                      </mover>
                    </mrow>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>h</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mrow class="MJX-TeXAtom-ORD">
                      <mover>
                        <mi>c</mi>
                        <mo stretchy="false">&#x007E;<!-- ~ --></mo>
                      </mover>
                    </mrow>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>h</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}h_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}h_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}h_{t-1}+b_{o})\\{\tilde {c}}_{t}&amp;=\sigma _{h}(W_{c}x_{t}+U_{c}h_{t-1}+b_{c})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ {\tilde {c}}_{t}\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9ab6a5ae30420f35bca913d4af146d7c69a68988" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -8.838ex; width:30.463ex; height:18.843ex;" alt="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}h_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}h_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}h_{t-1}+b_{o})\\{\tilde {c}}_{t}&amp;=\sigma _{h}(W_{c}x_{t}+U_{c}h_{t-1}+b_{c})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ {\tilde {c}}_{t}\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}"/></span></dd></dl>
<p>where the initial values are <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c_{0}=0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{0}=0}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/29af3d4e887815bb3b9b9eab4f7540a376fccd73" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:6.322ex; height:2.509ex;" alt="c_{0}=0"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle h_{0}=0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>h</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle h_{0}=0}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/14a294b6cf9cbde4c37efd966913a63d316e615c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:6.654ex; height:2.509ex;" alt="{\displaystyle h_{0}=0}"/></span> and the operator <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \circ }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>&#x2218;<!-- ∘ --></mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \circ }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/99add39d2b681e2de7ff62422c32704a05c7ec31" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: 0.125ex; margin-bottom: -0.297ex; width:1.162ex; height:1.509ex;" alt="\circ "/></span> denotes the <a href="/wiki/Hadamard_product_(matrices)" title="Hadamard product (matrices)">Hadamard product</a> (element-wise product). The subscript <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle t}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/65658b7b223af9e1acc877d848888ecdb4466560" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.84ex; height:2.009ex;" alt="t"/></span> indexes the time step.
</p>
<h4><span class="mw-headline" id="Variables">Variables</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=6" title="Edit section: Variables">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<ul><li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x_{t}\in \mathbb {R} ^{d}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>d</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{t}\in \mathbb {R} ^{d}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d528d57c5517e90795e0a6d6760463564236fee7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.766ex; height:3.009ex;" alt="{\displaystyle x_{t}\in \mathbb {R} ^{d}}"/></span>: input vector to the LSTM unit</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/02547735a64d79c553b23eaf3aeaaaf2fcde6eba" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.663ex; height:3.009ex;" alt="{\displaystyle f_{t}\in \mathbb {R} ^{h}}"/></span>: forget gate's activation vector</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>i</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/abb830b2d64edaa2aa92edaeccdcb027afa7344e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.326ex; height:3.009ex;" alt="{\displaystyle i_{t}\in \mathbb {R} ^{h}}"/></span>: input/update gate's activation vector</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle o_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>o</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle o_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/25b8c014b13f62fbe82f9a277a71f6a10c2ae330" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.651ex; height:3.009ex;" alt="{\displaystyle o_{t}\in \mathbb {R} ^{h}}"/></span>: output gate's activation vector</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle h_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>h</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle h_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cf6b05b4bd0106b70d036400f1ddd3ae54be2689" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.863ex; height:3.009ex;" alt="{\displaystyle h_{t}\in \mathbb {R} ^{h}}"/></span>: hidden state vector also known as output vector of the LSTM unit</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\tilde {c}}_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>c</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\tilde {c}}_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/017c48f0975511aaac8e4ea5b5cecd664283d016" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.815ex; height:3.009ex;" alt="{\displaystyle {\tilde {c}}_{t}\in \mathbb {R} ^{h}}"/></span>: cell input activation vector</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/65d6f2af820422ed59a0f14af91eee7498ebc4a2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.531ex; height:3.009ex;" alt="{\displaystyle c_{t}\in \mathbb {R} ^{h}}"/></span>: cell state vector</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle W\in \mathbb {R} ^{h\times d}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>W</mi>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
            <mo>&#x00D7;<!-- × --></mo>
            <mi>d</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle W\in \mathbb {R} ^{h\times d}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/925afdb42f13f1d912db87ecda65135eb9fe6352" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:10.271ex; height:2.676ex;" alt="{\displaystyle W\in \mathbb {R} ^{h\times d}}"/></span>, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle U\in \mathbb {R} ^{h\times h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>U</mi>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
            <mo>&#x00D7;<!-- × --></mo>
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle U\in \mathbb {R} ^{h\times h}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0ff9bb53a5409a1e51f6130b3dfbcdad63324880" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:9.706ex; height:2.676ex;" alt="{\displaystyle U\in \mathbb {R} ^{h\times h}}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle b\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>b</mi>
        <mo>&#x2208;<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle b\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/289515b23d7df7e2e09f2ee38951abf345e60080" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:6.695ex; height:2.676ex;" alt="{\displaystyle b\in \mathbb {R} ^{h}}"/></span>: weight matrices and bias vector parameters which need to be learned during training</li></ul>
<p>where the superscripts <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle d}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>d</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle d}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e85ff03cbe0c7341af6b982e47e9f90d235c66ab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.216ex; height:2.176ex;" alt="d"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle h}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>h</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle h}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b26be3e694314bc90c3215047e4a2010c6ee184a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.339ex; height:2.176ex;" alt="h"/></span> refer to the number of input features and number of hidden units, respectively.
</p>
<h4><span class="mw-headline" id="Activation_functions"><a href="/wiki/Activation_function" title="Activation function">Activation functions</a></span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=7" title="Edit section: Activation functions">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<ul><li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sigma _{g}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03C3;<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>g</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma _{g}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/086f92de077f853afd7f5d22fb3d305cbf5e0ac3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:2.349ex; height:2.343ex;" alt="\sigma _{g}"/></span>: <a href="/wiki/Sigmoid_function" title="Sigmoid function">sigmoid function</a>.</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sigma _{c}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03C3;<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>c</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma _{c}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b436b43abda74fce1a6859e03d34c914c6a240f4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.272ex; height:2.009ex;" alt="\sigma_c"/></span>: <a href="/wiki/Hyperbolic_tangent" class="mw-redirect" title="Hyperbolic tangent">hyperbolic tangent</a> function.</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sigma _{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03C3;<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma _{h}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8a7f19495f5a65d26570b54b7ca332956d27b27b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.506ex; height:2.009ex;" alt="\sigma _{h}"/></span>: hyperbolic tangent function or, as the peephole LSTM paper<sup id="cite_ref-peepholeLSTM_29-0" class="reference"><a href="#cite_note-peepholeLSTM-29">&#91;29&#93;</a></sup><sup id="cite_ref-peephole2002_30-0" class="reference"><a href="#cite_note-peephole2002-30">&#91;30&#93;</a></sup> suggests, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sigma _{h}(x)=x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03C3;<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma _{h}(x)=x}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/98d34299f4e04f10f7c22e1219bf182712c3e0fc" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:10.074ex; height:2.843ex;" alt="{\displaystyle \sigma _{h}(x)=x}"/></span>.</li></ul>
<h3><span class="mw-headline" id="Peephole_LSTM">Peephole LSTM</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=8" title="Edit section: Peephole LSTM">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="/wiki/File:Peephole_Long_Short-Term_Memory.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/5/53/Peephole_Long_Short-Term_Memory.svg/300px-Peephole_Long_Short-Term_Memory.svg.png" decoding="async" width="300" height="165" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/53/Peephole_Long_Short-Term_Memory.svg/450px-Peephole_Long_Short-Term_Memory.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/53/Peephole_Long_Short-Term_Memory.svg/600px-Peephole_Long_Short-Term_Memory.svg.png 2x" data-file-width="542" data-file-height="298" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Peephole_Long_Short-Term_Memory.svg" class="internal" title="Enlarge"></a></div>A <a href="#Peephole_LSTM">peephole LSTM</a> unit with input (i.e. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/add78d8608ad86e54951b8c8bd6c8d8416533d20" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.802ex; height:2.176ex;" alt="i"/></span>), output (i.e. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle o}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>o</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle o}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0c1031f61947aa3d1cf3a70ec3e4904df2c3675d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.128ex; height:1.676ex;" alt="o"/></span>), and forget (i.e. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span>) gates. Each of these gates can be thought as a "standard" neuron in a feed-forward (or multi-layer) neural network: that is, they compute an activation (using an activation function) of a weighted sum. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i_{t},o_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>i</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>o</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i_{t},o_{t}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cf0b0dee7b12fd921a114101ff11c83e1606a1f8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:4.616ex; height:2.509ex;" alt="{\displaystyle i_{t},o_{t}}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f_{t}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/874c306411e808e8191e8aeb95e3440e1c68d6e9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.965ex; height:2.509ex;" alt="f_{t}"/></span> represent the activations of respectively the input, output and forget gates, at time step <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle t}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/65658b7b223af9e1acc877d848888ecdb4466560" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.84ex; height:2.009ex;" alt="t"/></span>.  The 3 exit arrows from the memory cell <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/86a67b81c2de995bd608d5b2df50cd8cd7d92455" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;" alt="c"/></span> to the 3 gates <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i,o}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
        <mo>,</mo>
        <mi>o</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i,o}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4697b39f565cd54942b9f81d5de46dcdd1174528" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.964ex; height:2.509ex;" alt="{\displaystyle i,o}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span> represent the <i>peephole</i> connections. These peephole connections actually denote the contributions of the activation of the memory cell <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/86a67b81c2de995bd608d5b2df50cd8cd7d92455" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;" alt="c"/></span> at time step <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle t-1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
        <mo>&#x2212;<!-- − --></mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t-1}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a215d9553945bb84b3b5a79cc796fb7d6e0629f0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.505ex; width:4.842ex; height:2.343ex;" alt="t-1"/></span>, i.e. the contribution of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c_{t-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t-1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0b5dbc0177993c2ebd927aee23d88bd263770532" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:3.933ex; height:2.009ex;" alt="{\displaystyle c_{t-1}}"/></span> (and not <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/93578e37f3234419a34df79845836bc0ec5ef76c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.833ex; height:2.009ex;" alt="{\displaystyle c_{t}}"/></span>, as the picture may suggest). In other words, the gates <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i,o}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
        <mo>,</mo>
        <mi>o</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i,o}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4697b39f565cd54942b9f81d5de46dcdd1174528" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.964ex; height:2.509ex;" alt="{\displaystyle i,o}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span> calculate their activations at time step <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle t}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/65658b7b223af9e1acc877d848888ecdb4466560" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.84ex; height:2.009ex;" alt="t"/></span> (i.e., respectively, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i_{t},o_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>i</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>o</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i_{t},o_{t}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cf0b0dee7b12fd921a114101ff11c83e1606a1f8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:4.616ex; height:2.509ex;" alt="{\displaystyle i_{t},o_{t}}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f_{t}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/874c306411e808e8191e8aeb95e3440e1c68d6e9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.965ex; height:2.509ex;" alt="f_{t}"/></span>) also considering the activation of the memory cell <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/86a67b81c2de995bd608d5b2df50cd8cd7d92455" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;" alt="c"/></span> at time step <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle t-1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
        <mo>&#x2212;<!-- − --></mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t-1}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a215d9553945bb84b3b5a79cc796fb7d6e0629f0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.505ex; width:4.842ex; height:2.343ex;" alt="t-1"/></span>, i.e. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c_{t-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t-1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0b5dbc0177993c2ebd927aee23d88bd263770532" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:3.933ex; height:2.009ex;" alt="{\displaystyle c_{t-1}}"/></span>.  The single left-to-right arrow exiting the memory cell is <i>not</i> a peephole connection and denotes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/93578e37f3234419a34df79845836bc0ec5ef76c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.833ex; height:2.009ex;" alt="{\displaystyle c_{t}}"/></span>.  The little circles containing a <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \times }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>&#x00D7;<!-- × --></mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \times }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0ffafff1ad26cbe49045f19a67ce532116a32703" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: 0.019ex; margin-bottom: -0.19ex; width:1.808ex; height:1.509ex;" alt="\times "/></span> symbol represent an element-wise multiplication between its inputs. The big circles containing an <i>S</i>-like curve represent the application of a differentiable function (like the sigmoid function) to a weighted sum.  There are many other kinds of LSTMs as well.<sup id="cite_ref-ASearchSpaceOdyssey_5-3" class="reference"><a href="#cite_note-ASearchSpaceOdyssey-5">&#91;5&#93;</a></sup></div></div></div>
<p>The figure on the right is a graphical representation of an LSTM unit with peephole connections (i.e. a peephole LSTM).<sup id="cite_ref-peepholeLSTM_29-1" class="reference"><a href="#cite_note-peepholeLSTM-29">&#91;29&#93;</a></sup><sup id="cite_ref-peephole2002_30-1" class="reference"><a href="#cite_note-peephole2002-30">&#91;30&#93;</a></sup> Peephole connections allow the gates to access the constant error carousel (CEC), whose activation is the cell state.<sup id="cite_ref-31" class="reference"><a href="#cite_note-31">&#91;31&#93;</a></sup> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle h_{t-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>h</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle h_{t-1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cf56fc7e1114417475762546403f3d66460975d0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:4.265ex; height:2.509ex;" alt="{\displaystyle h_{t-1}}"/></span> is not used, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c_{t-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t-1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0b5dbc0177993c2ebd927aee23d88bd263770532" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:3.933ex; height:2.009ex;" alt="{\displaystyle c_{t-1}}"/></span> is used instead in most places.
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}c_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}c_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}x_{t}+b_{c})\\h_{t}&amp;=\sigma _{h}(o_{t}\circ c_{t})\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>h</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}c_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}c_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}x_{t}+b_{c})\\h_{t}&amp;=\sigma _{h}(o_{t}\circ c_{t})\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d144d712970f336e7f91fcdd78dd1b8946c54996" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -7.338ex; width:34.928ex; height:15.843ex;" alt="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}c_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}c_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}x_{t}+b_{c})\\h_{t}&amp;=\sigma _{h}(o_{t}\circ c_{t})\end{aligned}}}"/></span></dd></dl>
<h3><span class="mw-headline" id="Peephole_convolutional_LSTM">Peephole convolutional LSTM</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=9" title="Edit section: Peephole convolutional LSTM">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Peephole <a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">convolutional</a> LSTM.<sup id="cite_ref-32" class="reference"><a href="#cite_note-32">&#91;32&#93;</a></sup> The <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle *}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>&#x2217;<!-- ∗ --></mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle *}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8e9972f426d9e07855984f73ee195a21dbc21755" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: 0.079ex; margin-bottom: -0.25ex; width:1.162ex; height:1.509ex;" alt="*"/></span> denotes the <a href="/wiki/Convolution" title="Convolution">convolution</a> operator.
</p>
<dl><dd><span class="mwe-math-element" id="Page 4, formula 4 in [33] reference (Ot is calculated for C(t) intead of C(t-1)): https://arxiv.org/abs/1506.04214v2"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}*x_{t}+U_{f}*h_{t-1}+V_{f}\circ c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}*x_{t}+U_{i}*h_{t-1}+V_{i}\circ c_{t-1}+b_{i})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}*x_{t}+U_{c}*h_{t-1}+b_{c})\\o_{t}&amp;=\sigma _{g}(W_{o}*x_{t}+U_{o}*h_{t-1}+V_{o}\circ c_{t}+b_{o})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo>&#x2217;<!-- ∗ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo>&#x2217;<!-- ∗ --></mo>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>V</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo>&#x2217;<!-- ∗ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo>&#x2217;<!-- ∗ --></mo>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>V</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo>&#x2217;<!-- ∗ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo>&#x2217;<!-- ∗ --></mo>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo>&#x2217;<!-- ∗ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo>&#x2217;<!-- ∗ --></mo>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>V</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>&#x2218;<!-- ∘ --></mo>
                <msub>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>h</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}*x_{t}+U_{f}*h_{t-1}+V_{f}\circ c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}*x_{t}+U_{i}*h_{t-1}+V_{i}\circ c_{t-1}+b_{i})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}*x_{t}+U_{c}*h_{t-1}+b_{c})\\o_{t}&amp;=\sigma _{g}(W_{o}*x_{t}+U_{o}*h_{t-1}+V_{o}\circ c_{t}+b_{o})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1edbece2559479959fe829e9c6657efb380debe7" class="mwe-math-fallback-image-inline" id="Page_4,_formula_4_in_[33]_reference_(Ot_is_calculated_for_C(t)_intead_of_C(t-1)):_https://arxiv.org/abs/1506.04214v2" aria-hidden="true" style="vertical-align: -7.338ex; width:48.955ex; height:15.843ex;" alt="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}*x_{t}+U_{f}*h_{t-1}+V_{f}\circ c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}*x_{t}+U_{i}*h_{t-1}+V_{i}\circ c_{t-1}+b_{i})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}*x_{t}+U_{c}*h_{t-1}+b_{c})\\o_{t}&amp;=\sigma _{g}(W_{o}*x_{t}+U_{o}*h_{t-1}+V_{o}\circ c_{t}+b_{o})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}"/></span></dd></dl>
<h2><span class="mw-headline" id="Training">Training</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=10" title="Edit section: Training">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>An RNN using LSTM units can be trained in a supervised fashion, on a set of training sequences, using an optimization algorithm, like <a href="/wiki/Gradient_descent" title="Gradient descent">gradient descent</a>, combined with <a href="/wiki/Backpropagation_through_time" title="Backpropagation through time">backpropagation through time</a> to compute the gradients needed during the optimization process, in order to change each weight of the LSTM network in proportion to the derivative of the error (at the output layer of the LSTM network) with respect to corresponding weight.
</p><p>A problem with using <a href="/wiki/Gradient_descent" title="Gradient descent">gradient descent</a> for standard RNNs is that error gradients <a href="/wiki/Vanishing_gradient_problem" title="Vanishing gradient problem">vanish</a> exponentially quickly with the size of the time lag between important events. This is due to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \lim _{n\to \infty }W^{n}=0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <munder>
          <mo movablelimits="true" form="prefix">lim</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
            <mo stretchy="false">&#x2192;<!-- → --></mo>
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
          </mrow>
        </munder>
        <msup>
          <mi>W</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msup>
        <mo>=</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \lim _{n\to \infty }W^{n}=0}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4f21d24f36ac54c2e3826fe618891ce17b19e12d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.838ex; width:12.647ex; height:3.843ex;" alt="{\displaystyle \lim _{n\to \infty }W^{n}=0}"/></span> if the <a href="/wiki/Spectral_radius" title="Spectral radius">spectral radius</a> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle W}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>W</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle W}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/54a9c4c547f4d6111f81946cad242b18298d70b7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.435ex; height:2.176ex;" alt="W"/></span> is smaller than 1.<sup id="cite_ref-33" class="reference"><a href="#cite_note-33">&#91;33&#93;</a></sup><sup id="cite_ref-gradf_34-0" class="reference"><a href="#cite_note-gradf-34">&#91;34&#93;</a></sup>
</p><p>However, with LSTM units, when error values are back-propagated from the output layer, the error remains in the LSTM unit's cell. This "error carousel" continuously feeds error back to each of the LSTM unit's gates, until they learn to cut off the value.
</p>
<h3><span class="mw-headline" id="CTC_score_function">CTC score function</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=11" title="Edit section: CTC score function">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Many applications use stacks of LSTM RNNs<sup id="cite_ref-fernandez2007_35-0" class="reference"><a href="#cite_note-fernandez2007-35">&#91;35&#93;</a></sup> and train them by <a href="/wiki/Connectionist_temporal_classification_(CTC)" class="mw-redirect" title="Connectionist temporal classification (CTC)">connectionist temporal classification (CTC)</a><sup id="cite_ref-graves2006_36-0" class="reference"><a href="#cite_note-graves2006-36">&#91;36&#93;</a></sup> to find an RNN weight matrix that maximizes the probability of the label sequences in a training set, given the corresponding input sequences. CTC achieves both alignment and recognition.
</p>
<h3><span class="mw-headline" id="Alternatives">Alternatives</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=12" title="Edit section: Alternatives">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Sometimes, it can be advantageous to train (parts of) an LSTM by <a href="/wiki/Neuroevolution" title="Neuroevolution">neuroevolution</a><sup id="cite_ref-wierstra2005_37-0" class="reference"><a href="#cite_note-wierstra2005-37">&#91;37&#93;</a></sup> or by policy gradient methods, especially when there is no "teacher" (that is, training labels).
</p>
<h4><span class="mw-headline" id="Success">Success</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=13" title="Edit section: Success">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>There have been several successful stories of training, in a non-supervised fashion, RNNs with LSTM units.
</p><p>In 2018, <a href="/wiki/Bill_Gates" title="Bill Gates">Bill Gates</a> called it a “huge milestone in advancing artificial intelligence” when bots developed by <a href="/wiki/OpenAI" title="OpenAI">OpenAI</a> were able to beat humans in the game of Dota 2.<sup id="cite_ref-OpenAIfive_38-0" class="reference"><a href="#cite_note-OpenAIfive-38">&#91;38&#93;</a></sup> OpenAI Five consists of five independent but coordinated neural networks. Each network is trained by a policy gradient method without supervising teacher and contains a single-layer, 1024-unit Long-Short-Term-Memory that sees the current game state and emits actions through several possible action heads.<sup id="cite_ref-OpenAIfive_38-1" class="reference"><a href="#cite_note-OpenAIfive-38">&#91;38&#93;</a></sup>
</p><p>In 2018, <a href="/wiki/OpenAI" title="OpenAI">OpenAI</a> also trained a similar LSTM by policy gradients to control a human-like robot hand that manipulates physical objects with unprecedented dexterity.<sup id="cite_ref-OpenAIhand_39-0" class="reference"><a href="#cite_note-OpenAIhand-39">&#91;39&#93;</a></sup>
</p><p>In 2019, <a href="/wiki/DeepMind" title="DeepMind">DeepMind</a>'s program AlphaStar used a deep LSTM core to excel at the complex video game <a href="/wiki/Starcraft_II" class="mw-redirect" title="Starcraft II">Starcraft II</a>.<sup id="cite_ref-alphastar_40-0" class="reference"><a href="#cite_note-alphastar-40">&#91;40&#93;</a></sup> This was viewed as significant progress towards Artificial General Intelligence.<sup id="cite_ref-alphastar_40-1" class="reference"><a href="#cite_note-alphastar-40">&#91;40&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=14" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Applications of LSTM include:
</p>
<ul><li><a href="/wiki/Robot_control" title="Robot control">Robot control</a><sup id="cite_ref-41" class="reference"><a href="#cite_note-41">&#91;41&#93;</a></sup></li>
<li><a href="/wiki/Time_series_prediction" class="mw-redirect" title="Time series prediction">Time series prediction</a><sup id="cite_ref-wierstra2005_37-1" class="reference"><a href="#cite_note-wierstra2005-37">&#91;37&#93;</a></sup></li>
<li><a href="/wiki/Speech_recognition" title="Speech recognition">Speech recognition</a><sup id="cite_ref-42" class="reference"><a href="#cite_note-42">&#91;42&#93;</a></sup><sup id="cite_ref-43" class="reference"><a href="#cite_note-43">&#91;43&#93;</a></sup><sup id="cite_ref-ReferenceA_44-0" class="reference"><a href="#cite_note-ReferenceA-44">&#91;44&#93;</a></sup></li>
<li>Rhythm learning<sup id="cite_ref-peephole2002_30-2" class="reference"><a href="#cite_note-peephole2002-30">&#91;30&#93;</a></sup></li>
<li>Music composition<sup id="cite_ref-45" class="reference"><a href="#cite_note-45">&#91;45&#93;</a></sup></li>
<li>Grammar learning<sup id="cite_ref-46" class="reference"><a href="#cite_note-46">&#91;46&#93;</a></sup><sup id="cite_ref-peepholeLSTM_29-2" class="reference"><a href="#cite_note-peepholeLSTM-29">&#91;29&#93;</a></sup><sup id="cite_ref-47" class="reference"><a href="#cite_note-47">&#91;47&#93;</a></sup></li>
<li><a href="/wiki/Handwriting_recognition" title="Handwriting recognition">Handwriting recognition</a><sup id="cite_ref-48" class="reference"><a href="#cite_note-48">&#91;48&#93;</a></sup><sup id="cite_ref-49" class="reference"><a href="#cite_note-49">&#91;49&#93;</a></sup></li>
<li>Human action recognition<sup id="cite_ref-50" class="reference"><a href="#cite_note-50">&#91;50&#93;</a></sup></li>
<li><a href="/wiki/Sign_language" title="Sign language">Sign Language Translation</a><sup id="cite_ref-51" class="reference"><a href="#cite_note-51">&#91;51&#93;</a></sup></li>
<li>Protein Homology Detection<sup id="cite_ref-52" class="reference"><a href="#cite_note-52">&#91;52&#93;</a></sup></li>
<li>Predicting subcellular localization of proteins<sup id="cite_ref-53" class="reference"><a href="#cite_note-53">&#91;53&#93;</a></sup></li>
<li>Time series anomaly detection<sup id="cite_ref-54" class="reference"><a href="#cite_note-54">&#91;54&#93;</a></sup></li>
<li>Several prediction tasks in the area of business process management<sup id="cite_ref-55" class="reference"><a href="#cite_note-55">&#91;55&#93;</a></sup></li>
<li>Prediction in medical care pathways<sup id="cite_ref-56" class="reference"><a href="#cite_note-56">&#91;56&#93;</a></sup></li>
<li><a href="/wiki/Semantic_parsing" title="Semantic parsing">Semantic parsing</a><sup id="cite_ref-57" class="reference"><a href="#cite_note-57">&#91;57&#93;</a></sup></li>
<li><a href="/wiki/Object_Co-segmentation" title="Object Co-segmentation">Object Co-segmentation</a><sup id="cite_ref-Wang_Duan_Zhang_Niu_p=1657_58-0" class="reference"><a href="#cite_note-Wang_Duan_Zhang_Niu_p=1657-58">&#91;58&#93;</a></sup><sup id="cite_ref-Duan_Wang_Zhai_Zheng_2018_p._59-0" class="reference"><a href="#cite_note-Duan_Wang_Zhai_Zheng_2018_p.-59">&#91;59&#93;</a></sup></li>
<li>Airport passenger management<sup id="cite_ref-60" class="reference"><a href="#cite_note-60">&#91;60&#93;</a></sup></li>
<li>Short-term <a href="/wiki/Traffic_forecast" class="mw-redirect" title="Traffic forecast">traffic forecast</a><sup id="cite_ref-61" class="reference"><a href="#cite_note-61">&#91;61&#93;</a></sup></li></ul>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=15" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">Recurrent neural network</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">Gated recurrent unit</a></li>
<li><a href="/wiki/Differentiable_neural_computer" title="Differentiable neural computer">Differentiable neural computer</a></li>
<li><a href="/wiki/Long-term_potentiation" title="Long-term potentiation">Long-term potentiation</a></li>
<li><a href="/wiki/Prefrontal_cortex_basal_ganglia_working_memory" title="Prefrontal cortex basal ganglia working memory">Prefrontal cortex basal ganglia working memory</a></li>
<li><a href="/wiki/Time_series" title="Time series">Time series</a></li>
<li><a href="/wiki/Seq2seq" title="Seq2seq">Seq2seq</a></li>
<li><a href="/wiki/Highway_network" title="Highway network">Highway network</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=16" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-lstm1997-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-lstm1997_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-lstm1997_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-lstm1997_1-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal"><a href="/wiki/Sepp_Hochreiter" title="Sepp Hochreiter">Sepp Hochreiter</a>; <a href="/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Jürgen Schmidhuber</a> (1997). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/13853244">"Long short-term memory"</a>. <i><a href="/wiki/Neural_Computation_(journal)" title="Neural Computation (journal)">Neural Computation</a></i>. <b>9</b> (8): 1735–1780. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2Fneco.1997.9.8.1735">10.1162/neco.1997.9.8.1735</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/9377276">9377276</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Computation&amp;rft.atitle=Long+short-term+memory&amp;rft.volume=9&amp;rft.issue=8&amp;rft.pages=1735-1780&amp;rft.date=1997&amp;rft_id=info%3Adoi%2F10.1162%2Fneco.1997.9.8.1735&amp;rft_id=info%3Apmid%2F9377276&amp;rft.au=Sepp+Hochreiter&amp;rft.au=J%C3%BCrgen+Schmidhuber&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F13853244&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r935243608">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite class="citation journal">Graves, A.; Liwicki, M.; Fernandez, S.; Bertolami, R.; Bunke, H.; <a href="/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Schmidhuber, J.</a> (2009). <a rel="nofollow" class="external text" href="http://www.idsia.ch/~juergen/tpami_2008.pdf">"A Novel Connectionist System for Improved Unconstrained Handwriting Recognition"</a> <span class="cs1-format">(PDF)</span>. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>. <b>31</b> (5): 855–868. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.139.4502">10.1.1.139.4502</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2Ftpami.2008.137">10.1109/tpami.2008.137</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/19299860">19299860</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence&amp;rft.atitle=A+Novel+Connectionist+System+for+Improved+Unconstrained+Handwriting+Recognition&amp;rft.volume=31&amp;rft.issue=5&amp;rft.pages=855-868&amp;rft.date=2009&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.139.4502&amp;rft_id=info%3Apmid%2F19299860&amp;rft_id=info%3Adoi%2F10.1109%2Ftpami.2008.137&amp;rft.aulast=Graves&amp;rft.aufirst=A.&amp;rft.au=Liwicki%2C+M.&amp;rft.au=Fernandez%2C+S.&amp;rft.au=Bertolami%2C+R.&amp;rft.au=Bunke%2C+H.&amp;rft.au=Schmidhuber%2C+J.&amp;rft_id=http%3A%2F%2Fwww.idsia.ch%2F~juergen%2Ftpami_2008.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-sak2014-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-sak2014_3-0">^</a></b></span> <span class="reference-text"><cite class="citation web">Sak, Hasim; Senior, Andrew; Beaufays, Francoise (2014). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20180424203806/https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43905.pdf">"Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling"</a> <span class="cs1-format">(PDF)</span>. Archived from <a rel="nofollow" class="external text" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43905.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2018-04-24.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Long+Short-Term+Memory+recurrent+neural+network+architectures+for+large+scale+acoustic+modeling&amp;rft.date=2014&amp;rft.aulast=Sak&amp;rft.aufirst=Hasim&amp;rft.au=Senior%2C+Andrew&amp;rft.au=Beaufays%2C+Francoise&amp;rft_id=https%3A%2F%2Fstatic.googleusercontent.com%2Fmedia%2Fresearch.google.com%2Fen%2F%2Fpubs%2Farchive%2F43905.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-liwu2015-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-liwu2015_4-0">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Li, Xiangang; Wu, Xihong (2014-10-15). "Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1410.4281">1410.4281</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Constructing+Long+Short-Term+Memory+based+Deep+Recurrent+Neural+Networks+for+Large+Vocabulary+Speech+Recognition&amp;rft.date=2014-10-15&amp;rft_id=info%3Aarxiv%2F1410.4281&amp;rft.aulast=Li&amp;rft.aufirst=Xiangang&amp;rft.au=Wu%2C+Xihong&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-ASearchSpaceOdyssey-5"><span class="mw-cite-backlink">^ <a href="#cite_ref-ASearchSpaceOdyssey_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-ASearchSpaceOdyssey_5-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-ASearchSpaceOdyssey_5-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-ASearchSpaceOdyssey_5-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Klaus Greff; Rupesh Kumar Srivastava; Jan Koutník; Bas R. Steunebrink; Jürgen Schmidhuber (2015). "LSTM: A Search Space Odyssey". <i>IEEE Transactions on Neural Networks and Learning Systems</i>. <b>28</b> (10): 2222–2232. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1503.04069">1503.04069</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2015arXiv150304069G">2015arXiv150304069G</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FTNNLS.2016.2582924">10.1109/TNNLS.2016.2582924</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/27411231">27411231</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Neural+Networks+and+Learning+Systems&amp;rft.atitle=LSTM%3A+A+Search+Space+Odyssey&amp;rft.volume=28&amp;rft.issue=10&amp;rft.pages=2222-2232&amp;rft.date=2015&amp;rft_id=info%3Aarxiv%2F1503.04069&amp;rft_id=info%3Apmid%2F27411231&amp;rft_id=info%3Adoi%2F10.1109%2FTNNLS.2016.2582924&amp;rft_id=info%3Abibcode%2F2015arXiv150304069G&amp;rft.au=Klaus+Greff&amp;rft.au=Rupesh+Kumar+Srivastava&amp;rft.au=Jan+Koutn%C3%ADk&amp;rft.au=Bas+R.+Steunebrink&amp;rft.au=J%C3%BCrgen+Schmidhuber&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-lstm1999-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-lstm1999_6-0">^</a></b></span> <span class="reference-text"><cite class="citation book">Gers, F.A. (1999). "Learning to forget: Continual prediction with LSTM". <i>9th International Conference on Artificial Neural Networks: ICANN '99</i>. <b>1999</b>. pp.&#160;850–855. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1049%2Fcp%3A19991218">10.1049/cp:19991218</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-85296-721-7" title="Special:BookSources/0-85296-721-7"><bdi>0-85296-721-7</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Learning+to+forget%3A+Continual+prediction+with+LSTM&amp;rft.btitle=9th+International+Conference+on+Artificial+Neural+Networks%3A+ICANN+%2799&amp;rft.pages=850-855&amp;rft.date=1999&amp;rft_id=info%3Adoi%2F10.1049%2Fcp%3A19991218&amp;rft.isbn=0-85296-721-7&amp;rft.aulast=Gers&amp;rft.aufirst=F.A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-lstm2000-7"><span class="mw-cite-backlink">^ <a href="#cite_ref-lstm2000_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-lstm2000_7-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Felix A. Gers; Jürgen Schmidhuber; Fred Cummins (2000). "Learning to Forget: Continual Prediction with LSTM". <i><a href="/wiki/Neural_Computation_(journal)" title="Neural Computation (journal)">Neural Computation</a></i>. <b>12</b> (10): 2451–2471. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.5709">10.1.1.55.5709</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2F089976600300015015">10.1162/089976600300015015</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/11032042">11032042</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Computation&amp;rft.atitle=Learning+to+Forget%3A+Continual+Prediction+with+LSTM&amp;rft.volume=12&amp;rft.issue=10&amp;rft.pages=2451-2471&amp;rft.date=2000&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.55.5709&amp;rft_id=info%3Apmid%2F11032042&amp;rft_id=info%3Adoi%2F10.1162%2F089976600300015015&amp;rft.au=Felix+A.+Gers&amp;rft.au=J%C3%BCrgen+Schmidhuber&amp;rft.au=Fred+Cummins&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Cho, Kyunghyun; van Merrienboer, Bart; Gulcehre, Caglar; Bahdanau, Dzmitry; Bougares, Fethi; Schwenk, Holger; Bengio, Yoshua (2014). "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1406.1078">1406.1078</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Learning+Phrase+Representations+using+RNN+Encoder-Decoder+for+Statistical+Machine+Translation&amp;rft.date=2014&amp;rft_id=info%3Aarxiv%2F1406.1078&amp;rft.aulast=Cho&amp;rft.aufirst=Kyunghyun&amp;rft.au=van+Merrienboer%2C+Bart&amp;rft.au=Gulcehre%2C+Caglar&amp;rft.au=Bahdanau%2C+Dzmitry&amp;rft.au=Bougares%2C+Fethi&amp;rft.au=Schwenk%2C+Holger&amp;rft.au=Bengio%2C+Yoshua&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.mattmahoney.net/dc/text.html#1218">"The Large Text Compression Benchmark"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-01-13</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Large+Text+Compression+Benchmark&amp;rft_id=http%3A%2F%2Fwww.mattmahoney.net%2Fdc%2Ftext.html%231218&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><cite class="citation journal">Graves, A.; Liwicki, M.; Fernández, S.; Bertolami, R.; Bunke, H.; Schmidhuber, J. (May 2009). "A Novel Connectionist System for Unconstrained Handwriting Recognition". <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>. <b>31</b> (5): 855–868. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.139.4502">10.1.1.139.4502</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2Ftpami.2008.137">10.1109/tpami.2008.137</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0162-8828">0162-8828</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/19299860">19299860</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence&amp;rft.atitle=A+Novel+Connectionist+System+for+Unconstrained+Handwriting+Recognition&amp;rft.volume=31&amp;rft.issue=5&amp;rft.pages=855-868&amp;rft.date=2009-05&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.139.4502&amp;rft.issn=0162-8828&amp;rft_id=info%3Apmid%2F19299860&amp;rft_id=info%3Adoi%2F10.1109%2Ftpami.2008.137&amp;rft.aulast=Graves&amp;rft.aufirst=A.&amp;rft.au=Liwicki%2C+M.&amp;rft.au=Fern%C3%A1ndez%2C+S.&amp;rft.au=Bertolami%2C+R.&amp;rft.au=Bunke%2C+H.&amp;rft.au=Schmidhuber%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Graves, Alex; Mohamed, Abdel-rahman; Hinton, Geoffrey (2013-03-22). "Speech Recognition with Deep Recurrent Neural Networks". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1303.5778">1303.5778</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.NE">cs.NE</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Speech+Recognition+with+Deep+Recurrent+Neural+Networks&amp;rft.date=2013-03-22&amp;rft_id=info%3Aarxiv%2F1303.5778&amp;rft.aulast=Graves&amp;rft.aufirst=Alex&amp;rft.au=Mohamed%2C+Abdel-rahman&amp;rft.au=Hinton%2C+Geoffrey&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><cite class="citation journal">Metz, Cade (2016-06-14). <a rel="nofollow" class="external text" href="https://www.wired.com/2016/06/apple-bringing-ai-revolution-iphone/">"Apple is bringing the AI revolution to your iphone"</a>. <i>WIRED</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2016-06-16</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=WIRED&amp;rft.atitle=Apple+is+bringing+the+AI+revolution+to+your+iphone.&amp;rft.date=2016-06-14&amp;rft.aulast=Metz&amp;rft.aufirst=Cade&amp;rft_id=https%3A%2F%2Fwww.wired.com%2F2016%2F06%2Fapple-bringing-ai-revolution-iphone%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-Beau15-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-Beau15_13-0">^</a></b></span> <span class="reference-text"><cite class="citation news">Beaufays, Françoise (August 11, 2015). <a rel="nofollow" class="external text" href="http://googleresearch.blogspot.co.at/2015/08/the-neural-networks-behind-google-voice.html">"The neural networks behind Google Voice transcription"</a>. <i>Research Blog</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Research+Blog&amp;rft.atitle=The+neural+networks+behind+Google+Voice+transcription&amp;rft.date=2015-08-11&amp;rft.aulast=Beaufays&amp;rft.aufirst=Fran%C3%A7oise&amp;rft_id=http%3A%2F%2Fgoogleresearch.blogspot.co.at%2F2015%2F08%2Fthe-neural-networks-behind-google-voice.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-GoogleVoiceSearch-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-GoogleVoiceSearch_14-0">^</a></b></span> <span class="reference-text"><cite class="citation news">Sak, Haşim; Senior, Andrew; Rao, Kanishka; Beaufays, Françoise; Schalkwyk, Johan (September 24, 2015). <a rel="nofollow" class="external text" href="http://googleresearch.blogspot.co.uk/2015/09/google-voice-search-faster-and-more.html">"Google voice search: faster and more accurate"</a>. <i>Research Blog</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Research+Blog&amp;rft.atitle=Google+voice+search%3A+faster+and+more+accurate&amp;rft.date=2015-09-24&amp;rft.aulast=Sak&amp;rft.aufirst=Ha%C5%9Fim&amp;rft.au=Senior%2C+Andrew&amp;rft.au=Rao%2C+Kanishka&amp;rft.au=Beaufays%2C+Fran%C3%A7oise&amp;rft.au=Schalkwyk%2C+Johan&amp;rft_id=http%3A%2F%2Fgoogleresearch.blogspot.co.uk%2F2015%2F09%2Fgoogle-voice-search-faster-and-more.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-GoogleAllo-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-GoogleAllo_15-0">^</a></b></span> <span class="reference-text"><cite class="citation news">Khaitan, Pranav (May 18, 2016). <a rel="nofollow" class="external text" href="http://googleresearch.blogspot.co.at/2016/05/chat-smarter-with-allo.html">"Chat Smarter with Allo"</a>. <i>Research Blog</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Research+Blog&amp;rft.atitle=Chat+Smarter+with+Allo&amp;rft.date=2016-05-18&amp;rft.aulast=Khaitan&amp;rft.aufirst=Pranav&amp;rft_id=http%3A%2F%2Fgoogleresearch.blogspot.co.at%2F2016%2F05%2Fchat-smarter-with-allo.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-GoogleTranslate-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-GoogleTranslate_16-0">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Wu, Yonghui; Schuster, Mike; Chen, Zhifeng; Le, Quoc V.; Norouzi, Mohammad; Macherey, Wolfgang; Krikun, Maxim; Cao, Yuan; Gao, Qin (2016-09-26). "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1609.08144">1609.08144</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Google%27s+Neural+Machine+Translation+System%3A+Bridging+the+Gap+between+Human+and+Machine+Translation&amp;rft.date=2016-09-26&amp;rft_id=info%3Aarxiv%2F1609.08144&amp;rft.aulast=Wu&amp;rft.aufirst=Yonghui&amp;rft.au=Schuster%2C+Mike&amp;rft.au=Chen%2C+Zhifeng&amp;rft.au=Le%2C+Quoc+V.&amp;rft.au=Norouzi%2C+Mohammad&amp;rft.au=Macherey%2C+Wolfgang&amp;rft.au=Krikun%2C+Maxim&amp;rft.au=Cao%2C+Yuan&amp;rft.au=Gao%2C+Qin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-WiredGoogleTranslate-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-WiredGoogleTranslate_17-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Metz, Cade (September 27, 2016). <a rel="nofollow" class="external text" href="https://www.wired.com/2016/09/google-claims-ai-breakthrough-machine-translation/">"An Infusion of AI Makes Google Translate More Powerful Than Ever | WIRED"</a>. <i>Wired</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wired&amp;rft.atitle=An+Infusion+of+AI+Makes+Google+Translate+More+Powerful+Than+Ever+%7C+WIRED&amp;rft.date=2016-09-27&amp;rft.aulast=Metz&amp;rft.aufirst=Cade&amp;rft_id=https%3A%2F%2Fwww.wired.com%2F2016%2F09%2Fgoogle-claims-ai-breakthrough-machine-translation%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-AppleQuicktype-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-AppleQuicktype_18-0">^</a></b></span> <span class="reference-text"><cite class="citation web">Efrati, Amir (June 13, 2016). <a rel="nofollow" class="external text" href="https://www.theinformation.com/apples-machines-can-learn-too">"Apple's Machines Can Learn Too"</a>. <i>The Information</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Information&amp;rft.atitle=Apple%27s+Machines+Can+Learn+Too&amp;rft.date=2016-06-13&amp;rft.aulast=Efrati&amp;rft.aufirst=Amir&amp;rft_id=https%3A%2F%2Fwww.theinformation.com%2Fapples-machines-can-learn-too&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-AppleQuicktype2-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-AppleQuicktype2_19-0">^</a></b></span> <span class="reference-text"><cite class="citation news">Ranger, Steve (June 14, 2016). <a rel="nofollow" class="external text" href="https://www.zdnet.com/article/ai-big-data-and-the-iphone-heres-how-apple-plans-to-protect-your-privacy">"iPhone, AI and big data: Here's how Apple plans to protect your privacy | ZDNet"</a>. <i>ZDNet</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ZDNet&amp;rft.atitle=iPhone%2C+AI+and+big+data%3A+Here%27s+how+Apple+plans+to+protect+your+privacy+%7C+ZDNet&amp;rft.date=2016-06-14&amp;rft.aulast=Ranger&amp;rft.aufirst=Steve&amp;rft_id=http%3A%2F%2Fwww.zdnet.com%2Farticle%2Fai-big-data-and-the-iphone-heres-how-apple-plans-to-protect-your-privacy&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-AppleSiri-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-AppleSiri_20-0">^</a></b></span> <span class="reference-text"><cite class="citation web">Smith, Chris (2016-06-13). <a rel="nofollow" class="external text" href="http://bgr.com/2016/06/13/ios-10-siri-third-party-apps/">"iOS 10: Siri now works in third-party apps, comes with extra AI features"</a>. <i>BGR</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=BGR&amp;rft.atitle=iOS+10%3A+Siri+now+works+in+third-party+apps%2C+comes+with+extra+AI+features&amp;rft.date=2016-06-13&amp;rft.aulast=Smith&amp;rft.aufirst=Chris&amp;rft_id=http%3A%2F%2Fbgr.com%2F2016%2F06%2F13%2Fios-10-siri-third-party-apps%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-AmazonAlexa-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-AmazonAlexa_21-0">^</a></b></span> <span class="reference-text"><cite class="citation web">Vogels, Werner (30 November 2016). <a rel="nofollow" class="external text" href="http://www.allthingsdistributed.com/2016/11/amazon-ai-and-alexa-for-all-aws-apps.html">"Bringing the Magic of Amazon AI and Alexa to Apps on AWS. - All Things Distributed"</a>. <i>www.allthingsdistributed.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.allthingsdistributed.com&amp;rft.atitle=Bringing+the+Magic+of+Amazon+AI+and+Alexa+to+Apps+on+AWS.+-+All+Things+Distributed&amp;rft.date=2016-11-30&amp;rft.aulast=Vogels&amp;rft.aufirst=Werner&amp;rft_id=http%3A%2F%2Fwww.allthingsdistributed.com%2F2016%2F11%2Famazon-ai-and-alexa-for-all-aws-apps.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-FacebookTranslate-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-FacebookTranslate_22-0">^</a></b></span> <span class="reference-text"><cite class="citation web">Ong, Thuy (4 August 2017). <a rel="nofollow" class="external text" href="https://www.theverge.com/2017/8/4/16093872/facebook-ai-translations-artificial-intelligence">"Facebook's translations are now powered completely by AI"</a>. <i>www.allthingsdistributed.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-02-15</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.allthingsdistributed.com&amp;rft.atitle=Facebook%27s+translations+are+now+powered+completely+by+AI&amp;rft.date=2017-08-04&amp;rft.aulast=Ong&amp;rft.aufirst=Thuy&amp;rft_id=https%3A%2F%2Fwww.theverge.com%2F2017%2F8%2F4%2F16093872%2Ffacebook-ai-translations-artificial-intelligence&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://biometrics.cse.msu.edu/Publications/MachineLearning/Baytasetal_PatientSubtypingViaTimeAwareLSTMNetworks.pdf">"Patient Subtyping via Time-Aware LSTM Networks"</a> <span class="cs1-format">(PDF)</span>. <i>msu.edu</i><span class="reference-accessdate">. Retrieved <span class="nowrap">21 Nov</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=msu.edu&amp;rft.atitle=Patient+Subtyping+via+Time-Aware+LSTM+Networks&amp;rft_id=http%3A%2F%2Fbiometrics.cse.msu.edu%2FPublications%2FMachineLearning%2FBaytasetal_PatientSubtypingViaTimeAwareLSTMNetworks.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.kdd.org/kdd2017/papers/view/patient-subtyping-via-time-aware-lstm-networks">"Patient Subtyping via Time-Aware LSTM Networks"</a>. <i>Kdd.org</i><span class="reference-accessdate">. Retrieved <span class="nowrap">24 May</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Kdd.org&amp;rft.atitle=Patient+Subtyping+via+Time-Aware+LSTM+Networks&amp;rft_id=http%3A%2F%2Fwww.kdd.org%2Fkdd2017%2Fpapers%2Fview%2Fpatient-subtyping-via-time-aware-lstm-networks&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.kdd.org">"SIGKDD"</a>. <i>Kdd.org</i><span class="reference-accessdate">. Retrieved <span class="nowrap">24 May</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Kdd.org&amp;rft.atitle=SIGKDD&amp;rft_id=http%3A%2F%2Fwww.kdd.org&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite class="citation web">Haridy, Rich (August 21, 2017). <a rel="nofollow" class="external text" href="http://newatlas.com/microsoft-speech-recognition-equals-humans/50999">"Microsoft's speech recognition system is now as good as a human"</a>. <i>newatlas.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-08-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=newatlas.com&amp;rft.atitle=Microsoft%27s+speech+recognition+system+is+now+as+good+as+a+human&amp;rft.date=2017-08-21&amp;rft.aulast=Haridy&amp;rft.aufirst=Rich&amp;rft_id=http%3A%2F%2Fnewatlas.com%2Fmicrosoft-speech-recognition-equals-humans%2F50999&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><cite class="citation conference">Voelker, Aaron R.; Kajić, Ivana; Eliasmith, Chris (2019). <a rel="nofollow" class="external text" href="http://compneuro.uwaterloo.ca/files/publications/voelker.2019.lmu.pdf"><i>Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks</i></a> <span class="cs1-format">(PDF)</span>. <a rel="nofollow" class="external text" href="https://neurips.cc">Advances in Neural Information Processing Systems</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Legendre+Memory+Units%3A+Continuous-Time+Representation+in+Recurrent+Neural+Networks&amp;rft.date=2019&amp;rft.aulast=Voelker&amp;rft.aufirst=Aaron+R.&amp;rft.au=Kaji%C4%87%2C+Ivana&amp;rft.au=Eliasmith%2C+Chris&amp;rft_id=http%3A%2F%2Fcompneuro.uwaterloo.ca%2Ffiles%2Fpublications%2Fvoelker.2019.lmu.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text"><cite class="citation web">bro, n. <a rel="nofollow" class="external text" href="https://stats.stackexchange.com/q/320919/82135">"Why can RNNs with LSTM units also suffer from "exploding gradients"?"</a>. <i>Cross Validated</i><span class="reference-accessdate">. Retrieved <span class="nowrap">25 December</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Cross+Validated&amp;rft.atitle=Why+can+RNNs+with+LSTM+units+also+suffer+from+%22exploding+gradients%22%3F&amp;rft.aulast=bro&amp;rft.aufirst=n&amp;rft_id=https%3A%2F%2Fstats.stackexchange.com%2Fq%2F320919%2F82135&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-peepholeLSTM-29"><span class="mw-cite-backlink">^ <a href="#cite_ref-peepholeLSTM_29-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-peepholeLSTM_29-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-peepholeLSTM_29-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Gers, F. A.; Schmidhuber, J. (2001). <a rel="nofollow" class="external text" href="ftp://ftp.idsia.ch/pub/juergen/L-IEEE.pdf">"LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages"</a> <span class="cs1-format">(PDF)</span>. <i>IEEE Transactions on Neural Networks</i>. <b>12</b> (6): 1333–1340. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F72.963769">10.1109/72.963769</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/18249962">18249962</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Neural+Networks&amp;rft.atitle=LSTM+Recurrent+Networks+Learn+Simple+Context+Free+and+Context+Sensitive+Languages&amp;rft.volume=12&amp;rft.issue=6&amp;rft.pages=1333-1340&amp;rft.date=2001&amp;rft_id=info%3Adoi%2F10.1109%2F72.963769&amp;rft_id=info%3Apmid%2F18249962&amp;rft.aulast=Gers&amp;rft.aufirst=F.+A.&amp;rft.au=Schmidhuber%2C+J.&amp;rft_id=ftp%3A%2F%2Fftp.idsia.ch%2Fpub%2Fjuergen%2FL-IEEE.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-peephole2002-30"><span class="mw-cite-backlink">^ <a href="#cite_ref-peephole2002_30-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-peephole2002_30-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-peephole2002_30-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Gers, F.; Schraudolph, N.; Schmidhuber, J. (2002). <a rel="nofollow" class="external text" href="http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf">"Learning precise timing with LSTM recurrent networks"</a> <span class="cs1-format">(PDF)</span>. <i>Journal of Machine Learning Research</i>. <b>3</b>: 115–143.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Machine+Learning+Research&amp;rft.atitle=Learning+precise+timing+with+LSTM+recurrent+networks&amp;rft.volume=3&amp;rft.pages=115-143&amp;rft.date=2002&amp;rft.aulast=Gers&amp;rft.aufirst=F.&amp;rft.au=Schraudolph%2C+N.&amp;rft.au=Schmidhuber%2C+J.&amp;rft_id=http%3A%2F%2Fwww.jmlr.org%2Fpapers%2Fvolume3%2Fgers02a%2Fgers02a.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><cite class="citation journal">Gers, F. A.; Schmidhuber, E. (November 2001). <a rel="nofollow" class="external text" href="ftp://ftp.idsia.ch/pub/juergen/L-IEEE.pdf">"LSTM recurrent networks learn simple context-free and context-sensitive languages"</a> <span class="cs1-format">(PDF)</span>. <i>IEEE Transactions on Neural Networks</i>. <b>12</b> (6): 1333–1340. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F72.963769">10.1109/72.963769</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1045-9227">1045-9227</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/18249962">18249962</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Neural+Networks&amp;rft.atitle=LSTM+recurrent+networks+learn+simple+context-free+and+context-sensitive+languages&amp;rft.volume=12&amp;rft.issue=6&amp;rft.pages=1333-1340&amp;rft.date=2001-11&amp;rft.issn=1045-9227&amp;rft_id=info%3Apmid%2F18249962&amp;rft_id=info%3Adoi%2F10.1109%2F72.963769&amp;rft.aulast=Gers&amp;rft.aufirst=F.+A.&amp;rft.au=Schmidhuber%2C+E.&amp;rft_id=ftp%3A%2F%2Fftp.idsia.ch%2Fpub%2Fjuergen%2FL-IEEE.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text"><cite class="citation journal">Xingjian Shi; Zhourong Chen; Hao Wang; Dit-Yan Yeung; Wai-kin Wong; Wang-chun Woo (2015). "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting". <i>Proceedings of the 28th International Conference on Neural Information Processing Systems</i>: 802–810. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1506.04214">1506.04214</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2015arXiv150604214S">2015arXiv150604214S</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+28th+International+Conference+on+Neural+Information+Processing+Systems&amp;rft.atitle=Convolutional+LSTM+Network%3A+A+Machine+Learning+Approach+for+Precipitation+Nowcasting&amp;rft.pages=802-810&amp;rft.date=2015&amp;rft_id=info%3Aarxiv%2F1506.04214&amp;rft_id=info%3Abibcode%2F2015arXiv150604214S&amp;rft.au=Xingjian+Shi&amp;rft.au=Zhourong+Chen&amp;rft.au=Hao+Wang&amp;rft.au=Dit-Yan+Yeung&amp;rft.au=Wai-kin+Wong&amp;rft.au=Wang-chun+Woo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text">S. Hochreiter. Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut f. Informatik, Technische Univ. Munich, 1991.</span>
</li>
<li id="cite_note-gradf-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-gradf_34-0">^</a></b></span> <span class="reference-text"><cite class="citation book">Hochreiter, S.; Bengio, Y.; Frasconi, P.; Schmidhuber, J. (2001). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/2839938">"Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies (PDF Download Available)"</a>.  In Kremer and, S. C.; Kolen, J. F. (eds.). <i>A Field Guide to Dynamical Recurrent Neural Networks</i>. IEEE Press.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Gradient+Flow+in+Recurrent+Nets%3A+the+Difficulty+of+Learning+Long-Term+Dependencies+%28PDF+Download+Available%29&amp;rft.btitle=A+Field+Guide+to+Dynamical+Recurrent+Neural+Networks.&amp;rft.pub=IEEE+Press&amp;rft.date=2001&amp;rft.aulast=Hochreiter&amp;rft.aufirst=S.&amp;rft.au=Bengio%2C+Y.&amp;rft.au=Frasconi%2C+P.&amp;rft.au=Schmidhuber%2C+J.&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F2839938&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-fernandez2007-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-fernandez2007_35-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Fernández, Santiago; Graves, Alex; Schmidhuber, Jürgen (2007). "Sequence labelling in structured domains with hierarchical recurrent neural networks". <i>Proc. 20th Int. Joint Conf. On Artificial Intelligence, Ijcai 2007</i>: 774–779. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.79.1887">10.1.1.79.1887</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proc.+20th+Int.+Joint+Conf.+On+Artificial+Intelligence%2C+Ijcai+2007&amp;rft.atitle=Sequence+labelling+in+structured+domains+with+hierarchical+recurrent+neural+networks&amp;rft.pages=774-779&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.79.1887&amp;rft.aulast=Fern%C3%A1ndez&amp;rft.aufirst=Santiago&amp;rft.au=Graves%2C+Alex&amp;rft.au=Schmidhuber%2C+J%C3%BCrgen&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-graves2006-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-graves2006_36-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Graves, Alex; Fernández, Santiago; Gomez, Faustino (2006). "Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks". <i>In Proceedings of the International Conference on Machine Learning, ICML 2006</i>: 369–376. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.75.6306">10.1.1.75.6306</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=In+Proceedings+of+the+International+Conference+on+Machine+Learning%2C+ICML+2006&amp;rft.atitle=Connectionist+temporal+classification%3A+Labelling+unsegmented+sequence+data+with+recurrent+neural+networks&amp;rft.pages=369-376&amp;rft.date=2006&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.75.6306&amp;rft.aulast=Graves&amp;rft.aufirst=Alex&amp;rft.au=Fern%C3%A1ndez%2C+Santiago&amp;rft.au=Gomez%2C+Faustino&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-wierstra2005-37"><span class="mw-cite-backlink">^ <a href="#cite_ref-wierstra2005_37-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-wierstra2005_37-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Wierstra, Daan; Schmidhuber, J.; Gomez, F. J. (2005). <a rel="nofollow" class="external text" href="https://www.academia.edu/5830256">"Evolino: Hybrid Neuroevolution/Optimal Linear Search for Sequence Learning"</a>. <i>Proceedings of the 19th International Joint Conference on Artificial Intelligence (IJCAI), Edinburgh</i>: 853–858.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+19th+International+Joint+Conference+on+Artificial+Intelligence+%28IJCAI%29%2C+Edinburgh&amp;rft.atitle=Evolino%3A+Hybrid+Neuroevolution%2FOptimal+Linear+Search+for+Sequence+Learning&amp;rft.pages=853-858&amp;rft.date=2005&amp;rft.aulast=Wierstra&amp;rft.aufirst=Daan&amp;rft.au=Schmidhuber%2C+J.&amp;rft.au=Gomez%2C+F.+J.&amp;rft_id=https%3A%2F%2Fwww.academia.edu%2F5830256&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-OpenAIfive-38"><span class="mw-cite-backlink">^ <a href="#cite_ref-OpenAIfive_38-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-OpenAIfive_38-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation news">Rodriguez, Jesus (July 2, 2018). <a rel="nofollow" class="external text" href="https://towardsdatascience.com/the-science-behind-openai-five-that-just-produced-one-of-the-greatest-breakthrough-in-the-history-b045bcdc2b69">"The Science Behind OpenAI Five that just Produced One of the Greatest Breakthrough in the History of AI"</a>. <i>Towards Data Science</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-01-15</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Towards+Data+Science&amp;rft.atitle=The+Science+Behind+OpenAI+Five+that+just+Produced+One+of+the+Greatest+Breakthrough+in+the+History+of+AI&amp;rft.date=2018-07-02&amp;rft.aulast=Rodriguez&amp;rft.aufirst=Jesus&amp;rft_id=https%3A%2F%2Ftowardsdatascience.com%2Fthe-science-behind-openai-five-that-just-produced-one-of-the-greatest-breakthrough-in-the-history-b045bcdc2b69&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-OpenAIhand-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-OpenAIhand_39-0">^</a></b></span> <span class="reference-text"><cite class="citation news"><a rel="nofollow" class="external text" href="https://blog.openai.com/learning-dexterity/">"Learning Dexterity"</a>. <i>OpenAI Blog</i>. July 30, 2018<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-01-15</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=OpenAI+Blog&amp;rft.atitle=Learning+Dexterity&amp;rft.date=2018-07-30&amp;rft_id=https%3A%2F%2Fblog.openai.com%2Flearning-dexterity%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-alphastar-40"><span class="mw-cite-backlink">^ <a href="#cite_ref-alphastar_40-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-alphastar_40-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation news">Stanford, Stacy (January 25, 2019). <a rel="nofollow" class="external text" href="https://medium.com/mlmemoirs/deepminds-ai-alphastar-showcases-significant-progress-towards-agi-93810c94fbe9">"DeepMind's AI, AlphaStar Showcases Significant Progress Towards AGI"</a>. <i>Medium ML Memoirs</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-01-15</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Medium+ML+Memoirs&amp;rft.atitle=DeepMind%27s+AI%2C+AlphaStar+Showcases+Significant+Progress+Towards+AGI&amp;rft.date=2019-01-25&amp;rft.aulast=Stanford&amp;rft.aufirst=Stacy&amp;rft_id=https%3A%2F%2Fmedium.com%2Fmlmemoirs%2Fdeepminds-ai-alphastar-showcases-significant-progress-towards-agi-93810c94fbe9&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-41">^</a></b></span> <span class="reference-text"><cite class="citation book">Mayer, H.; Gomez, F.; Wierstra, D.; Nagy, I.; Knoll, A.; Schmidhuber, J. (October 2006). <i>A System for Robotic Heart Surgery that Learns to Tie Knots Using Recurrent Neural Networks</i>. <i>2006 IEEE/RSJ International Conference on Intelligent Robots and Systems</i>. pp.&#160;543–548. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.218.3399">10.1.1.218.3399</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FIROS.2006.282190">10.1109/IROS.2006.282190</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4244-0258-8" title="Special:BookSources/978-1-4244-0258-8"><bdi>978-1-4244-0258-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=A+System+for+Robotic+Heart+Surgery+that+Learns+to+Tie+Knots+Using+Recurrent+Neural+Networks&amp;rft.pages=543-548&amp;rft.date=2006-10&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.218.3399&amp;rft_id=info%3Adoi%2F10.1109%2FIROS.2006.282190&amp;rft.isbn=978-1-4244-0258-8&amp;rft.aulast=Mayer&amp;rft.aufirst=H.&amp;rft.au=Gomez%2C+F.&amp;rft.au=Wierstra%2C+D.&amp;rft.au=Nagy%2C+I.&amp;rft.au=Knoll%2C+A.&amp;rft.au=Schmidhuber%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-42">^</a></b></span> <span class="reference-text"><cite class="citation journal">Graves, A.; Schmidhuber, J. (2005). "Framewise phoneme classification with bidirectional LSTM and other neural network architectures". <i>Neural Networks</i>. <b>18</b> (5–6): 602–610. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.331.5800">10.1.1.331.5800</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.neunet.2005.06.042">10.1016/j.neunet.2005.06.042</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/16112549">16112549</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=Framewise+phoneme+classification+with+bidirectional+LSTM+and+other+neural+network+architectures&amp;rft.volume=18&amp;rft.issue=5%E2%80%936&amp;rft.pages=602-610&amp;rft.date=2005&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.331.5800&amp;rft_id=info%3Apmid%2F16112549&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neunet.2005.06.042&amp;rft.aulast=Graves&amp;rft.aufirst=A.&amp;rft.au=Schmidhuber%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-43"><span class="mw-cite-backlink"><b><a href="#cite_ref-43">^</a></b></span> <span class="reference-text"><cite class="citation book">Fernández, Santiago; Graves, Alex; Schmidhuber, Jürgen (2007). <a rel="nofollow" class="external text" href="http://dl.acm.org/citation.cfm?id=1778066.1778092"><i>An Application of Recurrent Neural Networks to Discriminative Keyword Spotting</i></a>. <i>Proceedings of the 17th International Conference on Artificial Neural Networks</i>. ICANN'07. Berlin, Heidelberg: Springer-Verlag. pp.&#160;220–229. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3540746935" title="Special:BookSources/978-3540746935"><bdi>978-3540746935</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=An+Application+of+Recurrent+Neural+Networks+to+Discriminative+Keyword+Spotting&amp;rft.place=Berlin%2C+Heidelberg&amp;rft.series=ICANN%2707&amp;rft.pages=220-229&amp;rft.pub=Springer-Verlag&amp;rft.date=2007&amp;rft.isbn=978-3540746935&amp;rft.aulast=Fern%C3%A1ndez&amp;rft.aufirst=Santiago&amp;rft.au=Graves%2C+Alex&amp;rft.au=Schmidhuber%2C+J%C3%BCrgen&amp;rft_id=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D1778066.1778092&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-ReferenceA-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-ReferenceA_44-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Graves, Alex; Mohamed, Abdel-rahman; Hinton, Geoffrey (2013). "Speech Recognition with Deep Recurrent Neural Networks". <i>Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on</i>: 6645–6649.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Acoustics%2C+Speech+and+Signal+Processing+%28ICASSP%29%2C+2013+IEEE+International+Conference+on&amp;rft.atitle=Speech+Recognition+with+Deep+Recurrent+Neural+Networks&amp;rft.pages=6645-6649&amp;rft.date=2013&amp;rft.aulast=Graves&amp;rft.aufirst=Alex&amp;rft.au=Mohamed%2C+Abdel-rahman&amp;rft.au=Hinton%2C+Geoffrey&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-45">^</a></b></span> <span class="reference-text"><cite class="citation book">Eck, Douglas; Schmidhuber, Jürgen (2002-08-28). <i>Learning the Long-Term Structure of the Blues</i>. <i>Artificial Neural Networks — ICANN 2002</i>. Lecture Notes in Computer Science. <b>2415</b>. Springer, Berlin, Heidelberg. pp.&#160;284–289. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.116.3620">10.1.1.116.3620</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F3-540-46084-5_47">10.1007/3-540-46084-5_47</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3540460848" title="Special:BookSources/978-3540460848"><bdi>978-3540460848</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Learning+the+Long-Term+Structure+of+the+Blues&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=284-289&amp;rft.pub=Springer%2C+Berlin%2C+Heidelberg&amp;rft.date=2002-08-28&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.116.3620&amp;rft_id=info%3Adoi%2F10.1007%2F3-540-46084-5_47&amp;rft.isbn=978-3540460848&amp;rft.aulast=Eck&amp;rft.aufirst=Douglas&amp;rft.au=Schmidhuber%2C+J%C3%BCrgen&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-46">^</a></b></span> <span class="reference-text"><cite class="citation journal">Schmidhuber, J.; Gers, F.; Eck, D.; Schmidhuber, J.; Gers, F. (2002). "Learning nonregular languages: A comparison of simple recurrent networks and LSTM". <i>Neural Computation</i>. <b>14</b> (9): 2039–2041. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.7369">10.1.1.11.7369</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2F089976602320263980">10.1162/089976602320263980</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/12184841">12184841</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Computation&amp;rft.atitle=Learning+nonregular+languages%3A+A+comparison+of+simple+recurrent+networks+and+LSTM&amp;rft.volume=14&amp;rft.issue=9&amp;rft.pages=2039-2041&amp;rft.date=2002&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.11.7369&amp;rft_id=info%3Apmid%2F12184841&amp;rft_id=info%3Adoi%2F10.1162%2F089976602320263980&amp;rft.aulast=Schmidhuber&amp;rft.aufirst=J.&amp;rft.au=Gers%2C+F.&amp;rft.au=Eck%2C+D.&amp;rft.au=Schmidhuber%2C+J.&amp;rft.au=Gers%2C+F.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-47"><span class="mw-cite-backlink"><b><a href="#cite_ref-47">^</a></b></span> <span class="reference-text"><cite class="citation journal">Perez-Ortiz, J. A.; Gers, F. A.; Eck, D.; Schmidhuber, J. (2003). "Kalman filters improve LSTM network performance in problems unsolvable by traditional recurrent nets". <i>Neural Networks</i>. <b>16</b> (2): 241–250. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.381.1992">10.1.1.381.1992</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fs0893-6080%2802%2900219-8">10.1016/s0893-6080(02)00219-8</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/12628609">12628609</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=Kalman+filters+improve+LSTM+network+performance+in+problems+unsolvable+by+traditional+recurrent+nets&amp;rft.volume=16&amp;rft.issue=2&amp;rft.pages=241-250&amp;rft.date=2003&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.381.1992&amp;rft_id=info%3Apmid%2F12628609&amp;rft_id=info%3Adoi%2F10.1016%2Fs0893-6080%2802%2900219-8&amp;rft.aulast=Perez-Ortiz&amp;rft.aufirst=J.+A.&amp;rft.au=Gers%2C+F.+A.&amp;rft.au=Eck%2C+D.&amp;rft.au=Schmidhuber%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-48"><span class="mw-cite-backlink"><b><a href="#cite_ref-48">^</a></b></span> <span class="reference-text">A. Graves, J. Schmidhuber. Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks. Advances in Neural Information Processing Systems 22, NIPS'22, pp 545–552, Vancouver, MIT Press, 2009.</span>
</li>
<li id="cite_note-49"><span class="mw-cite-backlink"><b><a href="#cite_ref-49">^</a></b></span> <span class="reference-text"><cite class="citation book">Graves, Alex; Fernández, Santiago; Liwicki, Marcus; Bunke, Horst; Schmidhuber, Jürgen (2007). <a rel="nofollow" class="external text" href="http://dl.acm.org/citation.cfm?id=2981562.2981635"><i>Unconstrained Online Handwriting Recognition with Recurrent Neural Networks</i></a>. <i>Proceedings of the 20th International Conference on Neural Information Processing Systems</i>. NIPS'07. USA: Curran Associates Inc. pp.&#160;577–584. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9781605603520" title="Special:BookSources/9781605603520"><bdi>9781605603520</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Unconstrained+Online+Handwriting+Recognition+with+Recurrent+Neural+Networks&amp;rft.place=USA&amp;rft.series=NIPS%2707&amp;rft.pages=577-584&amp;rft.pub=Curran+Associates+Inc.&amp;rft.date=2007&amp;rft.isbn=9781605603520&amp;rft.aulast=Graves&amp;rft.aufirst=Alex&amp;rft.au=Fern%C3%A1ndez%2C+Santiago&amp;rft.au=Liwicki%2C+Marcus&amp;rft.au=Bunke%2C+Horst&amp;rft.au=Schmidhuber%2C+J%C3%BCrgen&amp;rft_id=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D2981562.2981635&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-50"><span class="mw-cite-backlink"><b><a href="#cite_ref-50">^</a></b></span> <span class="reference-text">M. Baccouche, F. Mamalet, C Wolf, C. Garcia, A. Baskurt. Sequential Deep Learning for Human Action Recognition. 2nd International Workshop on Human Behavior Understanding (HBU), A.A. Salah, B. Lepri ed. Amsterdam, Netherlands. pp. 29–39. Lecture Notes in Computer Science 7065. Springer. 2011</span>
</li>
<li id="cite_note-51"><span class="mw-cite-backlink"><b><a href="#cite_ref-51">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Huang, Jie; Zhou, Wengang; Zhang, Qilin; Li, Houqiang; Li, Weiping (2018-01-30). "Video-based Sign Language Recognition without Temporal Segmentation". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1801.10111">1801.10111</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.CV">cs.CV</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Video-based+Sign+Language+Recognition+without+Temporal+Segmentation&amp;rft.date=2018-01-30&amp;rft_id=info%3Aarxiv%2F1801.10111&amp;rft.aulast=Huang&amp;rft.aufirst=Jie&amp;rft.au=Zhou%2C+Wengang&amp;rft.au=Zhang%2C+Qilin&amp;rft.au=Li%2C+Houqiang&amp;rft.au=Li%2C+Weiping&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-52"><span class="mw-cite-backlink"><b><a href="#cite_ref-52">^</a></b></span> <span class="reference-text"><cite class="citation journal">Hochreiter, S.; Heusel, M.; Obermayer, K. (2007). "Fast model-based protein homology detection without alignment". <i>Bioinformatics</i>. <b>23</b> (14): 1728–1736. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1093%2Fbioinformatics%2Fbtm247">10.1093/bioinformatics/btm247</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/17488755">17488755</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Bioinformatics&amp;rft.atitle=Fast+model-based+protein+homology+detection+without+alignment&amp;rft.volume=23&amp;rft.issue=14&amp;rft.pages=1728-1736&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1093%2Fbioinformatics%2Fbtm247&amp;rft_id=info%3Apmid%2F17488755&amp;rft.aulast=Hochreiter&amp;rft.aufirst=S.&amp;rft.au=Heusel%2C+M.&amp;rft.au=Obermayer%2C+K.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-53"><span class="mw-cite-backlink"><b><a href="#cite_ref-53">^</a></b></span> <span class="reference-text"><cite class="citation journal">Thireou, T.; Reczko, M. (2007). <a rel="nofollow" class="external text" href="https://www.semanticscholar.org/paper/2985b87fc977d8a893da6086b2a18298b9650d96">"Bidirectional Long Short-Term Memory Networks for predicting the subcellular localization of eukaryotic proteins"</a>. <i>IEEE/ACM Transactions on Computational Biology and Bioinformatics</i>. <b>4</b> (3): 441–446. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2Ftcbb.2007.1015">10.1109/tcbb.2007.1015</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/17666763">17666763</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE%2FACM+Transactions+on+Computational+Biology+and+Bioinformatics&amp;rft.atitle=Bidirectional+Long+Short-Term+Memory+Networks+for+predicting+the+subcellular+localization+of+eukaryotic+proteins&amp;rft.volume=4&amp;rft.issue=3&amp;rft.pages=441-446&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1109%2Ftcbb.2007.1015&amp;rft_id=info%3Apmid%2F17666763&amp;rft.aulast=Thireou&amp;rft.aufirst=T.&amp;rft.au=Reczko%2C+M.&amp;rft_id=https%3A%2F%2Fwww.semanticscholar.org%2Fpaper%2F2985b87fc977d8a893da6086b2a18298b9650d96&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-54"><span class="mw-cite-backlink"><b><a href="#cite_ref-54">^</a></b></span> <span class="reference-text"><cite class="citation journal">Malhotra, Pankaj; Vig, Lovekesh; Shroff, Gautam; Agarwal, Puneet (April 2015). <a rel="nofollow" class="external text" href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2015-56.pdf">"Long Short Term Memory Networks for Anomaly Detection in Time Series"</a> <span class="cs1-format">(PDF)</span>. <i>European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning — ESANN 2015</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=European+Symposium+on+Artificial+Neural+Networks%2C+Computational+Intelligence+and+Machine+Learning+%E2%80%94+ESANN+2015&amp;rft.atitle=Long+Short+Term+Memory+Networks+for+Anomaly+Detection+in+Time+Series&amp;rft.date=2015-04&amp;rft.aulast=Malhotra&amp;rft.aufirst=Pankaj&amp;rft.au=Vig%2C+Lovekesh&amp;rft.au=Shroff%2C+Gautam&amp;rft.au=Agarwal%2C+Puneet&amp;rft_id=https%3A%2F%2Fwww.elen.ucl.ac.be%2FProceedings%2Fesann%2Fesannpdf%2Fes2015-56.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-55"><span class="mw-cite-backlink"><b><a href="#cite_ref-55">^</a></b></span> <span class="reference-text"><cite class="citation book">Tax, N.; Verenich, I.; La Rosa, M.; Dumas, M. (2017). <i>Predictive Business Process Monitoring with LSTM neural networks</i>. <i>Proceedings of the International Conference on Advanced Information Systems Engineering (CAiSE)</i>. Lecture Notes in Computer Science. <b>10253</b>. pp.&#160;477–492. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1612.02130">1612.02130</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-319-59536-8_30">10.1007/978-3-319-59536-8_30</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-319-59535-1" title="Special:BookSources/978-3-319-59535-1"><bdi>978-3-319-59535-1</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Predictive+Business+Process+Monitoring+with+LSTM+neural+networks&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=477-492&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1612.02130&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-319-59536-8_30&amp;rft.isbn=978-3-319-59535-1&amp;rft.aulast=Tax&amp;rft.aufirst=N.&amp;rft.au=Verenich%2C+I.&amp;rft.au=La+Rosa%2C+M.&amp;rft.au=Dumas%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-56"><span class="mw-cite-backlink"><b><a href="#cite_ref-56">^</a></b></span> <span class="reference-text"><cite class="citation journal">Choi, E.; Bahadori, M.T.; Schuetz, E.; Stewart, W.; Sun, J. (2016). <a rel="nofollow" class="external text" href="http://proceedings.mlr.press/v56/Choi16.html">"Doctor AI: Predicting Clinical Events via Recurrent Neural Networks"</a>. <i>Proceedings of the 1st Machine Learning for Healthcare Conference</i>: 301–318. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1511.05942">1511.05942</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2015arXiv151105942C">2015arXiv151105942C</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+1st+Machine+Learning+for+Healthcare+Conference&amp;rft.atitle=Doctor+AI%3A+Predicting+Clinical+Events+via+Recurrent+Neural+Networks&amp;rft.pages=301-318&amp;rft.date=2016&amp;rft_id=info%3Aarxiv%2F1511.05942&amp;rft_id=info%3Abibcode%2F2015arXiv151105942C&amp;rft.aulast=Choi&amp;rft.aufirst=E.&amp;rft.au=Bahadori%2C+M.T.&amp;rft.au=Schuetz%2C+E.&amp;rft.au=Stewart%2C+W.&amp;rft.au=Sun%2C+J.&amp;rft_id=http%3A%2F%2Fproceedings.mlr.press%2Fv56%2FChoi16.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-57"><span class="mw-cite-backlink"><b><a href="#cite_ref-57">^</a></b></span> <span class="reference-text">Jia, Robin; Liang, Percy (2016-06-11). <a href="https://arxiv.org/abs/1606.03622" class="extiw" title="arxiv:1606.03622">"Data Recombination for Neural Semantic Parsing"</a>. <i>arXiv:1606.03622 [cs]</i>.</span>
</li>
<li id="cite_note-Wang_Duan_Zhang_Niu_p=1657-58"><span class="mw-cite-backlink"><b><a href="#cite_ref-Wang_Duan_Zhang_Niu_p=1657_58-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Wang, Le; Duan, Xuhuan; Zhang, Qilin; Niu, Zhenxing; Hua, Gang; Zheng, Nanning (2018-05-22). <a rel="nofollow" class="external text" href="https://qilin-zhang.github.io/_pages/pdfs/Segment-Tube_Spatio-Temporal_Action_Localization_in_Untrimmed_Videos_with_Per-Frame_Segmentation.pdf">"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation"</a> <span class="cs1-format">(PDF)</span>. <i>Sensors</i>. <b>18</b> (5): 1657. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.3390%2Fs18051657">10.3390/s18051657</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1424-8220">1424-8220</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC5982167">5982167</a></span>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/29789447">29789447</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Sensors&amp;rft.atitle=Segment-Tube%3A+Spatio-Temporal+Action+Localization+in+Untrimmed+Videos+with+Per-Frame+Segmentation&amp;rft.volume=18&amp;rft.issue=5&amp;rft.pages=1657&amp;rft.date=2018-05-22&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5982167&amp;rft.issn=1424-8220&amp;rft_id=info%3Apmid%2F29789447&amp;rft_id=info%3Adoi%2F10.3390%2Fs18051657&amp;rft.aulast=Wang&amp;rft.aufirst=Le&amp;rft.au=Duan%2C+Xuhuan&amp;rft.au=Zhang%2C+Qilin&amp;rft.au=Niu%2C+Zhenxing&amp;rft.au=Hua%2C+Gang&amp;rft.au=Zheng%2C+Nanning&amp;rft_id=https%3A%2F%2Fqilin-zhang.github.io%2F_pages%2Fpdfs%2FSegment-Tube_Spatio-Temporal_Action_Localization_in_Untrimmed_Videos_with_Per-Frame_Segmentation.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-Duan_Wang_Zhai_Zheng_2018_p.-59"><span class="mw-cite-backlink"><b><a href="#cite_ref-Duan_Wang_Zhai_Zheng_2018_p._59-0">^</a></b></span> <span class="reference-text"><cite class="citation conference">Duan, Xuhuan; Wang, Le; Zhai, Changbo; Zheng, Nanning; Zhang, Qilin; Niu, Zhenxing; Hua, Gang (2018). <i>Joint Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation</i>. 25th IEEE International Conference on Image Processing (ICIP). <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2Ficip.2018.8451692">10.1109/icip.2018.8451692</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4799-7061-2" title="Special:BookSources/978-1-4799-7061-2"><bdi>978-1-4799-7061-2</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Joint+Spatio-Temporal+Action+Localization+in+Untrimmed+Videos+with+Per-Frame+Segmentation&amp;rft.pub=25th+IEEE+International+Conference+on+Image+Processing+%28ICIP%29&amp;rft.date=2018&amp;rft_id=info%3Adoi%2F10.1109%2Ficip.2018.8451692&amp;rft.isbn=978-1-4799-7061-2&amp;rft.aulast=Duan&amp;rft.aufirst=Xuhuan&amp;rft.au=Wang%2C+Le&amp;rft.au=Zhai%2C+Changbo&amp;rft.au=Zheng%2C+Nanning&amp;rft.au=Zhang%2C+Qilin&amp;rft.au=Niu%2C+Zhenxing&amp;rft.au=Hua%2C+Gang&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-60"><span class="mw-cite-backlink"><b><a href="#cite_ref-60">^</a></b></span> <span class="reference-text"><cite class="citation conference">Orsini, F.; Gastaldi, M.; Mantecchini, L.; Rossi, R. (2019). <i>Neural networks trained with WiFi traces to predict airport passenger behavior</i>. 6th International Conference on Models and Technologies for Intelligent Transportation Systems. Krakow: IEEE. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1910.14026">1910.14026</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FMTITS.2019.8883365">10.1109/MTITS.2019.8883365</a>. 8883365.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Neural+networks+trained+with+WiFi+traces+to+predict+airport+passenger+behavior&amp;rft.place=Krakow&amp;rft.pub=IEEE&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1910.14026&amp;rft_id=info%3Adoi%2F10.1109%2FMTITS.2019.8883365&amp;rft.aulast=Orsini&amp;rft.aufirst=F.&amp;rft.au=Gastaldi%2C+M.&amp;rft.au=Mantecchini%2C+L.&amp;rft.au=Rossi%2C+R.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-61"><span class="mw-cite-backlink"><b><a href="#cite_ref-61">^</a></b></span> <span class="reference-text"><cite class="citation journal">Zhao, Z.; Chen, W.; Wu, X.; Chen, P.C.Y.; Liu, J. (2017). "LSTM network: A deep learning approach for Short-term traffic forecast". <i>IET Intelligent Transport Systems</i>. <b>11</b> (2): 68–75. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1049%2Fiet-its.2016.0208">10.1049/iet-its.2016.0208</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IET+Intelligent+Transport+Systems&amp;rft.atitle=LSTM+network%3A+A+deep+learning+approach+for+Short-term+traffic+forecast&amp;rft.volume=11&amp;rft.issue=2&amp;rft.pages=68-75&amp;rft.date=2017&amp;rft_id=info%3Adoi%2F10.1049%2Fiet-its.2016.0208&amp;rft.aulast=Zhao&amp;rft.aufirst=Z.&amp;rft.au=Chen%2C+W.&amp;rft.au=Wu%2C+X.&amp;rft.au=Chen%2C+P.C.Y.&amp;rft.au=Liu%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=17" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a rel="nofollow" class="external text" href="http://www.idsia.ch/~juergen/rnn.html">Recurrent Neural Networks</a> with over 30 LSTM papers by <a href="/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Jürgen Schmidhuber</a>'s group at <a href="/wiki/IDSIA" class="mw-redirect" title="IDSIA">IDSIA</a></li>
<li><cite class="citation web">Gers, Felix (2001). <a rel="nofollow" class="external text" href="http://www.felixgers.de/papers/phd.pdf">"Long Short-Term Memory in Recurrent Neural Networks"</a> <span class="cs1-format">(PDF)</span>. <i>PhD thesis</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=PhD+thesis&amp;rft.atitle=Long+Short-Term+Memory+in+Recurrent+Neural+Networks&amp;rft.date=2001&amp;rft.aulast=Gers&amp;rft.aufirst=Felix&amp;rft_id=http%3A%2F%2Fwww.felixgers.de%2Fpapers%2Fphd.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite class="citation journal">Gers, Felix A.; Schraudolph, Nicol N.; Schmidhuber, Jürgen (Aug 2002). <a rel="nofollow" class="external text" href="http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf">"Learning precise timing with LSTM recurrent networks"</a> <span class="cs1-format">(PDF)</span>. <i>Journal of Machine Learning Research</i>. <b>3</b>: 115–143.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Machine+Learning+Research&amp;rft.atitle=Learning+precise+timing+with+LSTM+recurrent+networks&amp;rft.volume=3&amp;rft.pages=115-143&amp;rft.date=2002-08&amp;rft.aulast=Gers&amp;rft.aufirst=Felix+A.&amp;rft.au=Schraudolph%2C+Nicol+N.&amp;rft.au=Schmidhuber%2C+J%C3%BCrgen&amp;rft_id=http%3A%2F%2Fwww.jmlr.org%2Fpapers%2Fvolume3%2Fgers02a%2Fgers02a.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite class="citation thesis">Abidogun, Olusola Adeniyi (2005). <a rel="nofollow" class="external text" href="http://etd.uwc.ac.za/xmlui/handle/11394/249"><i>Data Mining, Fraud Detection and Mobile Telecommunications: Call Pattern Analysis with Unsupervised Neural Networks</i></a>. <i>Master's Thesis</i> (Thesis). University of the Western Cape. <a href="/wiki/Handle_System" title="Handle System">hdl</a>:<a rel="nofollow" class="external text" href="//hdl.handle.net/11394%2F249">11394/249</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20120522234026/http://etd.uwc.ac.za/usrfiles/modules/etd/docs/etd_init_3937_1174040706.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on May 22, 2012.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adissertation&amp;rft.title=Data+Mining%2C+Fraud+Detection+and+Mobile+Telecommunications%3A+Call+Pattern+Analysis+with+Unsupervised+Neural+Networks&amp;rft.inst=University+of+the+Western+Cape&amp;rft.date=2005&amp;rft_id=info%3Ahdl%2F11394%2F249&amp;rft.aulast=Abidogun&amp;rft.aufirst=Olusola+Adeniyi&amp;rft_id=http%3A%2F%2Fetd.uwc.ac.za%2Fxmlui%2Fhandle%2F11394%2F249&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/>
<ul><li><a rel="nofollow" class="external text" href="http://etd.uwc.ac.za/bitstream/handle/11394/249/Abidogun_MSC_2005.pdf">original</a> with two chapters devoted to explaining recurrent neural networks, especially LSTM.</li></ul></li>
<li><cite class="citation web">Monner, Derek D.; Reggia, James A. (2010). <a rel="nofollow" class="external text" href="http://www.cs.umd.edu/~dmonner/papers/nn2012.pdf">"A generalized LSTM-like training algorithm for second-order recurrent neural networks"</a> <span class="cs1-format">(PDF)</span>. <q>High-performing extension of LSTM that has been simplified to a single node type and can train arbitrary architectures</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+generalized+LSTM-like+training+algorithm+for+second-order+recurrent+neural+networks&amp;rft.date=2010&amp;rft.aulast=Monner&amp;rft.aufirst=Derek+D.&amp;rft.au=Reggia%2C+James+A.&amp;rft_id=http%3A%2F%2Fwww.cs.umd.edu%2F~dmonner%2Fpapers%2Fnn2012.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li>
<li><cite class="citation web">Herta, Christian. <a rel="nofollow" class="external text" href="http://christianherta.de/lehre/dataScience/machineLearning/neuralNetworks/LSTM.html">"How to implement LSTM in Python with Theano"</a>. <i>Tutorial</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Tutorial&amp;rft.atitle=How+to+implement+LSTM+in+Python+with+Theano&amp;rft.aulast=Herta&amp;rft.aufirst=Christian&amp;rft_id=http%3A%2F%2Fchristianherta.de%2Flehre%2FdataScience%2FmachineLearning%2FneuralNetworks%2FLSTM.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></li></ul>
<!-- 
NewPP limit report
Parsed by mw1341
Cached time: 20200323015539
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.900 seconds
Real time usage: 1.116 seconds
Preprocessor visited node count: 3786/1000000
Post‐expand include size: 155448/2097152 bytes
Template argument size: 1625/2097152 bytes
Highest expansion depth: 12/40
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 211531/5000000 bytes
Number of Wikibase entities loaded: 7/400
Lua time usage: 0.522/10.000 seconds
Lua memory usage: 6.13 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  872.871      1 -total
 73.84%  644.551      1 Template:Reflist
 38.43%  335.482     25 Template:Cite_journal
  8.43%   73.600     14 Template:Cite_web
  8.16%   71.208      1 Template:Machine_learning_bar
  7.56%   66.024      1 Template:Citation_needed
  7.38%   64.389      1 Template:Sidebar_with_collapsible_lists
  6.56%   57.219      1 Template:Fix
  6.29%   54.891      7 Template:Cite_book
  5.92%   51.712      3 Template:Cite_arxiv
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:10711453-0!canonical!math=5 and timestamp 20200323015617 and revision id 946900344
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>
		<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;oldid=946900344">https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;oldid=946900344</a>"</div>
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Artificial_neural_networks" title="Category:Artificial neural networks">Artificial neural networks</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_October_2017" title="Category:Articles with unsourced statements from October 2017">Articles with unsourced statements from October 2017</a></li></ul></div></div>
		<div class="visualClear"></div>
		
	</div>
</div>
<div id='mw-data-after-content'>
	<div class="read-more-container"></div>
</div>

<div id="mw-navigation">
    <h2>Navigation menu</h2>
    <div id="mw-head">
        
        <div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
        	<h3 id="p-personal-label">Personal tools</h3>
        	<ul >
        		
        		<li id="pt-anonuserpage">Not logged in</li>
        		<li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Long+short-term+memory" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Long+short-term+memory" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>
        	</ul>
        </div>
        <div id="left-navigation">
            <div id="p-namespaces" role="navigation" class="vectorTabs " aria-labelledby="p-namespaces-label">
            	<h3 id="p-namespaces-label">Namespaces</h3>
            	<ul >
            		<li id="ca-nstab-main" class="selected"><a href="/wiki/Long_short-term_memory" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Long_short-term_memory" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></li>
            	</ul>
            </div>
            <div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
            	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
            	<h3 id="p-variants-label">
            		<span>Variants</span>
            	</h3>
            	<ul class="menu" >
            		
            	</ul>
            </div>
        </div>
        <div id="right-navigation">
            <div id="p-views" role="navigation" class="vectorTabs " aria-labelledby="p-views-label">
            	<h3 id="p-views-label">Views</h3>
            	<ul >
            		<li id="ca-view" class="collapsible selected"><a href="/wiki/Long_short-term_memory">Read</a></li><li id="ca-edit" class="collapsible"><a href="/w/index.php?title=Long_short-term_memory&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history" class="collapsible"><a href="/w/index.php?title=Long_short-term_memory&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li>
            	</ul>
            </div>
            <div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
            	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
            	<h3 id="p-cactions-label">
            		<span>More</span>
            	</h3>
            	<ul class="menu" >
            		
            	</ul>
            </div>
            <div id="p-search" role="search">
            	<h3 >
            		<label for="searchInput">Search</label>
            	</h3>
            	<form action="/w/index.php" id="searchform">
            		<div id="simpleSearch">
            			<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/>
            			<input type="hidden" value="Special:Search" name="title"/>
            			<input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/>
            			<input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>
            		</div>
            	</form>
            </div>
        </div>
    </div>
    
    <div id="mw-panel">
    	<div id="p-logo" role="banner">
    		<a  title="Visit the main page" class="mw-wiki-logo" href="/wiki/Main_Page"></a>
    	</div>
    	<div class="portal" role="navigation" id="p-navigation"  aria-labelledby="p-navigation-label">
    		<h3  id="p-navigation-label">
    			Navigation
    		</h3>
    		<div class="body">
    			<ul><li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Wikipedia:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li></ul>
    			
    		</div>
    	</div>
    	
    	<div class="portal" role="navigation" id="p-interaction"  aria-labelledby="p-interaction-label">
    		<h3  id="p-interaction-label">
    			Interaction
    		</h3>
    		<div class="body">
    			<ul><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li></ul>
    			
    		</div>
    	</div>
    	
    	<div class="portal" role="navigation" id="p-tb"  aria-labelledby="p-tb-label">
    		<h3  id="p-tb-label">
    			Tools
    		</h3>
    		<div class="body">
    			<ul><li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Long_short-term_memory" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Long_short-term_memory" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Long_short-term_memory&amp;oldid=946900344" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Long_short-term_memory&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q6673524" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Long_short-term_memory&amp;id=946900344&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li></ul>
    			
    		</div>
    	</div>
    	
    	<div class="portal" role="navigation" id="p-coll-print_export"  aria-labelledby="p-coll-print_export-label">
    		<h3  id="p-coll-print_export-label">
    			Print/export
    		</h3>
    		<div class="body">
    			<ul><li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Long+short-term+memory">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Long+short-term+memory&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Long_short-term_memory&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li></ul>
    			
    		</div>
    	</div>
    	
    	<div class="portal" role="navigation" id="p-lang"  aria-labelledby="p-lang-label">
    		<h3  id="p-lang-label">
    			Languages
    		</h3>
    		<div class="body">
    			<ul><li class="interlanguage-link interwiki-ca"><a href="https://ca.wikipedia.org/wiki/Long_short-term_memory" title="Long short-term memory – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target">Català</a></li><li class="interlanguage-link interwiki-de"><a href="https://de.wikipedia.org/wiki/Long_short-term_memory" title="Long short-term memory – German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D8%AD%D8%A7%D9%81%D8%B8%D9%87_%D8%B7%D9%88%D9%84%D8%A7%D9%86%DB%8C_%DA%A9%D9%88%D8%AA%D8%A7%D9%87-%D9%85%D8%AF%D8%AA" title="حافظه طولانی کوتاه-مدت – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-lv"><a href="https://lv.wikipedia.org/wiki/LSTM" title="LSTM – Latvian" lang="lv" hreflang="lv" class="interlanguage-link-target">Latviešu</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E9%95%B7%E3%83%BB%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6" title="長・短期記憶 – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%94%D0%BE%D0%BB%D0%B3%D0%B0%D1%8F_%D0%BA%D1%80%D0%B0%D1%82%D0%BA%D0%BE%D1%81%D1%80%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BF%D0%B0%D0%BC%D1%8F%D1%82%D1%8C" title="Долгая краткосрочная память – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-tr"><a href="https://tr.wikipedia.org/wiki/Long_short-term_memory" title="Long short-term memory – Turkish" lang="tr" hreflang="tr" class="interlanguage-link-target">Türkçe</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%94%D0%BE%D0%B2%D0%B3%D0%B0_%D0%BA%D0%BE%D1%80%D0%BE%D1%82%D0%BA%D0%BE%D1%87%D0%B0%D1%81%D0%BD%D0%B0_%D0%BF%D0%B0%D0%BC%27%D1%8F%D1%82%D1%8C" title="Довга короткочасна пам&#039;ять – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6" title="長短期記憶 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li></ul>
    			<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q6673524#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
    		</div>
    	</div>
    	
    </div>
</div>

<div id="footer" role="contentinfo" >
	<ul id="footer-info" class="">
		<li id="footer-info-lastmod"> This page was last edited on 23 March 2020, at 01:56<span class="anonymous-show">&#160;(UTC)</span>.</li>
		<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
	</ul>
	<ul id="footer-places" class="">
		<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
		<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
		<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
		<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
		<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
		<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
		<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
		<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
	</ul>
	<ul id="footer-icons" class="noprint">
		<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a></li>
		<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a></li>
	</ul>
	<div style="clear: both;"></div>
</div>

<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.900","walltime":"1.116","ppvisitednodes":{"value":3786,"limit":1000000},"postexpandincludesize":{"value":155448,"limit":2097152},"templateargumentsize":{"value":1625,"limit":2097152},"expansiondepth":{"value":12,"limit":40},"expensivefunctioncount":{"value":8,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":211531,"limit":5000000},"entityaccesscount":{"value":7,"limit":400},"timingprofile":["100.00%  872.871      1 -total"," 73.84%  644.551      1 Template:Reflist"," 38.43%  335.482     25 Template:Cite_journal","  8.43%   73.600     14 Template:Cite_web","  8.16%   71.208      1 Template:Machine_learning_bar","  7.56%   66.024      1 Template:Citation_needed","  7.38%   64.389      1 Template:Sidebar_with_collapsible_lists","  6.56%   57.219      1 Template:Fix","  6.29%   54.891      7 Template:Cite_book","  5.92%   51.712      3 Template:Cite_arxiv"]},"scribunto":{"limitreport-timeusage":{"value":"0.522","limit":"10.000"},"limitreport-memusage":{"value":6432386,"limit":52428800}},"cachereport":{"origin":"mw1341","timestamp":"20200323015539","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Long short-term memory","url":"https:\/\/en.wikipedia.org\/wiki\/Long_short-term_memory","sameAs":"http:\/\/www.wikidata.org\/entity\/Q6673524","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q6673524","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2007-04-16T20:18:38Z","dateModified":"2020-03-23T01:56:17Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/3\/3b\/The_LSTM_cell.png","headline":"recurrent neural network architecture"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":118,"wgHostname":"mw1333"});});</script></body></html>
